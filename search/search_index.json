{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#real-time-voice-agent-documentation-hub","title":"Real-Time Voice Agent Documentation Hub","text":"<p>Welcome to the Complete Guide</p> <p>This documentation covers everything you need to deploy, operate, and extend the Azure-based Real-Time Voice Agent with Python 3.11 + FastAPI and enterprise-grade Azure integrations.</p>"},{"location":"#quick-start","title":"Quick Start","text":"\ud83d\ude80 New Users\ud83c\udfd7\ufe0f Architects\ud83d\udd27 Operators <p>Start here for basic setup and deployment:</p> <ol> <li>Getting Started Guide - Installation &amp; basic usage</li> <li>Local Development - Development workflow  </li> <li>Deployment Guide - Azure deployment with azd</li> </ol> <p>Understand the system design:</p> <ol> <li>Architecture Overview - System architecture</li> <li>Data Flows - Redis &amp; Cosmos DB architecture</li> <li>ACS Integration - Three-thread voice processing</li> </ol> <p>Deploy and monitor in production:</p> <ol> <li>Production Deployment - Production checklist</li> <li>Monitoring Guide - Application Insights setup</li> <li>Troubleshooting - Common issues &amp; solutions</li> </ol>"},{"location":"#navigation-guide","title":"Navigation Guide","text":"Guide Description Quick Start Guide Complete setup and basic usage examples Local Development Local development setup and testing Configuration Guide Advanced configuration options Deployment Guide Complete Azure deployment with Terraform/azd Architecture Overview System architecture and design decisions Troubleshooting Common issues and solutions"},{"location":"#by-topic","title":"By Topic","text":"<p>Microsoft Learn Integration</p> <p>Documentation includes comprehensive Microsoft Learn references with validated links to official Azure documentation, samples, and best practices.</p> \ud83c\udfd7\ufe0f Architecture &amp; Design\ud83d\ude80 Deployment &amp; Operations\ud83d\udd27 Development &amp; API\ud83d\udcda Reference &amp; Utilities\ud83c\udfe5 Industry Solutions <p>Core System Design</p> <ul> <li>Architecture Overview - Enterprise Azure infrastructure &amp; logical design</li> <li>ACS Flows - Three-thread voice processing architecture  </li> <li>Data Flows - Redis &amp; Cosmos DB three-tier storage</li> <li>Cross-Cloud Integration - Azure/AWS integration patterns</li> <li>LLM Orchestration - AI model routing &amp; conversation flows</li> </ul> <p>Production Deployment</p> <ul> <li>Deployment Guide - Complete Azure deployment with <code>azd</code></li> <li>Production Checklist - Security, scaling &amp; monitoring</li> <li>CI/CD Pipeline - Automated deployment workflows</li> <li>Monitoring &amp; Observability - Application Insights integration</li> <li>Troubleshooting - Diagnostic guides &amp; solutions</li> <li>Load Testing - Performance validation strategies</li> <li>Testing Framework - Comprehensive testing approach</li> </ul> <p>Development Resources</p> <ul> <li>Getting Started - Quick setup &amp; basic usage</li> <li>Local Development - Development environment</li> <li>Configuration Guide - Environment &amp; service setup</li> <li>API Reference - Complete REST &amp; WebSocket API documentation  </li> <li>Interactive API Docs - OpenAPI specification with testing</li> </ul> <p>Supporting Documentation</p> <ul> <li>Speech Synthesis - Azure Speech TTS integration</li> <li>Speech Recognition - Azure Speech STT capabilities</li> <li>Streaming Modes - Audio processing pipelines</li> <li>Utilities &amp; Tools - Helper services &amp; infrastructure</li> <li>Repository Structure - Codebase organization</li> <li>Authentication Guide - Security &amp; session management</li> </ul> <p>Domain-Specific Guides</p> <ul> <li>Healthcare Solutions - HIPAA-compliant voice applications</li> <li>Samples &amp; Examples - Implementation examples &amp; tutorials</li> </ul>"},{"location":"#diagram-highlights","title":"Diagram Highlights","text":"<ul> <li>Production reference: Architecture Overview \u2013 Production Deployment (image: <code>assets/RTAudio.v0.png</code>)</li> <li>Data lifecycle: Data Flows \u2013 Call Lifecycle with interactive Mermaid sequence diagrams</li> <li>Contact center routing: ACS Flows featuring step-by-step diagrams and Mermaid flows</li> <li>Authentication flows: Authentication Guide detailing OAuth and shared access tokens</li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>Enterprise-Grade Voice AI Platform</p> <p>Built on Azure Communication Services, Azure OpenAI, and Azure Speech Services with FastAPI backend architecture.</p> graph TB     subgraph \"\ud83d\udcde Communication Layer\"         Phone[\ud83d\udcf1 Phone/PSTN]         Browser[\ud83c\udf10 Web Browser]         Teams[\ud83d\udc65 MS Teams]     end      subgraph \"\u26a1 Azure Services\"         ACS[\ud83d\udd17 Azure Communication ServicesCall Automation &amp; Media Streaming]         Speech[\ud83d\udde3\ufe0f Azure Speech ServicesSTT/TTS + Real-time Processing]           OpenAI[\ud83e\udde0 Azure OpenAIGPT-4o + Realtime API]         Redis[\u26a1 Azure Cache for RedisSession State &amp; Coordination]         Cosmos[\ud83d\uddc4\ufe0f Azure Cosmos DBConversation History]     end      subgraph \"\ud83c\udfd7\ufe0f Application Platform\"         Apps[\ud83d\udce6 Azure Container AppsFastAPI Backend + React Frontend]         Monitor[\ud83d\udcca Azure MonitorApplication Insights &amp; Tracing]     end      Phone --&gt; ACS     Browser --&gt; ACS      Teams --&gt; ACS     ACS &lt;--&gt; Speech     ACS &lt;--&gt; Apps     Speech &lt;--&gt; Apps     Apps &lt;--&gt; OpenAI     Apps &lt;--&gt; Redis     Apps &lt;--&gt; Cosmos     Apps --&gt; Monitor      classDef communication fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000     classDef azure fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000     classDef platform fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000      class Phone,Browser,Teams communication     class ACS,Speech,OpenAI,Redis,Cosmos azure     class Apps,Monitor platform   <p>Microsoft Learn Resources</p> <ul> <li>Azure Communication Services Architecture - Real-time media streaming concepts</li> <li>Azure Developer CLI Templates - Deployment automation with <code>azd up</code></li> <li>Azure Container Apps - Serverless container platform</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<p>Choose Your Learning Path</p> <p>Select the path that matches your role and experience level:</p> \ud83c\udd95 First Time Setup\ud83c\udfd7\ufe0f Platform Engineers\ud83d\udc68\u200d\ud83d\udcbb Solution Developers <p>New to the project? Start here:</p> <ol> <li>Getting Started Guide - Complete setup walkthrough</li> <li>Architecture Overview - Understand the system design </li> <li>Deployment Guide - Deploy with <code>azd up</code> in 15 minutes</li> <li>API Reference - Explore the REST and WebSocket APIs</li> </ol> <p>Infrastructure and operations focus:</p> <ol> <li>Production Deployment - Enterprise deployment checklist</li> <li>Monitoring Setup - Application Insights configuration</li> <li>Security Guide - Authentication &amp; session management  </li> <li>Troubleshooting - Diagnostic playbooks</li> </ol> <p>Integration and customization:</p> <ol> <li>Local Development - Dev environment setup</li> <li>Cross-Cloud Integration - Azure/AWS patterns</li> <li>Healthcare Solutions - Domain-specific implementations</li> <li>Speech Services - Advanced voice capabilities</li> </ol> <p>Microsoft Learn Learning Paths</p> <p>Complement this documentation with official Microsoft learning resources:</p> <ul> <li>Azure Communication Services Learning Path - Comprehensive ACS training</li> <li>Azure Developer CLI Fundamentals - Master <code>azd</code> deployment workflows  </li> <li>Azure Container Apps - Container orchestration on Azure</li> </ul>"},{"location":"api/","title":"Overview","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<p>Comprehensive REST API and WebSocket documentation for the Real-Time Voice Agent backend built on Python 3.11 + FastAPI.</p>"},{"location":"api/#quick-start","title":"Quick Start","text":"<p>The API provides comprehensive Azure integrations for voice-enabled applications:</p> <ul> <li>Azure Communication Services - Call automation and bidirectional media streaming</li> <li>Azure Speech Services - Neural text-to-speech and speech recognition  </li> <li>Azure OpenAI - Conversational AI and language processing</li> </ul>"},{"location":"api/#api-endpoints","title":"API Endpoints","text":"<p>The V1 API provides REST and WebSocket endpoints for real-time voice processing:</p>"},{"location":"api/#rest-endpoints","title":"REST Endpoints","text":"<ul> <li><code>/api/v1/calls/</code> - Phone call management (initiate, answer, callbacks)</li> <li><code>/api/v1/health/</code> - Service health monitoring and validation</li> </ul>"},{"location":"api/#websocket-endpoints","title":"WebSocket Endpoints","text":"<ul> <li><code>/api/v1/media/stream</code> - ACS media streaming and session management</li> <li><code>/api/v1/realtime/conversation</code> - Browser-based voice conversations</li> </ul>"},{"location":"api/#interactive-api-documentation","title":"Interactive API Documentation","text":"<p>\ud83d\udc49 Complete API Reference - Interactive OpenAPI documentation with all REST endpoints, WebSocket details, authentication, and configuration.</p>"},{"location":"api/#key-features","title":"Key Features","text":"<ul> <li>Call Management - Phone call lifecycle through Azure Communication Services</li> <li>Media Streaming - Real-time audio processing for ACS calls  </li> <li>Real-time Communication - Browser-based voice conversations</li> <li>Health Monitoring - Service validation and diagnostics</li> </ul>"},{"location":"api/#websocket-protocol","title":"WebSocket Protocol","text":"<p>Real-time bidirectional audio streaming following Azure Communication Services WebSocket specifications:</p> <ul> <li>Audio Format: PCM 16kHz mono (ACS) / PCM 24kHz mono (Azure OpenAI Realtime)</li> <li>Transport: WebSocket over TCP with full-duplex communication</li> <li>Latency: Sub-50ms for voice activity detection and response generation</li> </ul> <p>\ufffd WebSocket Details - Complete protocol documentation</p>"},{"location":"api/#observability","title":"Observability","text":"<p>OpenTelemetry Tracing - Built-in distributed tracing for production monitoring with Azure Monitor integration:</p> <ul> <li>Session-level spans for complete request lifecycle  </li> <li>Service dependency mapping (Speech, Communication Services, Redis, OpenAI)</li> <li>Audio processing latency and error rate monitoring</li> </ul>"},{"location":"api/#streaming-modes","title":"Streaming Modes","text":"<p>The API supports multiple streaming modes configured via <code>ACS_STREAMING_MODE</code>:</p> <ul> <li>MEDIA Mode (Default) - Traditional STT/TTS with orchestrator processing</li> <li>VOICE_LIVE Mode - Azure OpenAI Realtime API integration  </li> <li>TRANSCRIPTION Mode - Real-time transcription without AI responses</li> </ul> <p>\ud83d\udc49 Detailed Configuration - Complete streaming mode documentation</p>"},{"location":"api/#architecture","title":"Architecture","text":"<p>Three-Thread Design - Optimized for real-time conversational AI with sub-10ms barge-in detection following Azure Speech SDK best practices.</p> <p>\ufffd Architecture Details - Complete three-thread architecture documentation</p>"},{"location":"api/#reliability","title":"Reliability","text":"<p>Graceful Degradation - Following Azure Communication Services reliability patterns:</p> <ul> <li>Connection pooling and retry logic with exponential backoff</li> <li>Headless environment support with memory-only audio synthesis  </li> <li>Managed identity authentication with automatic token refresh</li> </ul>"},{"location":"api/#related-documentation","title":"Related Documentation","text":"<ul> <li>API Reference - Complete OpenAPI specification with interactive testing</li> <li>Speech Synthesis - Comprehensive TTS implementation guide</li> <li>Speech Recognition - Advanced STT capabilities and configuration</li> <li>Streaming Modes - Audio processing pipeline configuration</li> <li>Utilities - Supporting services and infrastructure components</li> <li>Architecture Overview - System architecture and deployment patterns</li> </ul>"},{"location":"api/api-reference/","title":"API Reference","text":""},{"location":"api/api-reference/#api-reference","title":"API Reference","text":"<p>Interactive API documentation generated from the OpenAPI schema. This provides the definitive reference for all REST endpoints, WebSocket connections, authentication, and configuration.</p>"},{"location":"api/api-reference/#interactive-documentation","title":"Interactive Documentation","text":""},{"location":"api/api-reference/#real-time-voice-agent-api-100","title":"Real-Time Voice Agent API 1.0.0","text":"<p>Real-Time Voice Agent API</p> <p>Contact: Real-Time Voice Agent Team support@example.com</p> <p>License: MIT License</p>"},{"location":"api/api-reference/#health","title":"health","text":""},{"location":"api/api-reference/#get-apiv1health","title":"GET /api/v1/health","text":"<p>Basic Health Check</p> <p>Description Basic health check endpoint that returns 200 if the server is running. Used by load balancers for liveness checks.</p>"},{"location":"api/api-reference/#response-200-ok","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"status\": \"healthy\",\n    \"version\": \"1.0.0\",\n    \"timestamp\": 1691668800.0,\n    \"message\": \"Real-Time Audio Agent API v1 is running\",\n    \"details\": {\n        \"api_version\": \"v1\",\n        \"service\": \"rtagent-backend\"\n    }\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"status\": {\n            \"type\": \"string\",\n            \"title\": \"Status\",\n            \"description\": \"Overall health status\",\n            \"example\": \"healthy\"\n        },\n        \"version\": {\n            \"type\": \"string\",\n            \"title\": \"Version\",\n            \"description\": \"API version\",\n            \"default\": \"1.0.0\",\n            \"example\": \"1.0.0\"\n        },\n        \"timestamp\": {\n            \"type\": \"number\",\n            \"title\": \"Timestamp\",\n            \"description\": \"Timestamp when check was performed\",\n            \"example\": 1691668800.0\n        },\n        \"message\": {\n            \"type\": \"string\",\n            \"title\": \"Message\",\n            \"description\": \"Human-readable status message\",\n            \"example\": \"Real-Time Audio Agent API v1 is running\"\n        },\n        \"details\": {\n            \"additionalProperties\": true,\n            \"type\": \"object\",\n            \"title\": \"Details\",\n            \"description\": \"Additional health details\",\n            \"example\": {\n                \"api_version\": \"v1\",\n                \"service\": \"rtagent-backend\"\n            }\n        },\n        \"active_sessions\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"integer\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Active Sessions\",\n            \"description\": \"Current number of active realtime conversation sessions (None if unavailable)\",\n            \"example\": 3\n        },\n        \"session_metrics\": {\n            \"anyOf\": [\n                {\n                    \"additionalProperties\": true,\n                    \"type\": \"object\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Session Metrics\",\n            \"description\": \"Optional granular session metrics (connected/disconnected, etc.)\",\n            \"example\": {\n                \"active\": 3,\n                \"connected\": 5,\n                \"disconnected\": 2\n            }\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"status\",\n        \"timestamp\",\n        \"message\"\n    ],\n    \"title\": \"HealthResponse\",\n    \"description\": \"Health check response model.\",\n    \"example\": {\n        \"active_sessions\": 3,\n        \"details\": {\n            \"api_version\": \"v1\",\n            \"service\": \"rtagent-backend\"\n        },\n        \"message\": \"Real-Time Audio Agent API v1 is running\",\n        \"session_metrics\": {\n            \"active\": 3,\n            \"connected\": 5,\n            \"disconnected\": 2\n        },\n        \"status\": \"healthy\",\n        \"timestamp\": 1691668800.0,\n        \"version\": \"1.0.0\"\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#get-apiv1readiness","title":"GET /api/v1/readiness","text":"<p>Comprehensive Readiness Check</p> <p>Description Comprehensive readiness probe that checks all critical dependencies with timeouts.</p> <pre><code>This endpoint verifies:\n- Redis connectivity and performance\n- Azure OpenAI client health\n- Speech services (TTS/STT) availability\n- ACS caller configuration and connectivity\n- RT Agents initialization\n- Authentication configuration (when ENABLE_AUTH_VALIDATION=True)\n- Event system health\n\nWhen authentication validation is enabled, checks:\n- BACKEND_AUTH_CLIENT_ID is set and is a valid GUID\n- AZURE_TENANT_ID is set and is a valid GUID\n- ALLOWED_CLIENT_IDS contains at least one valid GUID\n\nReturns 503 if any critical services are unhealthy, 200 if all systems are\n</code></pre> <p>ready.</p>"},{"location":"api/api-reference/#response-200-ok_1","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"status\": \"ready\",\n    \"timestamp\": 1691668800.0,\n    \"response_time_ms\": 45.2,\n    \"checks\": [\n        {\n            \"component\": \"redis\",\n            \"status\": \"healthy\",\n            \"check_time_ms\": 12.5,\n            \"details\": \"Connected to Redis successfully\"\n        },\n        {\n            \"component\": \"auth_configuration\",\n            \"status\": \"healthy\",\n            \"check_time_ms\": 1.2,\n            \"details\": \"Auth validation enabled with 2 allowed client(s)\"\n        }\n    ],\n    \"event_system\": {\n        \"is_healthy\": true,\n        \"handlers_count\": 7,\n        \"domains_count\": 2\n    }\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"status\": {\n            \"type\": \"string\",\n            \"enum\": [\n                \"ready\",\n                \"not_ready\",\n                \"degraded\"\n            ],\n            \"title\": \"Status\",\n            \"description\": \"Overall readiness status\",\n            \"example\": \"ready\"\n        },\n        \"timestamp\": {\n            \"type\": \"number\",\n            \"title\": \"Timestamp\",\n            \"description\": \"Timestamp when check was performed\",\n            \"example\": 1691668800.0\n        },\n        \"response_time_ms\": {\n            \"type\": \"number\",\n            \"title\": \"Response Time Ms\",\n            \"description\": \"Total time taken for all checks in milliseconds\",\n            \"example\": 45.2\n        },\n        \"checks\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ServiceCheck\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Checks\",\n            \"description\": \"Individual component health checks\"\n        },\n        \"event_system\": {\n            \"anyOf\": [\n                {\n                    \"additionalProperties\": true,\n                    \"type\": \"object\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Event System\",\n            \"description\": \"Event system status information\",\n            \"example\": {\n                \"domains_count\": 2,\n                \"handlers_count\": 7,\n                \"is_healthy\": true\n            }\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"status\",\n        \"timestamp\",\n        \"response_time_ms\",\n        \"checks\"\n    ],\n    \"title\": \"ReadinessResponse\",\n    \"description\": \"Comprehensive readiness check response model.\",\n    \"example\": {\n        \"checks\": [\n            {\n                \"check_time_ms\": 12.5,\n                \"component\": \"redis\",\n                \"details\": \"Connected to Redis successfully\",\n                \"status\": \"healthy\"\n            },\n            {\n                \"check_time_ms\": 8.3,\n                \"component\": \"azure_openai\",\n                \"details\": \"Client initialized\",\n                \"status\": \"healthy\"\n            }\n        ],\n        \"event_system\": {\n            \"domains_count\": 2,\n            \"handlers_count\": 7,\n            \"is_healthy\": true\n        },\n        \"response_time_ms\": 45.2,\n        \"status\": \"ready\",\n        \"timestamp\": 1691668800.0\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#response-503-service-unavailable","title":"Response 503 Service Unavailable","text":"<p>application/json</p> <pre><code>{\n    \"status\": \"not_ready\",\n    \"timestamp\": 1691668800.0,\n    \"response_time_ms\": 1250.0,\n    \"checks\": [\n        {\n            \"component\": \"redis\",\n            \"status\": \"unhealthy\",\n            \"check_time_ms\": 1000.0,\n            \"error\": \"Connection timeout\"\n        },\n        {\n            \"component\": \"auth_configuration\",\n            \"status\": \"unhealthy\",\n            \"check_time_ms\": 2.1,\n            \"error\": \"BACKEND_AUTH_CLIENT_ID is not a valid GUID\"\n        }\n    ]\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#get-apiv1agents","title":"GET /api/v1/agents","text":"<p>Get Agents Info</p> <p>Description Get information about loaded RT agents including their configuration, model settings, and voice settings that can be modified.</p>"},{"location":"api/api-reference/#response-200-ok_2","title":"Response 200 OK","text":"<p>application/json</p> <p>Schema of the response body</p>"},{"location":"api/api-reference/#put-apiv1agentsagent_name","title":"PUT /api/v1/agents/{agent_name}","text":"<p>Update Agent Config</p> <p>Description Update configuration for a specific agent (model settings, voice, etc.). Changes are applied to the runtime instance but not persisted to YAML files.</p> <p>Input parameters</p> Parameter In Type Default Nullable Description agent_name path string No <p>Request body</p> <p>application/json</p> <p><pre><code>{\n    \"model\": null,\n    \"voice\": null\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the request body</p> <pre><code>{\n    \"properties\": {\n        \"model\": {\n            \"anyOf\": [\n                {\n                    \"$ref\": \"#/components/schemas/AgentModelUpdate\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ]\n        },\n        \"voice\": {\n            \"anyOf\": [\n                {\n                    \"$ref\": \"#/components/schemas/AgentVoiceUpdate\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ]\n        }\n    },\n    \"type\": \"object\",\n    \"title\": \"AgentConfigUpdate\"\n}\n</code></pre>"},{"location":"api/api-reference/#response-200-ok_3","title":"Response 200 OK","text":"<p>application/json</p> <p>Schema of the response body</p>"},{"location":"api/api-reference/#response-422-unprocessable-entity","title":"Response 422 Unprocessable Entity","text":"<p>application/json</p> <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n        }\n    },\n    \"type\": \"object\",\n    \"title\": \"HTTPValidationError\"\n}\n</code></pre>"},{"location":"api/api-reference/#call-management","title":"Call Management","text":""},{"location":"api/api-reference/#post-apiv1callsinitiate","title":"POST /api/v1/calls/initiate","text":"<p>Initiate Outbound Call</p> <p>Description Initiate a new outbound call to the specified phone number.</p> <pre><code>This endpoint:\n- Validates the phone number format\n- Generates a unique call ID\n- Emits a call initiation event through the V1 event system\n- Returns immediately with call status\n\nThe actual call establishment is handled asynchronously through Azure\n</code></pre> <p>Communication Services.</p> <p>Request body</p> <p>application/json</p> <p><pre><code>{\n    \"caller_id\": \"+1987654321\",\n    \"context\": {\n        \"customer_id\": \"cust_12345\",\n        \"department\": \"support\"\n    },\n    \"target_number\": \"+1234567890\"\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the request body</p> <pre><code>{\n    \"properties\": {\n        \"target_number\": {\n            \"type\": \"string\",\n            \"pattern\": \"^\\\\+[1-9]\\\\d{1,14}$\",\n            \"title\": \"Target Number\",\n            \"description\": \"Phone number to call in E.164 format (e.g., +1234567890)\",\n            \"example\": \"+1234567890\"\n        },\n        \"caller_id\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"string\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Caller Id\",\n            \"description\": \"Caller ID to display (optional, uses system default if not provided)\",\n            \"example\": \"+1987654321\"\n        },\n        \"context\": {\n            \"anyOf\": [\n                {\n                    \"additionalProperties\": true,\n                    \"type\": \"object\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Context\",\n            \"description\": \"Additional call context metadata\",\n            \"example\": {\n                \"customer_id\": \"cust_12345\",\n                \"department\": \"support\",\n                \"priority\": \"high\",\n                \"source\": \"web_portal\"\n            }\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"target_number\"\n    ],\n    \"title\": \"CallInitiateRequest\",\n    \"description\": \"Request model for initiating a call.\",\n    \"example\": {\n        \"caller_id\": \"+1987654321\",\n        \"context\": {\n            \"customer_id\": \"cust_12345\",\n            \"department\": \"support\"\n        },\n        \"target_number\": \"+1234567890\"\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#response-200-ok_4","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"call_id\": \"call_abc12345\",\n    \"status\": \"initiating\",\n    \"target_number\": \"+1234567890\",\n    \"message\": \"Call initiation requested for +1234567890\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"call_id\": {\n            \"type\": \"string\",\n            \"title\": \"Call Id\",\n            \"description\": \"Unique call identifier\",\n            \"example\": \"call_abc12345\"\n        },\n        \"status\": {\n            \"type\": \"string\",\n            \"title\": \"Status\",\n            \"description\": \"Current call status\",\n            \"example\": \"initiating\"\n        },\n        \"target_number\": {\n            \"type\": \"string\",\n            \"title\": \"Target Number\",\n            \"description\": \"Target phone number\",\n            \"example\": \"+1234567890\"\n        },\n        \"message\": {\n            \"type\": \"string\",\n            \"title\": \"Message\",\n            \"description\": \"Human-readable status message\",\n            \"example\": \"Call initiation requested\"\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"call_id\",\n        \"status\",\n        \"target_number\",\n        \"message\"\n    ],\n    \"title\": \"CallInitiateResponse\",\n    \"description\": \"Response model for call initiation.\",\n    \"example\": {\n        \"call_id\": \"call_abc12345\",\n        \"message\": \"Call initiation requested for +1234567890\",\n        \"status\": \"initiating\",\n        \"target_number\": \"+1234567890\"\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#response-400-bad-request","title":"Response 400 Bad Request","text":"<p>application/json</p> <pre><code>{\n    \"detail\": \"Invalid phone number format. Must be in E.164 format (e.g., +1234567890)\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-500-internal-server-error","title":"Response 500 Internal Server Error","text":"<p>application/json</p> <pre><code>{\n    \"detail\": \"Failed to initiate call: Azure Communication Service unavailable\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-422-unprocessable-entity_1","title":"Response 422 Unprocessable Entity","text":"<p>application/json</p> <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n        }\n    },\n    \"type\": \"object\",\n    \"title\": \"HTTPValidationError\"\n}\n</code></pre>"},{"location":"api/api-reference/#get-apiv1calls","title":"GET /api/v1/calls/","text":"<p>List Calls</p> <p>Description Retrieve a paginated list of calls with optional filtering.</p> <pre><code>Supports:\n- Pagination with page and limit parameters\n- Filtering by call status\n- Sorting by creation time (newest first)\n</code></pre> <p>Input parameters</p> Parameter In Type Default Nullable Description limit query integer 10 No Number of items per page (1-100) page query integer 1 No Page number (1-based) status_filter query None No Filter calls by status"},{"location":"api/api-reference/#response-200-ok_5","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"calls\": [\n        {\n            \"call_id\": \"call_abc12345\",\n            \"status\": \"connected\",\n            \"duration\": 120,\n            \"participants\": [],\n            \"events\": []\n        }\n    ],\n    \"total\": 25,\n    \"page\": 1,\n    \"limit\": 10\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"calls\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/CallStatusResponse\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Calls\",\n            \"description\": \"List of calls\"\n        },\n        \"total\": {\n            \"type\": \"integer\",\n            \"title\": \"Total\",\n            \"description\": \"Total number of calls matching criteria\",\n            \"example\": 25\n        },\n        \"page\": {\n            \"type\": \"integer\",\n            \"title\": \"Page\",\n            \"description\": \"Current page number (1-based)\",\n            \"default\": 1,\n            \"example\": 1\n        },\n        \"limit\": {\n            \"type\": \"integer\",\n            \"title\": \"Limit\",\n            \"description\": \"Number of items per page\",\n            \"default\": 10,\n            \"example\": 10\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"calls\",\n        \"total\"\n    ],\n    \"title\": \"CallListResponse\",\n    \"description\": \"Response model for listing calls.\",\n    \"example\": {\n        \"calls\": [\n            {\n                \"call_id\": \"call_abc12345\",\n                \"duration\": 120,\n                \"events\": [],\n                \"participants\": [],\n                \"status\": \"connected\"\n            }\n        ],\n        \"limit\": 10,\n        \"page\": 1,\n        \"total\": 25\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#response-400-bad-request_1","title":"Response 400 Bad Request","text":"<p>application/json</p> <pre><code>{\n    \"detail\": \"Page number must be positive\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-422-unprocessable-entity_2","title":"Response 422 Unprocessable Entity","text":"<p>application/json</p> <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n        }\n    },\n    \"type\": \"object\",\n    \"title\": \"HTTPValidationError\"\n}\n</code></pre>"},{"location":"api/api-reference/#post-apiv1callsanswer","title":"POST /api/v1/calls/answer","text":"<p>Answer Inbound Call</p> <p>Description Handle inbound call events and Event Grid subscription validation.</p> <pre><code>This endpoint:\n- Validates Event Grid subscription requests\n- Answers incoming calls automatically with orchestrator selection\n- Initializes conversation state with features\n- Supports pluggable conversation orchestrators\n- Provides advanced tracing and monitoring\n\nEnhanced V1 features:\n- Pluggable orchestrator injection for conversation handling\n- Enhanced state management with orchestrator metadata\n- Advanced observability and correlation\n- Production-ready error handling\n</code></pre>"},{"location":"api/api-reference/#response-200-ok_6","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"status\": \"call answered\",\n    \"orchestrator\": \"gpt_flow\",\n    \"acs_features\": {\n        \"orchestrator_support\": true,\n        \"advanced_tracing\": true,\n        \"api_version\": \"v1\"\n    }\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-400-bad-request_2","title":"Response 400 Bad Request","text":"<p>application/json</p> <pre><code>{\n    \"detail\": \"Invalid Event Grid request format\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-503-service-unavailable_1","title":"Response 503 Service Unavailable","text":"<p>application/json</p> <pre><code>{\n    \"detail\": \"ACS not initialised\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#post-apiv1callscallbacks","title":"POST /api/v1/calls/callbacks","text":"<p>Handle ACS Callback Events</p> <p>Description Handle Azure Communication Services callback events.</p> <pre><code>This endpoint receives webhooks from ACS when call events occur:\n- Call connected/disconnected\n- Participant joined/left\n- Media events (DTMF tones, play completed, etc.)\n- Transfer events\n\nThe endpoint validates authentication, processes events through the\nV1 CallEventProcessor system, and returns processing results.\n</code></pre>"},{"location":"api/api-reference/#response-200-ok_7","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"status\": \"success\",\n    \"processed_events\": 1,\n    \"call_connection_id\": \"abc123\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-500-internal-server-error_1","title":"Response 500 Internal Server Error","text":"<p>application/json</p> <pre><code>{\n    \"error\": \"Failed to process callback events\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#response-503-service-unavailable_2","title":"Response 503 Service Unavailable","text":"<p>application/json</p> <pre><code>{\n    \"error\": \"ACS not initialised\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>\n</code></pre>"},{"location":"api/api-reference/#acs-media-session","title":"ACS Media Session","text":""},{"location":"api/api-reference/#get-apiv1mediastatus","title":"GET /api/v1/media/status","text":"<p>Get Media Streaming Status</p> <p>Description Get the current status of media streaming configuration.</p> <p>:return: Current media streaming configuration and status :rtype: dict</p>"},{"location":"api/api-reference/#response-200-ok_8","title":"Response 200 OK","text":"<p>application/json</p> <p>Schema of the response body</p> <pre><code>{\n    \"additionalProperties\": true,\n    \"type\": \"object\",\n    \"title\": \"Response Get Media Status Api V1 Media Status Get\"\n}\n</code></pre>"},{"location":"api/api-reference/#post-apiv1mediasessions","title":"POST /api/v1/media/sessions","text":"<p>Create Media Session</p> <p>Description Create a new media streaming session for Azure Communication Services.</p> <p>Initializes a media session with specified audio configuration and returns WebSocket connection details for real-time audio streaming. This endpoint prepares the infrastructure for bidirectional media communication with configurable audio parameters.</p> <p>Args:     request: Media session configuration including call connection ID,             audio format, sample rate, and streaming options.</p> <p>Returns:     MediaSessionResponse: Session details containing unique session ID,     WebSocket URL for streaming, status, and audio configuration.</p> <p>Raises:     HTTPException: When session creation fails due to invalid configuration                   or system resource constraints.</p> <p>Example:     &gt;&gt;&gt; request = MediaSessionRequest(call_connection_id=\"call_123\")     &gt;&gt;&gt; response = await create_media_session(request)     &gt;&gt;&gt; print(response.websocket_url)</p> <p>Request body</p> <p>application/json</p> <p><pre><code>{\n    \"audio_format\": \"pcm_16\",\n    \"call_connection_id\": \"call_12345\",\n    \"channels\": 1,\n    \"chunk_size\": 1024,\n    \"enable_transcription\": true,\n    \"enable_vad\": true,\n    \"sample_rate\": 16000\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the request body</p> <pre><code>{\n    \"properties\": {\n        \"call_connection_id\": {\n            \"type\": \"string\",\n            \"title\": \"Call Connection Id\",\n            \"description\": \"ACS call connection identifier\",\n            \"example\": \"call_12345\"\n        },\n        \"sample_rate\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"integer\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Sample Rate\",\n            \"description\": \"Audio sample rate in Hz\",\n            \"default\": 16000,\n            \"example\": 16000\n        },\n        \"channels\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"integer\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Channels\",\n            \"description\": \"Number of audio channels\",\n            \"default\": 1,\n            \"example\": 1\n        },\n        \"audio_format\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"string\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Audio Format\",\n            \"description\": \"Audio format (pcm_16, pcm_24, opus, etc.)\",\n            \"default\": \"pcm_16\",\n            \"example\": \"pcm_16\"\n        },\n        \"chunk_size\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"integer\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Chunk Size\",\n            \"description\": \"Audio chunk size in bytes\",\n            \"default\": 1024,\n            \"example\": 1024\n        },\n        \"enable_transcription\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"boolean\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Enable Transcription\",\n            \"description\": \"Enable real-time transcription\",\n            \"default\": true,\n            \"example\": true\n        },\n        \"enable_vad\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"boolean\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"title\": \"Enable Vad\",\n            \"description\": \"Enable voice activity detection\",\n            \"default\": true,\n            \"example\": true\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"call_connection_id\"\n    ],\n    \"title\": \"MediaSessionRequest\",\n    \"description\": \"Request schema for starting a media session.\",\n    \"example\": {\n        \"audio_format\": \"pcm_16\",\n        \"call_connection_id\": \"call_12345\",\n        \"channels\": 1,\n        \"chunk_size\": 1024,\n        \"enable_transcription\": true,\n        \"enable_vad\": true,\n        \"sample_rate\": 16000\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#response-200-ok_9","title":"Response 200 OK","text":"<p>application/json</p> <p><pre><code>{\n    \"configuration\": {\n        \"channels\": 1,\n        \"chunk_size\": 1024,\n        \"format\": \"pcm_16\",\n        \"sample_rate\": 16000\n    },\n    \"created_at\": \"2025-08-10T13:45:00Z\",\n    \"session_id\": \"media_session_123456\",\n    \"status\": \"active\",\n    \"websocket_url\": \"wss://api.example.com/v1/media/stream/media_session_123456\"\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"session_id\": {\n            \"type\": \"string\",\n            \"title\": \"Session Id\",\n            \"description\": \"Unique media session identifier\",\n            \"example\": \"media_session_123456\"\n        },\n        \"websocket_url\": {\n            \"type\": \"string\",\n            \"title\": \"Websocket Url\",\n            \"description\": \"WebSocket URL for audio streaming\",\n            \"example\": \"wss://api.example.com/v1/media/stream/media_session_123456\"\n        },\n        \"status\": {\n            \"type\": \"string\",\n            \"title\": \"Status\",\n            \"description\": \"Session status\",\n            \"example\": \"active\"\n        },\n        \"created_at\": {\n            \"type\": \"string\",\n            \"title\": \"Created At\",\n            \"description\": \"Session creation timestamp\",\n            \"example\": \"2025-08-10T13:45:00Z\"\n        },\n        \"configuration\": {\n            \"additionalProperties\": true,\n            \"type\": \"object\",\n            \"title\": \"Configuration\",\n            \"description\": \"Session configuration settings\",\n            \"example\": {\n                \"channels\": 1,\n                \"chunk_size\": 1024,\n                \"format\": \"pcm_16\",\n                \"sample_rate\": 16000\n            }\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"session_id\",\n        \"websocket_url\",\n        \"status\",\n        \"created_at\",\n        \"configuration\"\n    ],\n    \"title\": \"MediaSessionResponse\",\n    \"description\": \"Response schema for media session creation.\",\n    \"example\": {\n        \"configuration\": {\n            \"channels\": 1,\n            \"chunk_size\": 1024,\n            \"format\": \"pcm_16\",\n            \"sample_rate\": 16000\n        },\n        \"created_at\": \"2025-08-10T13:45:00Z\",\n        \"session_id\": \"media_session_123456\",\n        \"status\": \"active\",\n        \"websocket_url\": \"wss://api.example.com/v1/media/stream/media_session_123456\"\n    }\n}\n</code></pre>"},{"location":"api/api-reference/#response-422-unprocessable-entity_3","title":"Response 422 Unprocessable Entity","text":"<p>application/json</p> <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n        }\n    },\n    \"type\": \"object\",\n    \"title\": \"HTTPValidationError\"\n}\n</code></pre>"},{"location":"api/api-reference/#get-apiv1mediasessionssession_id","title":"GET /api/v1/media/sessions/{session_id}","text":"<p>Get Media Session Status</p> <p>Description Retrieve status and metadata for a specific media session.</p> <p>Queries the current state of an active media session including connection status, WebSocket state, and session configuration details. Used for monitoring and debugging media streaming sessions.</p> <p>Args:     session_id: Unique identifier for the media session to query.</p> <p>Returns:     dict: Session information including status, connection state, creation     timestamp, and API version details.</p> <p>Example:     &gt;&gt;&gt; session_info = await get_media_session(\"media_session_123\")     &gt;&gt;&gt; print(session_info[\"status\"])</p> <p>Input parameters</p> Parameter In Type Default Nullable Description session_id path string No"},{"location":"api/api-reference/#response-200-ok_10","title":"Response 200 OK","text":"<p>application/json</p> <p>Schema of the response body</p> <pre><code>{\n    \"type\": \"object\",\n    \"additionalProperties\": true,\n    \"title\": \"Response Get Media Session Api V1 Media Sessions  Session Id  Get\"\n}\n</code></pre>"},{"location":"api/api-reference/#response-422-unprocessable-entity_4","title":"Response 422 Unprocessable Entity","text":"<p>application/json</p> <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n        }\n    },\n    \"type\": \"object\",\n    \"title\": \"HTTPValidationError\"\n}\n</code></pre>"},{"location":"api/api-reference/#real-time-communication","title":"Real-time Communication","text":""},{"location":"api/api-reference/#get-apiv1realtimestatus","title":"GET /api/v1/realtime/status","text":"<p>Get Realtime Service Status</p> <p>Description Get the current status of the realtime communication service.</p> <pre><code>Returns information about:\n- Service availability and health\n- Supported protocols and features\n- Active connection counts\n- WebSocket endpoint configurations\n</code></pre>"},{"location":"api/api-reference/#response-200-ok_11","title":"Response 200 OK","text":"<p>application/json</p> <pre><code>{\n    \"status\": \"available\",\n    \"websocket_endpoints\": {\n        \"dashboard_relay\": \"/api/v1/realtime/dashboard/relay\",\n        \"conversation\": \"/api/v1/realtime/conversation\"\n    },\n    \"features\": {\n        \"dashboard_broadcasting\": true,\n        \"conversation_streaming\": true,\n        \"orchestrator_support\": true,\n        \"session_management\": true\n    },\n    \"active_connections\": {\n        \"dashboard_clients\": 0,\n        \"conversation_sessions\": 0\n    },\n    \"version\": \"v1\"\n}\n</code></pre> <p>Schema of the response body</p> <pre><code>{\n    \"properties\": {\n        \"status\": {\n            \"type\": \"string\",\n            \"enum\": [\n                \"available\",\n                \"degraded\",\n                \"unavailable\"\n            ],\n            \"title\": \"Status\",\n            \"description\": \"Current service status\",\n            \"example\": \"available\"\n        },\n        \"websocket_endpoints\": {\n            \"additionalProperties\": {\n                \"type\": \"string\"\n            },\n            \"type\": \"object\",\n            \"title\": \"Websocket Endpoints\",\n            \"description\": \"Available WebSocket endpoints\",\n            \"example\": {\n                \"conversation\": \"/api/v1/realtime/conversation\",\n                \"dashboard_relay\": \"/api/v1/realtime/dashboard/relay\"\n            }\n        },\n        \"features\": {\n            \"additionalProperties\": {\n                \"type\": \"boolean\"\n            },\n            \"type\": \"object\",\n            \"title\": \"Features\",\n            \"description\": \"Supported features and capabilities\",\n            \"example\": {\n                \"conversation_streaming\": true,\n                \"dashboard_broadcasting\": true,\n                \"orchestrator_support\": true,\n                \"session_management\": true\n            }\n        },\n        \"active_connections\": {\n            \"additionalProperties\": {\n                \"type\": \"integer\"\n            },\n            \"type\": \"object\",\n            \"title\": \"Active Connections\",\n            \"description\": \"Current active connection counts\",\n            \"example\": {\n                \"conversation_sessions\": 0,\n                \"dashboard_clients\": 0\n            }\n        },\n        \"protocols_supported\": {\n            \"items\": {\n                \"type\": \"string\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Protocols Supported\",\n            \"description\": \"Supported communication protocols\",\n            \"default\": [\n                \"WebSocket\"\n            ],\n            \"example\": [\n                \"WebSocket\"\n            ]\n        },\n        \"version\": {\n            \"type\": \"string\",\n            \"title\": \"Version\",\n            \"description\": \"API version\",\n            \"default\": \"v1\",\n            \"example\": \"v1\"\n        }\n    },\n    \"type\": \"object\",\n    \"required\": [\n        \"status\",\n        \"websocket_endpoints\",\n        \"features\",\n        \"active_connections\"\n    ],\n    \"title\": \"RealtimeStatusResponse\",\n    \"description\": \"Response schema for realtime service status endpoint.\\n\\nProvides comprehensive information about the realtime communication\\nservice including availability, features, and active connections.\"\n}\n</code></pre>"},{"location":"api/api-reference/#schemas","title":"Schemas","text":""},{"location":"api/api-reference/#agentconfigupdate","title":"AgentConfigUpdate","text":"Name Type model voice"},{"location":"api/api-reference/#agentmodelupdate","title":"AgentModelUpdate","text":"Name Type deployment_id max_tokens temperature top_p"},{"location":"api/api-reference/#agentvoiceupdate","title":"AgentVoiceUpdate","text":"Name Type voice_name voice_style"},{"location":"api/api-reference/#callinitiaterequest","title":"CallInitiateRequest","text":"Name Type caller_id context target_number string"},{"location":"api/api-reference/#callinitiateresponse","title":"CallInitiateResponse","text":"Name Type call_id string message string status string target_number string"},{"location":"api/api-reference/#calllistresponse","title":"CallListResponse","text":"Name Type calls Array&lt;CallStatusResponse&gt; limit integer page integer total integer"},{"location":"api/api-reference/#callstatusresponse","title":"CallStatusResponse","text":"Name Type call_id string duration events Array&lt;&gt; participants Array&lt;&gt; status string"},{"location":"api/api-reference/#healthresponse","title":"HealthResponse","text":"Name Type active_sessions details Example: <code>{'api_version': 'v1', 'service': 'rtagent-backend'}</code> message string session_metrics status string timestamp number version string"},{"location":"api/api-reference/#httpvalidationerror","title":"HTTPValidationError","text":"Name Type detail Array&lt;ValidationError&gt;"},{"location":"api/api-reference/#mediasessionrequest","title":"MediaSessionRequest","text":"Name Type audio_format call_connection_id string channels chunk_size enable_transcription enable_vad sample_rate"},{"location":"api/api-reference/#mediasessionresponse","title":"MediaSessionResponse","text":"Name Type configuration Example: <code>{'channels': 1, 'chunk_size': 1024, 'format': 'pcm_16', 'sample_rate': 16000}</code> created_at string session_id string status string websocket_url string"},{"location":"api/api-reference/#readinessresponse","title":"ReadinessResponse","text":"Name Type checks Array&lt;ServiceCheck&gt; event_system response_time_ms number status string timestamp number"},{"location":"api/api-reference/#realtimestatusresponse","title":"RealtimeStatusResponse","text":"Name Type active_connections Example: <code>{'conversation_sessions': 0, 'dashboard_clients': 0}</code> features Example: <code>{'conversation_streaming': True, 'dashboard_broadcasting': True, 'orchestrator_support': True, 'session_management': True}</code> protocols_supported Array&lt;string&gt; status string version string websocket_endpoints Example: <code>{'conversation': '/api/v1/realtime/conversation', 'dashboard_relay': '/api/v1/realtime/dashboard/relay'}</code>"},{"location":"api/api-reference/#servicecheck","title":"ServiceCheck","text":"Name Type check_time_ms number component string details error status string"},{"location":"api/api-reference/#validationerror","title":"ValidationError","text":"Name Type loc Array&lt;&gt; msg string type string"},{"location":"api/api-reference/#websocket-endpoints","title":"WebSocket Endpoints","text":"<p>The following WebSocket endpoints provide real-time communication capabilities:</p>"},{"location":"api/api-reference/#media-streaming-websocket","title":"Media Streaming WebSocket","text":"<p>URL: <code>wss://api.domain.com/api/v1/media/stream</code></p> <p>Real-time bidirectional audio streaming for Azure Communication Services calls following ACS WebSocket protocol.</p> <p>Query Parameters: - <code>call_connection_id</code> (required): ACS call connection identifier - <code>session_id</code> (optional): Browser session ID for UI coordination</p> <p>Audio Formats: - MEDIA/TRANSCRIPTION Mode: PCM 16kHz mono (16-bit) - VOICE_LIVE Mode: PCM 24kHz mono (24-bit) for Azure OpenAI Realtime API</p> <p>Message Types: <pre><code>// Incoming audio data\n{\n  \"kind\": \"AudioData\",\n  \"audioData\": {\n    \"timestamp\": \"2025-09-28T12:00:00Z\",\n    \"participantRawID\": \"8:acs:...\",\n    \"data\": \"base64EncodedPCMAudio\",\n    \"silent\": false\n  }\n}\n\n// Outgoing audio data (bidirectional streaming)\n{\n  \"Kind\": \"AudioData\",\n  \"AudioData\": {\n    \"Data\": \"base64EncodedPCMAudio\"\n  }\n}\n</code></pre></p>"},{"location":"api/api-reference/#realtime-conversation-websocket","title":"Realtime Conversation WebSocket","text":"<p>URL: <code>wss://api.domain.com/api/v1/realtime/conversation</code></p> <p>Browser-based voice conversations with session persistence and real-time transcription.</p> <p>Query Parameters: - <code>session_id</code> (optional): Conversation session identifier for session restoration</p> <p>Features: - Real-time speech-to-text transcription - TTS audio streaming for responses - Conversation context persistence - Multi-language support</p>"},{"location":"api/api-reference/#dashboard-relay-websocket","title":"Dashboard Relay WebSocket","text":"<p>URL: <code>wss://api.domain.com/api/v1/realtime/dashboard/relay</code> </p> <p>Real-time updates for dashboard clients monitoring ongoing conversations.</p> <p>Query Parameters: - <code>session_id</code> (optional): Filter updates for specific conversation sessions</p> <p>Use Cases: - Live call monitoring and analytics - Real-time transcript viewing - Agent performance dashboards</p>"},{"location":"api/api-reference/#authentication-security","title":"Authentication &amp; Security","text":"<p>All endpoints support Azure Entra ID authentication using <code>DefaultAzureCredential</code> following Azure best practices.</p>"},{"location":"api/api-reference/#authentication-methods","title":"Authentication Methods","text":"<p>Environment Variables (Recommended for production): <pre><code># Service Principal Authentication\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\" \nexport AZURE_TENANT_ID=\"your-tenant-id\"\n</code></pre></p> <p>Azure CLI (Development): <pre><code>az login\n</code></pre></p> <p>Managed Identity (Azure deployment): - System-assigned or user-assigned managed identity - No credential management required - Automatic token refresh</p>"},{"location":"api/api-reference/#required-rbac-roles","title":"Required RBAC Roles","text":"<p>Grant these Azure roles to your service principal or managed identity:</p> Service Required Role Purpose Azure Speech Services Cognitive Services User STT/TTS operations Azure Cache for Redis Redis Cache Contributor Session state management Azure Communication Services Communication Services Contributor Call automation and media streaming Azure Storage Storage Blob Data Contributor Call recordings and artifacts Azure OpenAI Cognitive Services OpenAI User AI model inference"},{"location":"api/api-reference/#security-features","title":"Security Features","text":"<ul> <li>Credential-less authentication with managed identity</li> <li>Connection pooling with automatic token refresh</li> <li>TLS encryption for all HTTP/WebSocket connections</li> <li>Input validation and request sanitization</li> <li>Rate limiting per Azure service quotas</li> </ul>"},{"location":"api/api-reference/#configuration","title":"Configuration","text":""},{"location":"api/api-reference/#required-environment-variables","title":"Required Environment Variables","text":"<p>Azure Services Configuration: <pre><code># Azure Speech Services\nAZURE_SPEECH_REGION=eastus\nAZURE_SPEECH_RESOURCE_ID=/subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.CognitiveServices/accounts/{name}\n\n# Azure Cache for Redis\nAZURE_REDIS_HOSTNAME=your-redis.redis.cache.windows.net\nAZURE_REDIS_USERNAME=default\n\n# Azure Communication Services\nACS_ENDPOINT=https://your-acs.communication.azure.com\n</code></pre></p> <p>Application Configuration: <pre><code># Streaming Mode (affects audio processing pipeline)\nACS_STREAMING_MODE=MEDIA  # MEDIA | VOICE_LIVE | TRANSCRIPTION\n\n# Optional Settings\nAZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com  # For AI features\nAZURE_STORAGE_CONNECTION_STRING=...  # For call recordings\n</code></pre></p>"},{"location":"api/api-reference/#streaming-mode-configuration","title":"Streaming Mode Configuration","text":"<p>Controls the audio processing pipeline and determines handler selection:</p> Mode Description Audio Format Use Case <code>MEDIA</code> Default STT/TTS pipeline PCM 16kHz mono Traditional phone calls with AI orchestration <code>VOICE_LIVE</code> Azure OpenAI Realtime API PCM 24kHz mono Advanced conversational AI <code>TRANSCRIPTION</code> Real-time transcription only PCM 16kHz mono Call recording and analysis <p>\ud83d\udcd6 Reference: Complete streaming modes documentation</p>"},{"location":"api/api-reference/#performance-tuning","title":"Performance Tuning","text":"<p>Connection Pools (optional): <pre><code># Speech service connection limits\nMAX_STT_POOL_SIZE=4\nMAX_TTS_POOL_SIZE=4\n\n# Redis connection pool\nREDIS_MAX_CONNECTIONS=20\nREDIS_CONNECTION_TIMEOUT=5\n</code></pre></p> <p>Audio Processing: <pre><code># Voice Activity Detection (VAD) settings\nVAD_TIMEOUT_MS=2000  # Silence timeout\nVAD_SENSITIVITY=medium  # low | medium | high\n\n# Barge-in detection\nBARGE_IN_ENABLED=true\nBARGE_IN_THRESHOLD_MS=10  # Response time for interruption\n</code></pre></p>"},{"location":"api/api-reference/#error-handling","title":"Error Handling","text":""},{"location":"api/api-reference/#standard-error-response-format","title":"Standard Error Response Format","text":"<p>All endpoints return consistent error responses following RFC 7807:</p> <pre><code>{\n  \"detail\": \"Human-readable error description\",\n  \"status_code\": 400,\n  \"timestamp\": \"2025-09-28T12:00:00Z\",\n  \"type\": \"validation_error\",\n  \"instance\": \"/api/v1/calls/initiate\",\n  \"errors\": [\n    {\n      \"field\": \"phone_number\",\n      \"message\": \"Invalid phone number format\",\n      \"code\": \"format_invalid\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api/api-reference/#http-status-codes","title":"HTTP Status Codes","text":"Status Description Common Causes 200 Success Request completed successfully 202 Accepted Async operation initiated 400 Bad Request Invalid request format or parameters 401 Unauthorized Missing or invalid authentication 403 Forbidden Insufficient permissions or RBAC roles 404 Not Found Resource not found 422 Validation Error Request body schema validation failed 429 Rate Limited Azure service quota exceeded 500 Internal Server Error Unexpected server error 502 Bad Gateway Azure service unavailable 503 Service Unavailable Dependencies not ready 504 Gateway Timeout Azure service timeout"},{"location":"api/api-reference/#service-specific-errors","title":"Service-Specific Errors","text":"<p>Azure Speech Services: - <code>speech_quota_exceeded</code> - API rate limit reached - <code>speech_region_unavailable</code> - Speech service region down - <code>audio_format_unsupported</code> - Invalid audio format specified</p> <p>Azure Communication Services: - <code>call_not_found</code> - Call connection ID invalid - <code>media_streaming_failed</code> - WebSocket streaming error - <code>pstn_number_invalid</code> - Phone number format error</p> <p>Azure Cache for Redis: - <code>redis_connection_failed</code> - Redis cluster unavailable - <code>session_expired</code> - Session data TTL exceeded</p>"},{"location":"api/api-reference/#retry-strategy","title":"Retry Strategy","text":"<p>The API implements exponential backoff for transient errors:</p> <pre><code># Retry configuration\nRETRY_MAX_ATTEMPTS=3\nRETRY_BACKOFF_FACTOR=2.0\nRETRY_JITTER=true\n\n# Service-specific timeouts\nSPEECH_REQUEST_TIMEOUT=30\nACS_CALL_TIMEOUT=60\nREDIS_OPERATION_TIMEOUT=5\n</code></pre> <p>\ud83d\udcd6 Reference: Azure Service reliability patterns</p>"},{"location":"api/api-reference/#getting-started","title":"Getting Started","text":""},{"location":"api/api-reference/#quick-setup","title":"Quick Setup","text":"<ol> <li> <p>Configure Authentication:    <pre><code>export AZURE_TENANT_ID=\"your-tenant-id\"\nexport AZURE_CLIENT_ID=\"your-client-id\"\nexport AZURE_CLIENT_SECRET=\"your-client-secret\"\n</code></pre></p> </li> <li> <p>Set Required Environment Variables:    <pre><code>export AZURE_SPEECH_REGION=\"eastus\"\nexport ACS_ENDPOINT=\"https://your-acs.communication.azure.com\"\nexport AZURE_REDIS_HOSTNAME=\"your-redis.redis.cache.windows.net\"\n</code></pre></p> </li> <li> <p>Test Health Endpoint:    <pre><code>curl -X GET https://api.domain.com/api/v1/health/\n</code></pre></p> </li> <li> <p>Initiate a Test Call:    <pre><code>curl -X POST https://api.domain.com/api/v1/calls/initiate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"phone_number\": \"+1234567890\"}'\n</code></pre></p> </li> </ol>"},{"location":"api/api-reference/#development-resources","title":"Development Resources","text":"<ul> <li>Interactive API Explorer - Test all endpoints directly in browser</li> <li>WebSocket Testing - WebSocket connection examples</li> <li>Authentication Setup - Detailed auth configuration</li> <li>Architecture Overview - System design and deployment patterns</li> </ul>"},{"location":"api/api-reference/#production-considerations","title":"Production Considerations","text":"<ul> <li>Use managed identity authentication in Azure deployments</li> <li>Configure connection pooling for high-throughput scenarios  </li> <li>Enable distributed tracing with Azure Monitor integration</li> <li>Implement health checks for all dependent services</li> <li>Set up monitoring and alerting for service reliability</li> </ul> <p>\ud83d\udcd6 Reference: Production deployment guide</p>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":"<p>Real-Time Voice AI Accelerator</p> <p>Azure Communication Services voice agent accelerator with modular AI agents, real-time audio processing, and enterprise deployment patterns.</p>"},{"location":"architecture/#core-capabilities","title":"Core Capabilities","text":"Feature What's Included Purpose Real-time Audio ACS + Speech Services integration Voice conversation processing AI Agent Framework Modular, swappable agent system Industry-specific implementations Intelligent Barge-in Voice activity detection patterns Natural conversation flow Serverless Scaling Container Apps with auto-scaling Cost-effective, elastic hosting Development Ready Public endpoints with managed identity Quick deployment and testing <p>Deployment Architecture Options</p> <p>Current Terraform: Container Apps with public endpoints for rapid development</p> <p>Available Bicep: Enterprise production architecture with API Management, and private networking. (Advanced, WIP)</p>"},{"location":"architecture/#deployment-architecture","title":"Deployment Architecture","text":"\ud83c\udfd7\ufe0f Simplified Azure Production\ud83d\udd27 Detailed Component View\ud83c\udf99\ufe0f Voice Live Orchestration\ud83e\udde9 Dynamics IVR Bridge <p>Streamlined deployment with Container Apps and public endpoints</p> <p></p> <p>Current Terraform deployment with Container Apps, AI Foundry, and public endpoints. App Gateway, APIM, and private networking are intentionally excluded to maintain simplicity and flexibility for rapid development.</p> <p>Agent framework and processing pipeline architecture</p> <p></p> <p>Detailed view of the agent orchestration, processing components, and data flow patterns within the simplified production architecture.</p> <p>Real-time voice processing with live orchestration</p> <p></p> <p>Voice live orchestration architecture showing real-time audio processing, conversation management, and agent coordination patterns.</p> <p>Low-code intent mapping with Dynamics and ACS orchestration</p> <p></p> <p>Dynamics 365 handles IVR intent mapping and automated workflows, then performs a SIP transfer bridge into Azure Communication Services for custom real-time orchestration with the RT Agent.</p> <p>Infrastructure Deployment Approach</p> <p>The Terraform deployment intentionally excludes App Gateway, API Management, and private networking to provide a malleable foundation that consumers can extend based on their specific requirements. Production enterprise features are available through separate Bicep templates.</p> <p>Azure infrastructure with Container Apps, AI Foundry, and public endpoints</p> <p>Microsoft Learn Resources</p> <ul> <li>Azure Communication Services - Core platform</li> <li>Audio Streaming Concepts - Real-time media</li> <li>Container Apps - Serverless hosting</li> </ul> <p>Current Terraform Deployment</p> <p>Simplified Public Infrastructure - The Terraform deployment creates a streamlined development-focused architecture with public endpoints and Container Apps hosting. Advanced features like API Management, AI Gateway, private networking, and Application Gateway are available in the Bicep templates for production scenarios.</p>"},{"location":"architecture/#key-infrastructure-components","title":"Key Infrastructure Components","text":"Core Services (Terraform Deployed)Production Extensions (Bicep Available) <p>Container Apps Environment:</p> <ul> <li>Auto-scaling - KEDA-based scaling for frontend and backend containers</li> <li>Public Ingress - External endpoints for development and testing</li> <li>Managed Identity - Azure AD authentication across all services</li> <li>Application Insights - Centralized logging and monitoring</li> </ul> <p>AI Services:</p> <ul> <li>Azure AI Foundry - LLM Model hosting, unified resource for Speech/Cognitive Services</li> </ul> <p>Data Layer:</p> <ul> <li>Cosmos DB (MongoDB API) - Session and conversation storage</li> <li>Redis Enterprise - High-performance caching with RBAC</li> <li>Storage Account - Audio files and prompt storage</li> <li>Key Vault - Secure secret management</li> </ul> <p>Advanced Networking:</p> <ul> <li>Hub-spoke VNet topology with private endpoints</li> <li>Application Gateway with WAF protection  </li> <li>NSG rules and traffic control</li> </ul> <p>API Management &amp; AI Gateway:</p> <ul> <li>Token management and PTU optimization</li> <li>Load balancing and cost analytics</li> <li>Content safety and multi-region routing</li> </ul> <p>Deployment Comparison</p> <p>Terraform: Streamlined development infrastructure with public endpoints and Container Apps</p> <p>Bicep: Enterprise-grade production architecture with private networking, API Gateway, and Application Gateway</p> <p>Microsoft Learn References:</p> <ul> <li>Container Apps Architecture - Serverless hosting patterns</li> <li>AI Gateway Architecture - Advanced API management (Bicep only)</li> <li>Private Endpoint Integration - Network security patterns (Bicep only)</li> </ul>"},{"location":"architecture/#architecture-deep-dives","title":"Architecture Deep Dives","text":"Document Focus What You'll Learn LLM Orchestration AI routing and conversation management Multi-agent coordination, dependency injection patterns, orchestrator design Speech Recognition Real-time STT processing Azure Speech integration, WebSocket handling, and transcription accuracy Speech Synthesis Dynamic TTS generation Low-latency audio synthesis, voice font customization, and output streaming ACS Call Flows Three-thread voice processing Real-time audio handling, WebSocket patterns, media lifecycle Data Flows Storage and caching patterns State management, Redis coordination, Cosmos DB persistence Integrations Cross-cloud connectivity External service patterns, authentication flows"},{"location":"architecture/#quick-start-paths","title":"Quick Start Paths","text":"\ud83d\udc69\u200d\ud83d\udcbb Developers\ud83c\udfd7\ufe0f Architects\ud83d\udd27 Operations <ol> <li>Getting Started - Environment setup and prerequisites</li> <li>Local Development - Run the accelerator locally</li> <li>API Reference - Endpoints and WebSocket protocols</li> </ol> <ol> <li>Data Flow Patterns - Storage strategies and state management</li> <li>Production Deployment - Infrastructure and scaling</li> <li>Integrations Overview - External service connectivity</li> </ol> <ol> <li>Monitoring Guide - Application insights and observability</li> <li>Load Testing - Performance validation and capacity planning</li> <li>Troubleshooting - Issue resolution and debugging</li> </ol> <p>Additional Resources</p> <p>For more comprehensive guidance on development and operations:</p> <ul> <li>Repository Structure - Understand the codebase layout</li> <li>Utilities &amp; Services - Core infrastructure components</li> <li>Deployment Guide - Deploy the accelerator to Azure</li> </ul>"},{"location":"architecture/acs-flows/","title":"ACS Flows","text":""},{"location":"architecture/acs-flows/#acs-call-automation-media-flows","title":"ACS Call Automation &amp; Media Flows","text":"<p>Three-Thread Voice Processing Architecture</p> <p>Comprehensive architecture for Azure Communication Services (ACS) media handling, specifically designed for real-time voice processing with integrated barge-in detection capabilities.</p>"},{"location":"architecture/acs-flows/#azure-communication-services-integration","title":"Azure Communication Services Integration","text":"<p>Enterprise Voice Processing</p> <p>Azure Speech SDK provides continuous speech recognition optimized for real-time conversations with sub-10ms barge-in detection.</p>"},{"location":"architecture/acs-flows/#speech-recognition-capabilities","title":"Speech Recognition Capabilities","text":"Feature  Description  Accelerator Focus Real-time Processing Immediate partial and final result processing Low-latency patterns Barge-in Detection Advanced voice activity detection for interruptions Reference implementation Multiple Result Types Partial results for speed, final results for accuracy Flexible processing modes Session Management Automatic session handling with connection recovery Robust connection patterns Continuous Recognition Persistent speech-to-text processing 24/7 operation templates <p>Microsoft Learn Resources</p> <ul> <li>Audio Streaming Quickstart - Server-side audio streaming implementation</li> <li>Call Automation SDK - Automated call routing solutions</li> <li>Media Access Overview - Real-time media stream processing patterns</li> <li>Speech to Text Service - Real-time speech recognition capabilities</li> <li>Real-time Speech Recognition - Implementation patterns for continuous STT processing</li> <li>Bidirectional Audio Streaming - Two-way media streaming architecture</li> <li>WebSocket Audio Processing - Real-time audio stream handling patterns</li> </ul>"},{"location":"architecture/acs-flows/#three-thread-processing-architecture","title":"Three-Thread Processing Architecture","text":"<p>Thread Separation Strategy</p> <p>The architecture separates concerns across three dedicated threads for optimal performance and reliability.</p> graph TB     subgraph SpeechSDK[\"\ud83c\udfa4 Speech SDK Thread\"]         A1[\"Continuous Audio Recognition\"]         A2[\"on_partial \u2192 Barge-in Detection\"]         A3[\"on_final \u2192 Queue Speech Result\"]         A1 --&gt; A2         A1 --&gt; A3     end      subgraph RouteLoop[\"\ud83d\udd04 Route Turn Thread\"]         B1[\"await speech_queue.get()\"]         B2[\"Orchestrator Processing\"]         B3[\"TTS Generation &amp; Playback\"]         B1 --&gt; B2 --&gt; B3     end      subgraph MainLoop[\"\ud83c\udf10 Main Event Loop\"]         C1[\"WebSocket Media Handler\"]         C2[\"Barge-in Response\"]         C3[\"Task Cancellation\"]         C1 --&gt; C2 --&gt; C3     end      %% Cross-thread communication     A2 -.-&gt;|\"run_coroutine_threadsafe\"| C2     A3 -.-&gt;|\"queue.put_nowait\"| B1     B3 -.-&gt;|\"Task Reference\"| C1     C2 -.-&gt;|\"cancel()\"| B2      classDef speechStyle fill:#9B59B6,stroke:#6B3E99,stroke-width:2px,color:#FFFFFF     classDef routeStyle fill:#FF6B35,stroke:#E55100,stroke-width:2px,color:#FFFFFF     classDef mainStyle fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#FFFFFF      class A1,A2,A3 speechStyle     class B1,B2,B3 routeStyle     class C1,C2,C3 mainStyle"},{"location":"architecture/acs-flows/#thread-responsibilities-communication","title":"Thread Responsibilities &amp; Communication","text":""},{"location":"architecture/acs-flows/#core-design-principles","title":"Core Design Principles","text":"<p>The three-thread architecture follows these key principles:</p>"},{"location":"architecture/acs-flows/#speech-sdk-thread-never-blocks","title":"\ud83c\udfa4 Speech SDK Thread - Never Blocks","text":"<ul> <li>Continuous audio recognition using Azure Speech SDK</li> <li>Immediate barge-in detection via <code>on_partial</code> callbacks</li> <li>Cross-thread communication via <code>run_coroutine_threadsafe</code></li> <li>Performance: &lt; 10ms response time for barge-in detection</li> </ul>"},{"location":"architecture/acs-flows/#route-turn-thread-blocks-only-on-queue","title":"\ud83d\udd04 Route Turn Thread - Blocks Only on Queue","text":"<ul> <li>AI processing and response generation through orchestrator</li> <li>Queue-based serialization of conversation turns</li> <li>Safe cancellation without affecting speech recognition</li> <li>Performance: Processes one turn at a time, can be cancelled</li> </ul>"},{"location":"architecture/acs-flows/#main-event-loop-never-blocks","title":"\ud83c\udf10 Main Event Loop - Never Blocks","text":"<ul> <li>WebSocket handling for real-time media streaming</li> <li>Task cancellation for barge-in scenarios</li> <li>Non-blocking coordination between threads</li> <li>Performance: &lt; 50ms for task cancellation and stop commands</li> </ul>"},{"location":"architecture/acs-flows/#thread-performance-matrix","title":"Thread Performance Matrix","text":"Thread Primary Role Blocking Behavior Barge-in Role Response Time Speech SDK Audio recognition \u274c Never blocks \u2705 Detection &lt; 10ms Route Turn AI processing \u2705 Queue operations only \u274c None Variable Main Event WebSocket &amp; coordination \u274c Never blocks \u2705 Execution &lt; 50ms"},{"location":"architecture/acs-flows/#implementation-flow","title":"Implementation Flow","text":""},{"location":"architecture/acs-flows/#barge-in-detection-and-handling","title":"Barge-in Detection and Handling","text":"<ol> <li>User speaks during AI response:</li> <li><code>on_partial()</code> callback fires immediately (&lt; 10ms)</li> <li><code>ThreadBridge.schedule_barge_in()</code> schedules handler on main event loop</li> <li> <p><code>MainEventLoop.handle_barge_in()</code> cancels current processing</p> </li> <li> <p>Task cancellation chain:    <pre><code>on_partial() \u2192 schedule_barge_in() \u2192 cancel_current_processing() \u2192 send_stop_audio()\n</code></pre></p> </li> <li> <p>Speech finalization:</p> </li> <li><code>on_final()</code> callback queues completed speech via <code>ThreadBridge.queue_speech_result()</code></li> <li><code>RouteTurnThread</code> picks up speech from queue</li> <li>New AI processing task created for response generation</li> </ol>"},{"location":"architecture/acs-flows/#key-components","title":"Key Components","text":""},{"location":"architecture/acs-flows/#threadbridge","title":"ThreadBridge","text":"<p>Provides thread-safe communication between Speech SDK Thread and Main Event Loop: - <code>schedule_barge_in()</code> - Schedules barge-in handler execution - <code>queue_speech_result()</code> - Queues final speech for processing - Uses <code>run_coroutine_threadsafe</code> and <code>asyncio.Queue</code> for safe cross-thread communication</p>"},{"location":"architecture/acs-flows/#speechsdkthread","title":"SpeechSDKThread","text":"<p>Manages Speech SDK in dedicated background thread: - Pre-initializes <code>push_stream</code> to prevent audio data loss - Never blocks on AI processing or network operations - Provides immediate callback execution for barge-in detection</p>"},{"location":"architecture/acs-flows/#routeturnthread","title":"RouteTurnThread","text":"<p>Handles AI processing in isolated thread: - Blocks only on <code>speech_queue.get()</code> operations - Processes speech through orchestrator - Creates and manages TTS playback tasks</p>"},{"location":"architecture/acs-flows/#maineventloop","title":"MainEventLoop","text":"<p>Coordinates WebSocket operations and task management: - Handles incoming media messages and audio data - Manages barge-in interruption and task cancellation - Never blocks to ensure real-time responsiveness</p>"},{"location":"architecture/acs-flows/#non-blocking-thread-communication-sequence","title":"\ud83d\udd04 Non-Blocking Thread Communication Sequence","text":"sequenceDiagram     participant SpeechSDK as \ud83e\uddf5 Speech SDK Thread     participant MainLoop as \ud83e\uddf5 Main Event Loop     participant RouteLoop as \ud83e\uddf5 Route Turn Thread       participant ACS as \ud83d\udd0a Azure Communication Services     participant User as \ud83d\udc64 User      Note over SpeechSDK,User: \ud83c\udfb5 AI Currently Playing Audio     MainLoop-&gt;&gt;ACS: \ud83d\udd0a Streaming TTS Audio Response     ACS-&gt;&gt;User: \ud83c\udfb5 Audio Playback Active      rect rgba(255, 149, 0, 0.15)     Note over SpeechSDK,User: \ud83d\udea8 USER SPEAKS (BARGE-IN EVENT)     User-&gt;&gt;SpeechSDK: \ud83d\udde3\ufe0f Audio Input (Partial Recognition)      Note right of SpeechSDK: \u26a1 IMMEDIATE ACTION\ud83d\udeab NO BLOCKING     SpeechSDK-&gt;&gt;SpeechSDK: \ud83d\udd0d on_partial() callback triggered     end      rect rgba(255, 59, 48, 0.2)     Note over SpeechSDK,MainLoop: \ud83d\udd17 CROSS-THREAD COMMUNICATION     SpeechSDK--&gt;&gt;MainLoop: \ud83d\ude80 run_coroutine_threadsafe(_handle_barge_in_async)     Note right of SpeechSDK: \u2705 Speech thread continues NOT BLOCKED      Note over MainLoop: \ud83d\uded1 BARGE-IN HANDLER EXECUTES     MainLoop-&gt;&gt;MainLoop: \u274c playback_task.cancel()     MainLoop-&gt;&gt;MainLoop: \ud83e\uddf9 Clear route_turn_queue     MainLoop-&gt;&gt;ACS: \ud83d\uded1 Send StopAudio command     end      rect rgba(52, 199, 89, 0.15)     ACS--&gt;&gt;User: \ud83d\udd07 Audio Playback STOPPED     Note right of MainLoop: \u2705 Previous AI responsecancelled cleanly     end      rect rgba(0, 122, 255, 0.1)     Note over SpeechSDK,RouteLoop: \ud83d\udcdd USER CONTINUES SPEAKING     User-&gt;&gt;SpeechSDK: \ud83d\udde3\ufe0f Continues Speaking     SpeechSDK-&gt;&gt;SpeechSDK:  on_final() callback triggered      Note over SpeechSDK,MainLoop: \ud83d\udd17 FINAL RESULT COMMUNICATION     SpeechSDK--&gt;&gt;MainLoop:  run_coroutine_threadsafe(_handle_final_async)     MainLoop-&gt;&gt;MainLoop:  route_turn_queue.put(final_text)     Note right of SpeechSDK: \u2705 Speech thread continues\ud83d\udeab NOT BLOCKED     end      rect rgba(102, 51, 153, 0.1)     Note over RouteLoop,ACS: \ud83e\udd16 NEW AI PROCESSING     RouteLoop-&gt;&gt;RouteLoop: \ud83d\udce5 queue.get() receives final_text     Note right of RouteLoop: \u23f3 ONLY thread that blocks\ud83c\udfaf Dedicated AI processing      RouteLoop-&gt;&gt;MainLoop: \ud83c\udfb5 Create new playback_task     MainLoop-&gt;&gt;ACS: \ud83d\udd0a Send New TTS Response     ACS-&gt;&gt;User: \ud83c\udfb5 Play New AI Response     end      Note over SpeechSDK,User: \u2705 COMPLETE NON-BLOCKING CYCLE"},{"location":"architecture/acs-flows/#critical-non-blocking-characteristics","title":"\ud83d\ude80 Critical Non-Blocking Characteristics","text":"Event Thread Source Target Thread Blocking? Communication Method Response Time \ud83d\udea8 Barge-in Detection Speech SDK Main Event Loop \u274c NO <code>run_coroutine_threadsafe</code> &lt; 10ms \ud83d\udccb Final Speech Speech SDK Route Turn Thread \u274c NO <code>asyncio.Queue.put()</code> &lt; 5ms \ud83c\udfb5 AI Processing Route Turn Main Event Loop \u274c NO <code>asyncio.create_task</code> &lt; 1ms \ud83d\uded1 Task Cancellation Main Event Loop Playback Task \u274c NO <code>task.cancel()</code> &lt; 1ms <p>\ud83c\udfaf Key Insight: Only the Route Turn Thread blocks (on <code>queue.get()</code>), ensuring Speech SDK and Main Event Loop remain responsive for real-time barge-in detection.</p>"},{"location":"architecture/acs-flows/#key-implementation-details","title":"Key Implementation Details","text":"<p>This section provides concrete implementation specifics for developers working with the ACS Media Handler threading architecture.</p>"},{"location":"architecture/acs-flows/#barge-in-detection","title":"\ud83d\udea8 Barge-In Detection","text":"<ul> <li>Trigger: <code>on_partial</code> callback from Speech Recognizer detects user speech</li> <li>Immediate Action: Synchronous cancellation of <code>playback_task</code> using <code>asyncio.Task.cancel()</code></li> <li>Stop Signal: Send <code>{\"Kind\": \"StopAudio\", \"StopAudio\": {}}</code> JSON command to ACS via WebSocket</li> <li>Logging: Comprehensive logging with emojis for real-time debugging</li> </ul>"},{"location":"architecture/acs-flows/#async-background-task-management","title":"\ud83d\udd04 Async Background Task Management","text":"<ul> <li>Route Turn Queue: Serializes final speech processing using <code>asyncio.Queue()</code></li> <li>Playback Task: Tracks current AI response generation/playback with <code>self.playback_task</code></li> <li>Task Lifecycle: Clean creation, cancellation, and cleanup of background tasks</li> <li>Cancellation Safety: Proper <code>try/except asyncio.CancelledError</code> handling</li> </ul>"},{"location":"architecture/acs-flows/#stop-audio-signal-protocol","title":"\ud83d\uded1 Stop Audio Signal Protocol","text":"<p><pre><code>{\n  \"Kind\": \"StopAudio\",\n  \"AudioData\": null,\n  \"StopAudio\": {}\n}\n</code></pre> This JSON message is sent to ACS to immediately halt any ongoing audio playback.</p>"},{"location":"architecture/acs-flows/#error-handling-resilience","title":"\u26a1 Error Handling &amp; Resilience","text":"<ul> <li>Event Loop Detection: Graceful handling when no event loop is available</li> <li>WebSocket Validation: Connection state checks before sending messages</li> <li>Task Cancellation: Proper cleanup with <code>await task</code> after cancellation</li> <li>Queue Management: Full queue detection and message dropping strategies</li> </ul>"},{"location":"architecture/acs-flows/#performance-optimizations","title":"\ud83d\udcca Performance Optimizations","text":"<ul> <li>Immediate Cancellation: Barge-in triggers instant playback stop (&lt; 50ms)</li> <li>Background Processing: Non-blocking AI response generation</li> <li>Memory Management: Proper task cleanup prevents memory leaks</li> <li>Concurrent Safety: Thread-safe queue operations for speech processing</li> </ul>"},{"location":"architecture/data-flows/","title":"Data Flows","text":""},{"location":"architecture/data-flows/#data-architecture-flow-patterns","title":"Data Architecture &amp; Flow Patterns","text":"<p>Three-Tier Data Architecture</p> <p>Sophisticated data architecture optimized for real-time voice processing at scale with hierarchical key organization, intelligent caching, and seamless data persistence for Azure Communication Services calls.</p>"},{"location":"architecture/data-flows/#architecture-overview","title":"Architecture Overview","text":"<p>Performance-Optimized Storage Strategy</p> <p>The system employs a strategic three-tier data storage hierarchy optimized for different access patterns and performance requirements.</p>"},{"location":"architecture/data-flows/#storage-hierarchy","title":"Storage Hierarchy","text":"Tier  Access Time  Use Cases  Capacity \ud83d\udd25 Application Memory Microseconds Active call state, audio buffers, real-time metrics Limited by RAM \u26a1 Redis Enterprise Sub-second Conversation context, session history, worker affinity 10GB - 1TB \ud83d\udcda Cosmos DB 1-5 seconds Persistent conversations, analytics, audit logs Unlimited <p>Microsoft Learn Resources</p> <ul> <li>Azure Cache for Redis Overview - High-performance in-memory data store</li> <li>Azure Cosmos DB Use Cases - NoSQL database for modern applications</li> <li>Azure Redis Key Scenarios - Session store and caching patterns</li> </ul> flowchart TD     subgraph Memory [\"\ud83d\udd25 Application Memory (ms access)\"]         A[\"Active Call State\"]         B[\"Audio Buffers\"]         C[\"Real-time Metrics\"]         D[\"Connection Pools\"]         E[\"Cached Prompts\"]     end      subgraph Redis [\"\u26a1 Redis Enterprise (sub-second access)\"]         F[\"Conversation Context\"]         G[\"Session History\"]         H[\"Worker Affinity\"]         I[\"Authentication State\"]         J[\"TTS Cache\"]     end      subgraph Cosmos [\"\ud83d\udcbe Cosmos DB (permanent storage)\"]         K[\"Call Transcripts\"]         L[\"User Profiles\"]         M[\"Analytics Data\"]         N[\"Audit Logs\"]         O[\"System Metrics\"]     end      A --&gt; F     B --&gt; F     F --&gt; K     G --&gt; L     I --&gt; L      classDef memoryNode fill:#FF5722,stroke:#D84315,stroke-width:2px,color:#fff     classDef redisNode fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff     classDef cosmosNode fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff      class A,B,C,D,E memoryNode     class F,G,H,I,J redisNode     class K,L,M,N,O cosmosNode"},{"location":"architecture/data-flows/#storage-decision-matrix","title":"Storage Decision Matrix","text":"Data Type Memory Redis Cosmos Access Pattern Reasoning WebSocket Connections \u2705 \u274c \u274c High throughput Process-specific, ultra-low latency Audio Buffers \u2705 \u274c \u274c Real-time High-frequency, temporary Conversation Context \u274c \u2705 \u274c 10-50 ops/sec Session persistence, shared workers TTS Cache \u274c \u2705 \u274c Variable Shared across calls, time-limited Call Transcripts \u274c \u274c \u2705 1-10 ops/min Permanent record, analytics User Profiles \u274c \ud83d\udd04 \u2705 Low frequency Long-term, complex queries <p>Legend: \u2705 Primary storage, \ud83d\udd04 Cached copy, \u274c Not stored</p>"},{"location":"architecture/data-flows/#storage-layer-characteristics","title":"Storage Layer Characteristics","text":""},{"location":"architecture/data-flows/#application-memory-milliseconds","title":"\ud83d\udd25 Application Memory (Milliseconds)","text":"<ul> <li>Purpose: Ultra-low latency data for active calls</li> <li>Examples: Audio buffers, WebSocket connections, real-time metrics</li> <li>Lifespan: Seconds to minutes (call duration)</li> <li>Access: 100+ ops/second per call</li> <li>Recovery: Non-recoverable, rebuilt on restart</li> </ul>"},{"location":"architecture/data-flows/#redis-enterprise-sub-second","title":"\u26a1 Redis Enterprise (Sub-second)","text":"<ul> <li>Purpose: Session-scoped data shared across workers</li> <li>Examples: Conversation context, authentication state, TTS cache</li> <li>Lifespan: Minutes to hours (15min - 7 days TTL)</li> <li>Access: 10-50 ops/second per call</li> <li>Recovery: Critical, survives restarts</li> </ul> <p>\ud83d\udcda Microsoft Learn Resources: - Azure Cache for Redis Reliability - Best practices for enterprise Redis deployment - Redis Session Store Pattern - Session management and caching strategies</p>"},{"location":"architecture/data-flows/#cosmos-db-permanent","title":"\ud83d\udcbe Cosmos DB (Permanent)","text":"<ul> <li>Purpose: Long-term storage, analytics, compliance</li> <li>Examples: Call transcripts, user profiles, audit logs</li> <li>Lifespan: Days to years (policy-driven retention)</li> <li>Access: 1-10 ops/minute for active calls</li> <li>Recovery: Permanent system of record</li> </ul> <p>\ud83d\udcda Microsoft Learn Resources: - Global Data Distribution with Cosmos DB - Multi-region replication and consistency - Azure Cosmos DB for NoSQL - Document storage with SQL-like queries</p>"},{"location":"architecture/data-flows/#redis-key-architecture","title":"Redis Key Architecture","text":""},{"location":"architecture/data-flows/#hierarchical-key-structure","title":"Hierarchical Key Structure","text":"<pre><code>{app_prefix}:{environment}:{data_type}:{identifier}:{component}\n</code></pre> <p>Examples: - <code>rtvoice:prod:call:call-connection-id-1234:session</code> - <code>rtvoice:prod:conversation:session-id-5678:context</code> - <code>rtvoice:dev:worker:worker-abc123:affinity</code></p>"},{"location":"architecture/data-flows/#ttl-management-strategy","title":"TTL Management Strategy","text":"<pre><code>TTL_POLICIES = {\n    \"conversation_context\": 30 * 60,      # 30 minutes\n    \"session_history\": 2 * 60 * 60,       # 2 hours\n    \"authentication_state\": 15 * 60,      # 15 minutes\n    \"tts_cache\": 24 * 60 * 60,           # 24 hours\n    \"call_summary\": 7 * 24 * 60 * 60,    # 7 days (analytics)\n}\n</code></pre>"},{"location":"architecture/data-flows/#implementation-patterns","title":"Implementation Patterns","text":""},{"location":"architecture/data-flows/#core-components","title":"Core Components","text":"<ol> <li>RedisKeyManager: Hierarchical key structure and TTL management</li> <li>AsyncAzureRedisManager: High-level async operations for conversation and call management  </li> <li>ConversationManager: Conversation state with automatic legacy migration</li> </ol>"},{"location":"architecture/data-flows/#usage-examples","title":"Usage Examples","text":"<pre><code># ACS Call Session Setup\nasync def handle_call_connected(call_connection_id: str):\n    session_key = redis_manager.key_manager.call_key(call_connection_id, Component.SESSION)\n    await redis_manager.store_call_session(call_connection_id, session_data)\n\n# Conversation Management with ConversationManager\nasync def setup_conversation(session_id: str = None):\n    cm = ConversationManager(session_id=session_id, environment=\"prod\")\n    cm = await ConversationManager.from_redis(session_id, redis_mgr)\n    await cm.update_context({\"user_authenticated\": True})\n    await cm.append_to_history(\"user\", \"Hello\")\n\n# TTS Caching\nasync def cache_tts_response(phrase_hash: str, audio_data: bytes):\n    key = f\"rtvoice:prod:cache:tts:{phrase_hash}\"\n    await redis_manager.set_binary(key, audio_data, ttl=86400)\n</code></pre>"},{"location":"architecture/data-flows/#complete-call-lifecycle-flow","title":"Complete Call Lifecycle Flow","text":"sequenceDiagram     participant ACS as Azure Communication Services     participant Memory as App Memory     participant CM as ConversationManager     participant Redis as Redis Cache     participant AI as AI Service     participant Cosmos as Cosmos DB      Note over ACS,Cosmos: Call Initialization     ACS-&gt;&gt;Memory: CallConnected Event     Memory-&gt;&gt;CM: new ConversationManager(call_connection_id)     CM-&gt;&gt;Redis: Initialize session context      Note over ACS,Cosmos: Active Conversation     loop Conversation Turns         ACS-&gt;&gt;Memory: User audio stream         Memory-&gt;&gt;CM: from_redis() - load state         CM-&gt;&gt;Redis: Get conversation context &amp; history          alt TTS Cache Hit             Redis-&gt;&gt;Memory: Return cached audio         else Cache Miss             CM-&gt;&gt;AI: Generate response             Memory-&gt;&gt;Redis: Cache TTS audio         end          CM-&gt;&gt;Redis: persist conversation state         Memory-&gt;&gt;ACS: Stream audio response         Memory-&gt;&gt;Cosmos: Queue transcript (async)     end      Note over ACS,Cosmos: Call Completion &amp; Archival     ACS-&gt;&gt;Memory: CallDisconnected Event     Memory-&gt;&gt;CM: Get final state     CM-&gt;&gt;Cosmos: Store complete transcript     CM-&gt;&gt;Cosmos: Update user profile     Memory-&gt;&gt;Memory: Cleanup call state"},{"location":"architecture/data-flows/#best-practices-configuration","title":"Best Practices &amp; Configuration","text":""},{"location":"architecture/data-flows/#key-design-principles","title":"Key Design Principles","text":"<ul> <li>Use <code>call_connection_id</code> as session_id for ACS calls (no random UUIDs)</li> <li>Batch Redis operations for performance (pipeline transactions)</li> <li>Implement graceful degradation with fallback mechanisms</li> <li>Monitor TTL expiration for critical session data</li> <li>Use async operations throughout for non-blocking performance</li> </ul>"},{"location":"architecture/data-flows/#monitoring-production-readiness","title":"Monitoring &amp; Production Readiness","text":""},{"location":"architecture/data-flows/#key-performance-metrics-baselines","title":"Key Performance Metrics &amp; Baselines","text":"<p>Latency Baselines (Production SLA):</p> <ul> <li>Redis operations: p99 &lt; 5ms, p95 &lt; 2ms</li> <li>Memory-to-Redis persistence: &lt; 10ms</li> <li>Redis-to-Cosmos archival: &lt; 100ms</li> <li>End-to-end call setup: &lt; 500ms</li> </ul> <p>Operational Metrics:</p> <ul> <li>Key creation rate: Monitor spikes (&gt;1000 keys/min indicates issues)</li> <li>TTL distribution: Alert on keys without TTL (potential memory leaks)</li> <li>Memory usage: Alert at 70% Redis memory capacity</li> <li>Connection pool exhaustion: Alert on &gt;80% pool utilization</li> <li>Failed operations: Alert on &gt;1% error rate per 5-minute window</li> </ul>"},{"location":"architecture/data-flows/#production-alerting-strategy","title":"Production Alerting Strategy","text":"Priority Alert Type Trigger Conditions Response Time Examples \ud83d\udea8 P0 - Critical Infrastructure Failure \u2022 Redis unavailability &gt;30s\u2022 Memory usage &gt;85% (OOM risk)\u2022 Call setup failures &gt;5% in 2 minutes\u2022 Security breach detection Immediate PagerDuty escalationOn-call engineer responseAuto-failover procedures \u26a0\ufe0f P1 - Warning Performance Degradation \u2022 Latency p95 &gt;5ms for 10+ minutes\u2022 TTL policy violations detected\u2022 Key growth +50% in 1 hour\u2022 Authentication failure spikes Next Business Day Email notificationsEngineering team reviewCapacity planning review \ud83d\udcca P2 - Informational Operational Insights \u2022 Capacity planning metrics\u2022 Usage pattern analysis\u2022 Performance trend reports\u2022 Routine health summaries Weekly Review Dashboard reportsQuarterly business reviewsArchitecture optimization"},{"location":"architecture/data-flows/#alert-configuration-details","title":"Alert Configuration Details","text":"<pre><code># P0 Critical Alert Thresholds\nredis_availability:\n    threshold: \"availability degradation for 30 seconds\"\n    escalation: \"page on-call immediately\"\n\nmemory_pressure:\n    threshold: \"memory_usage &gt; 85%\"\n    action: \"trigger auto-scaling + immediate alert\"\n\ncall_failure_rate:\n    threshold: \"failed_calls / total_calls &gt; 0.05 over 2 minutes\"\n    severity: \"business_critical\"\n\n# P1 Warning Alert Configuration  \nperformance_degradation:\n    latency_p95: \"&gt; 5ms for 10 consecutive minutes\"\n    ttl_violations: \"keys without TTL &gt; 100\"\n    growth_anomaly: \"key_count increase &gt; 50% in 1 hour\"\n</code></pre>"},{"location":"architecture/data-flows/#security-compliance-framework","title":"Security &amp; Compliance Framework","text":"<p>Infrastructure Security:</p> <ul> <li>Network: Private endpoints, VNet integration, no public Redis access</li> <li>Authentication: Azure Managed Identity for service-to-service auth</li> <li>Encryption: TLS 1.3 in transit, customer-managed keys at rest</li> <li>Access Control: RBAC with principle of least privilege</li> <li>Audit: All Redis operations logged with correlation IDs</li> </ul> <p>Data Protection &amp; PII Handling: <pre><code># PII Encryption Strategy\nENCRYPTED_FIELDS = {\n    \"conversation_context\": [\"user_id\", \"phone_number\", \"session_metadata\"],\n    \"call_transcripts\": [\"transcript\", \"participant_info\"],\n    \"user_profiles\": [\"personal_data\", \"preferences\"]\n}\n\n# Automatic PII Detection &amp; Masking\nasync def store_conversation_context(context: dict):\n    masked_context = await pii_detector.mask_sensitive_data(context)\n    encrypted_context = await crypto_service.encrypt_fields(masked_context, ENCRYPTED_FIELDS)\n    await redis_manager.set_json(key, encrypted_context, ttl=TTL_POLICIES[\"conversation_context\"])\n</code></pre></p> <p>Compliance Controls:</p> Requirement Implementation Monitoring Data Retention (GDPR) Automated TTL enforcement, scheduled purge jobs Daily retention compliance reports Right to Erasure <code>delete_user_data()</code> API with cascade deletion Audit log of deletion requests Data Minimization PII detection, automatic field masking Weekly PII exposure scans Breach Notification Real-time security event monitoring 72-hour breach notification workflow"},{"location":"architecture/data-flows/#operational-runbooks","title":"Operational Runbooks","text":"<p>Incident Response Procedures:</p> <ol> <li> <p>Redis Performance Degradation:    <pre><code># Check cluster health\naz redis show --resource-group $RG --name $REDIS_NAME\n\n# Monitor key distribution\nredis-cli --scan --pattern \"rtvoice:prod:*\" | wc -l\n\n# Check TTL compliance\nredis-cli eval \"return redis.call('keys', 'rtvoice:prod:*')\" 0 | xargs -I {} redis-cli TTL {}\n</code></pre></p> </li> <li> <p>Security Incident Response:</p> <ul> <li>Immediate: Rotate Redis access keys</li> <li>Within 1 hour: Audit all active sessions</li> <li>Within 24 hours: Security assessment report</li> <li>Within 72 hours: Compliance notification if required</li> </ul> </li> </ol>"},{"location":"architecture/data-flows/#capacity-planning","title":"Capacity Planning","text":"<ul> <li>Memory: Scale Redis cluster at 70% utilization</li> <li>Connections: Monitor connection pool metrics, scale at 80%</li> <li>Throughput: Baseline 10K ops/sec per shard, alert on degradation</li> </ul>"},{"location":"architecture/data-flows/#health-check-implementation","title":"Health Check Implementation","text":"<pre><code>async def comprehensive_health_check():\n    \"\"\"Multi-tier health validation for production readiness\"\"\"\n    health_status = {\n        \"redis_connectivity\": await test_redis_connection(),\n        \"memory_usage\": await check_redis_memory(),\n        \"key_expiration_compliance\": await audit_ttl_policies(),\n        \"encryption_validation\": await verify_pii_encryption(),\n        \"performance_baseline\": await measure_operation_latency(),\n        \"security_posture\": await validate_security_controls()\n    }\n\n    # Aggregate health score for load balancer\n    overall_health = all(health_status.values())\n    return {\"status\": \"healthy\" if overall_health else \"degraded\", \"details\": health_status}\n</code></pre> <p>Production Deployment Checklist:</p> <ul> <li>[ ] Redis cluster provisioned with HA configuration</li> <li>[ ] Private endpoints configured (no public access)</li> <li>[ ] Monitoring dashboards deployed (Azure Monitor + custom metrics)</li> <li>[ ] Alert rules configured for all critical thresholds</li> <li>[ ] Security scanning completed (vulnerability assessment)</li> <li>[ ] Compliance validation passed (data classification, retention policies)</li> <li>[ ] Disaster recovery tested (backup/restore procedures)</li> <li>[ ] Performance load testing completed (10x expected traffic)</li> <li>[ ] Incident response runbooks validated</li> </ul>"},{"location":"architecture/integrations/","title":"Integrations","text":""},{"location":"architecture/integrations/#telephony-integration-with-existing-ivr-systems","title":"Telephony Integration with Existing IVR Systems","text":"<p>Connecting Your Contact Center to Azure</p> <p>This guide provides a detailed architecture for integrating an existing on-premises or cloud-based telephony system (PBX, IVR, Contact Center) with this accelerator. By leveraging Azure Communication Services (ACS) Direct Routing and a certified Session Border Controller (SBC), you can seamlessly route calls to the AI voice agent while preserving your existing carrier relationships and infrastructure.</p>"},{"location":"architecture/integrations/#core-concept-acs-direct-routing","title":"Core Concept: ACS Direct Routing","text":"<p>ACS Direct Routing is the key technology that enables a \"Bring Your Own Carrier\" (BYOC) model. It allows you to connect your own telephony trunks to Azure Communication Services through a certified SBC. This is the ideal pattern for enterprises that want to augment their existing contact center with Azure's advanced AI and voice capabilities without replacing their entire telephony infrastructure.</p> <p>Official Microsoft Documentation</p> <ul> <li>Azure Communication Services Direct Routing</li> <li>Infrastructure Requirements for Direct Routing</li> <li>List of Certified Session Border Controllers (SBCs)</li> </ul>"},{"location":"architecture/integrations/#integration-architecture-call-flow","title":"Integration Architecture &amp; Call Flow","text":"<p>The following diagram illustrates how a call is routed from an existing IVR system to the Azure-based voice agent and potentially back to a human agent queue.</p> graph LR     subgraph YourInfra [Your Infrastructure]         PSTN[\ud83d\udcde PSTN]         Carrier[\ud83c\udfe2 Telecom Carrier]         IVR[\ud83e\udd16 IVR / Contact Center]         PSTN --&gt; Carrier         Carrier --&gt; IVR     end      subgraph DMZEdge [DMZ / Network Edge]         SBC[\ud83d\udee1\ufe0f Session Border Controller]     end      subgraph AzureCloud [Azure Cloud]         ACS[\ud83c\udf10 ACS Direct Routing]         AgentBackend[\ud83d\udcf1 Voice Agent Backend]         ACS --&gt;|3 Webhook Event| AgentBackend         AgentBackend --&gt;|4 WebSocket Media| ACS     end      IVR --&gt;|1 SIP Transfer| SBC     SBC --&gt;|2 SIP over TLS| ACS     AgentBackend --&gt;|5 Initiate Transfer| ACS     ACS --&gt;|6 Route back| SBC     SBC --&gt;|7 Transfer to Queue| IVR      classDef yourinfra fill:#f9f9f9,stroke:#333,stroke-width:2px     classDef azurecloud fill:#eaf5ff,stroke:#0078d4,stroke-width:2px     class IVR,Carrier,PSTN yourinfra     class ACS,AgentBackend azurecloud"},{"location":"architecture/integrations/#call-flow-steps","title":"Call Flow Steps","text":"<ol> <li>Initial Call &amp; IVR Handling: A customer calls a number that routes to your existing carrier and is answered by your current IVR or contact center platform.</li> <li>Transfer to AI Agent: Based on a menu selection or business logic, the IVR decides to transfer the call to the AI voice agent. It initiates a SIP transfer (INVITE) to a pre-configured number that points to the SBC. Custom SIP headers can be added here to pass context (e.g., customer ID, reason for call).</li> <li>SBC to ACS Routing: The SBC receives the SIP INVITE, validates it, and forwards it securely over TLS to the ACS Direct Routing interface.</li> <li>ACS to Voice Agent Backend: ACS receives the call and triggers a webhook (<code>IncomingCall</code>) to the voice agent backend. The backend answers the call and establishes a real-time media stream over WebSockets.</li> <li>AI Conversation: The voice agent backend processes the audio stream in real-time, using Azure Speech for transcription/synthesis and Azure OpenAI for responses.</li> <li>Escalation to Human: If the AI agent determines a human is needed, the backend uses the ACS Call Automation SDK to initiate a transfer. This sends a SIP REFER message back to the original IVR/contact center via the SBC.</li> <li>Return to IVR/Agent Queue: The SBC routes the call back to your contact center, placing the customer in a queue for a human agent, passing along any new context gathered by the AI.</li> </ol>"},{"location":"architecture/integrations/#configuration-steps","title":"Configuration Steps","text":"<p>Integrating your existing telephony requires a few key configuration steps, primarily centered around the SBC and ACS.</p> Step 1: PrerequisitesStep 2: Connect the SBC to ACSStep 3: Contextual Call Transfer (IVR to AI)Step 4: Escalation &amp; Transfer (AI to Human) <p>Before You Begin</p> <p>Ensure you have the following in place before attempting integration:</p> <ul> <li>A Certified SBC: Your Session Border Controller must be on the list of SBCs certified for ACS Direct Routing.</li> <li>Public IP and FQDN for SBC: The SBC must have a public IP address and a Fully Qualified Domain Name (FQDN).</li> <li>Publicly Trusted Certificate: The FQDN for the SBC must have a valid, publicly signed TLS certificate. Wildcard certificates are supported.</li> <li>Verified Domain: You must add and verify the SBC's domain name within your Azure Communication Services resource. See Validate Domain Ownership.</li> </ul> <p>Once the prerequisites are met, you connect your SBC to ACS. This process pairs the SBC with your ACS resource, making it a valid gateway for SIP traffic.</p> <ol> <li>Add the SBC in Azure: In the Azure portal, navigate to your Communication Services resource and select Direct routing under \"Voice Calling - PSTN\". Add your SBC's FQDN and signaling port.</li> <li>Configure Voice Routes: Create outbound voice routing rules that determine how calls are sent. For a simple setup, you can create a rule that sends all calls to your newly added SBC.</li> <li>Verify Connection: After configuration, the SBC status should appear as \"Online\" in the Azure portal. This is verified by a successful exchange of SIP OPTIONS messages between ACS and your SBC.</li> </ol> <p>Troubleshooting SBC Connectivity</p> <p>If the SBC does not come online, refer to the official SBC Connectivity Issues Troubleshooting Guide. Common issues relate to TLS certificates or firewall misconfigurations.</p> <p>To make the handoff from your IVR to the AI agent intelligent, you need to pass contextual data. This is typically done using custom SIP headers.</p> <ul> <li>In your IVR/PBX: When initiating the transfer to the SBC, add custom SIP headers to the INVITE message. A common practice is to use <code>X-</code> prefixed headers.   <pre><code>INVITE sip:+18005551234@sbc.yourcompany.com SIP/2.0\n...\nX-Customer-ID: 12345\nX-Transfer-Reason: BillingInquiry\n...\n</code></pre></li> <li>In the Voice Agent Backend: The ACS Call Automation SDK delivers these headers to your application as part of the <code>IncomingCall</code> event payload. You can access them to inform the agent's initial greeting or actions.   <pre><code># Example in your event handler\nif event.type == \"Microsoft.Communication.IncomingCall\":\n    call_connection_id = event.data.get(\"callConnectionId\")\n    custom_headers = event.data.get(\"customHeaders\", {})\n    customer_id = custom_headers.get(\"X-Customer-ID\")\n\n    # Use customer_id to fetch customer data before answering\n    await answer_call_with_context(call_connection_id, customer_id)\n</code></pre></li> </ul> <p>When the AI agent needs to escalate to a human, it uses the <code>transfer</code> action from the ACS Call Automation SDK.</p> <ul> <li>The target of the transfer is a phone number corresponding to a human agent queue in your original contact center.</li> <li>You can again pass context, this time from the AI conversation, back to the contact center using custom SIP headers.</li> </ul> <p><pre><code># Example of transferring a call back to a human agent queue\nfrom azure.communication.callautomation import CallAutomationClient, SipHeaders\n\n# ... inside your agent logic\n\ntarget_pstn_number = \"+18005559876\" # Your human agent queue number\n\ncustom_context = SipHeaders(\n    custom_headers={\n        \"X-AI-Summary\": \"Customer confirmed identity and wants to dispute a charge.\"\n    }\n)\n\nawait call_automation_client.transfer_call(\n    call_connection_id=call_connection_id,\n    target_participant=PhoneNumberIdentifier(target_pstn_number),\n    custom_context=custom_context\n)\n</code></pre> This sends a SIP REFER message back through the SBC, instructing your telephony system to route the call to the specified number, with the AI-generated summary included in the SIP headers for your agent desktop to display.</p>"},{"location":"architecture/llm-orchestration/","title":"LLM Orchestration","text":""},{"location":"architecture/llm-orchestration/#llm-orchestration-architecture","title":"LLM Orchestration Architecture","text":"<p>Agent-Based Conversation Orchestration</p> <p>Two distinct orchestration approaches: Custom Multi-Agent with local dependency injection and Voice Live API with Azure AI Foundry-managed orchestration.</p>"},{"location":"architecture/llm-orchestration/#orchestration-approaches","title":"Orchestration Approaches","text":"\ud83c\udfaf Custom Multi-Agent (MEDIA/TRANSCRIPTION)\u26a1 Voice Live API (VOICE_LIVE) <p>Local orchestration with full developer control</p> <ul> <li>Orchestration: Local dependency injection and agent registry</li> <li>Configuration: YAML-based agent definitions (ARTAgent + FoundryAgent)</li> <li>Tools: Custom function calling and business logic</li> <li>Control: Complete customization of conversation flow</li> <li>Implementation: Fully implemented with examples</li> </ul> <p>Azure AI Foundry-managed orchestration for simplified deployment</p> <p>Implementation Status</p> <p>Voice Live orchestration is offloaded to Azure AI Foundry agents. Local orchestration (dependency injection, agent registry) described in this document applies only to Custom Multi-Agent modes.</p> <p>LVAgent integration (see <code>apps/rtagent/backend/src/agents/Lvagent/</code> directory) is pending full implementation.</p> <ul> <li>Orchestration: Managed by Azure AI Foundry (not local)</li> <li>Configuration: Azure AI agent configurations</li> <li>Tools: Azure AI native capabilities</li> <li>Control: Configuration-driven through Azure portal</li> <li>Implementation: LVAgent framework in development</li> </ul>"},{"location":"architecture/llm-orchestration/#dependency-injection-pattern","title":"Dependency Injection Pattern","text":"<p>Scope: Custom Multi-Agent Orchestration Only</p> <p>The dependency injection, agent registry, and orchestration patterns described below apply only to Custom Multi-Agent modes (MEDIA/TRANSCRIPTION).</p> <p>Voice Live API orchestration is handled entirely by Azure AI Foundry agents - see <code>apps/rtagent/backend/src/agents/Lvagent/</code> for the integration layer.</p> <p>Simple Function-Based Orchestration:</p> apps/rtagent/backend/api/v1/dependencies/orchestrator.py<pre><code>def get_orchestrator() -&gt; callable:\n    \"\"\"FastAPI dependency provider for conversation orchestrator.\"\"\"\n    return route_conversation_turn\n\nasync def route_conversation_turn(cm, transcript, ws, **kwargs):\n    \"\"\"Route conversation through agent registry with error handling.\"\"\"\n    await route_turn(cm=cm, transcript=transcript, ws=ws, is_acs=True)\n</code></pre> <p>Usage in Endpoints:</p> apps/rtagent/backend/api/v1/endpoints/media.py<pre><code>@router.websocket(\"/stream\")\nasync def acs_media_stream(websocket: WebSocket):\n    orchestrator = get_orchestrator()  # Inject orchestrator function\n\n    handler = await _create_media_handler(\n        orchestrator=orchestrator,  # Pass to handler\n        # ... other params\n    )\n</code></pre> <p>Plug-and-Play Orchestration:</p> Swappable Orchestration Strategies<pre><code>def get_orchestrator() -&gt; callable:\n    # return route_conversation_turn      # Default ARTAgent routing  \n    # return route_turn_for_fnol         # Insurance-specific routing\n    # return custom_conversation_handler # Custom business logic\n    return route_conversation_turn\n</code></pre>"},{"location":"architecture/llm-orchestration/#agent-configuration-system","title":"Agent Configuration System","text":""},{"location":"architecture/llm-orchestration/#artagent-framework-yaml-driven","title":"ARTAgent Framework (YAML-Driven)","text":"<p>Authentication Agent Configuration</p> apps/rtagent/backend/src/agents/artagent/agent_store/auth_agent.yaml<pre><code>agent:\n  name: AuthAgent\n  description: Handles caller authentication and routing\n\nmodel:\n  deployment_id: gpt-4o\n  temperature: 1\n  max_completion_tokens: 2040\n\nvoice:\n  name: en-US-Ava:DragonHDLatestNeural\n  style: chat\n  rate: \"+5%\"  # Slower for authentication clarity\n\nprompts:\n  path: voice_agent_authentication.jinja\n\ntools:\n  - authenticate_caller\n  - escalate_emergency\n  - escalate_human\n</code></pre> <p>Claims Intake Agent Configuration</p> apps/rtagent/backend/src/agents/artagent/agent_store/claim_intake_agent.yaml<pre><code>agent:\n  name: FNOLIntakeAgent\n  description: First Notice of Loss claim processing\n\nmodel:\n  deployment_id: gpt-4o\n  temperature: 0.60\n\nvoice:\n  name: en-US-Andrew2:DragonHDLatestNeural\n  rate: \"+10%\"  # Faster for efficient data collection\n\ntools:\n  - record_fnol\n  - authenticate_caller\n  - escalate_emergency\n  - handoff_general_agent\n</code></pre>"},{"location":"architecture/llm-orchestration/#foundryagent-framework-instructions-based","title":"FoundryAgent Framework (Instructions-Based)","text":"<p>Customer Service Agent Configuration</p> apps/rtagent/backend/src/agents/foundryagents/agent_store/customer_service_agent.yaml<pre><code>agent:\n  name: CustomerServiceAgent\n  instructions: |\n    Professional customer service agent for e-commerce company.\n    Help customers resolve inquiries quickly and accurately.\n\nmodel:\n  deployment_id: gpt-4o\n\ntools:\n  - check_order_status\n  - search_knowledge_base\n  - create_support_ticket\n  - escalate_to_human\n</code></pre>"},{"location":"architecture/llm-orchestration/#agent-registry-system","title":"Agent Registry System","text":"<p>Dynamic Agent Registration:</p> apps/rtagent/backend/src/orchestration/artagent/registry.py<pre><code># Registry for pluggable agents\n_REGISTRY: Dict[str, AgentHandler] = {}\n\ndef register_specialist(name: str, handler: AgentHandler) -&gt; None:\n    \"\"\"Register an agent handler under a name.\"\"\"\n    _REGISTRY[name] = handler\n\ndef get_specialist(name: str) -&gt; Optional[AgentHandler]:\n    \"\"\"Lookup a registered agent handler.\"\"\" \n    return _REGISTRY.get(name)\n</code></pre> <p>Agent Lookup Flow:</p> apps/rtagent/backend/src/orchestration/artagent/orchestrator.py<pre><code>async def route_turn(cm, transcript, ws, *, is_acs: bool):\n    # 1. Check active agent from memory\n    active_agent = cm.get_context(\"active_agent\", \"General\")\n\n    # 2. Get handler from registry\n    handler = get_specialist(active_agent)\n\n    # 3. Execute specialized processing\n    if handler:\n        await handler(cm, transcript, ws, is_acs=is_acs)\n    else:\n        await fallback_handler(cm, transcript, ws, is_acs=is_acs)\n</code></pre>"},{"location":"architecture/llm-orchestration/#tool-integration-patterns","title":"Tool Integration Patterns","text":""},{"location":"architecture/llm-orchestration/#artagent-tools","title":"ARTAgent Tools","text":"apps/rtagent/backend/src/agents/artagent/tool_store/auth.py<pre><code>async def authenticate_caller(caller_name: str, phone_number: str):\n    \"\"\"Authenticate caller identity.\"\"\"\n    # Implementation for caller verification\n    pass\n\nasync def escalate_emergency(reason: str, caller_name: str = None):\n    \"\"\"Emergency escalation for 911-type situations.\"\"\"\n    # Implementation for emergency routing\n    pass\n</code></pre>"},{"location":"architecture/llm-orchestration/#foundryagent-tools","title":"FoundryAgent Tools","text":"apps/rtagent/backend/src/agents/foundryagents/tool_store/customer_support_tools.py<pre><code>async def check_order_status(order_id: str):\n    \"\"\"Get real-time order information.\"\"\"\n    # Implementation for order lookup\n    pass\n\nasync def create_support_ticket(issue_description: str, customer_info: dict):\n    \"\"\"Create support ticket for complex issues.\"\"\"\n    # Implementation for ticket creation\n    pass\n</code></pre>"},{"location":"architecture/llm-orchestration/#orchestration-flow","title":"Orchestration Flow","text":"sequenceDiagram     participant WS as WebSocket     participant Orch as Orchestrator     participant Reg as Agent Registry     participant Agent as Specialized Agent     participant AI as Azure AI Foundry      WS-&gt;&gt;Orch: Audio \u2192 Transcript     Orch-&gt;&gt;Reg: Lookup Active Agent     Reg--&gt;&gt;Orch: Return Handler     Orch-&gt;&gt;Agent: Execute Agent Logic     Agent-&gt;&gt;AI: LLM Request + Tools     AI--&gt;&gt;Agent: Response + Function Calls     Agent--&gt;&gt;WS: TTS Audio Response"},{"location":"architecture/llm-orchestration/#mode-comparison","title":"Mode Comparison","text":"Aspect Custom Multi-Agent Voice Live API Orchestration Local (this document) Azure AI Foundry managed Configuration YAML agent definitions Azure AI agent configs Dependency Injection FastAPI dependencies Not applicable Agent Registry Local registry system Azure AI managed Tool Integration Custom function calling Azure AI native Agent Switching Dynamic via local registry Azure AI routing Implementation Fully implemented LVAgent integration pending"},{"location":"architecture/llm-orchestration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"architecture/llm-orchestration/#environment-configuration","title":"Environment Configuration","text":"Orchestration Mode Selection<pre><code># Multi-Agent Orchestration\nexport ACS_STREAMING_MODE=MEDIA\nexport ACS_STREAMING_MODE=TRANSCRIPTION\n\n# Voice Live API  \nexport ACS_STREAMING_MODE=VOICE_LIVE\nexport VOICE_LIVE_AGENT_YAML=\"path/to/agent.yaml\"\n</code></pre>"},{"location":"architecture/llm-orchestration/#custom-agent-development","title":"Custom Agent Development","text":"Creating New Agents<pre><code># 1. Create YAML configuration\n# agents/custom/my_agent.yaml\n\n# 2. Implement agent handler\nasync def my_agent_handler(cm, utterance, ws, *, is_acs):\n    # Custom agent logic\n    pass\n\n# 3. Register with orchestrator\nregister_specialist(\"MyAgent\", my_agent_handler)\n\n# 4. Set as active agent\ncm.set_context(\"active_agent\", \"MyAgent\")\n</code></pre>"},{"location":"architecture/llm-orchestration/#integration-points","title":"Integration Points","text":""},{"location":"architecture/llm-orchestration/#custom-multi-agent-integration-files","title":"Custom Multi-Agent Integration Files:","text":"<ul> <li><code>apps/rtagent/backend/api/v1/dependencies/orchestrator.py</code> - Dependency injection provider</li> <li><code>apps/rtagent/backend/src/orchestration/artagent/orchestrator.py</code> - Main routing logic</li> <li><code>apps/rtagent/backend/src/orchestration/artagent/registry.py</code> - Agent registration system  </li> <li><code>apps/rtagent/backend/src/agents/artagent/agent_store/</code> - ARTAgent YAML configurations</li> <li><code>apps/rtagent/backend/src/agents/foundryagents/agent_store/</code> - FoundryAgent YAML configurations</li> <li><code>apps/rtagent/backend/src/agents/*/tool_store/</code> - Function calling implementations</li> </ul>"},{"location":"architecture/llm-orchestration/#voice-live-api-integration-pending","title":"Voice Live API Integration (Pending):","text":"<ul> <li><code>apps/rtagent/backend/src/agents/Lvagent/</code> - LVAgent framework for Voice Live integration</li> <li><code>apps/rtagent/backend/src/agents/Lvagent/factory.py</code> - Agent factory for Voice Live mode</li> <li><code>apps/rtagent/backend/src/agents/Lvagent/agent_store/</code> - Voice Live agent configurations</li> </ul> <p>Voice Live API Status</p> <p>LVAgent integration is under development. Current Voice Live mode uses basic passthrough to Azure AI Foundry. Full orchestration capabilities will be available when LVAgent implementation is complete.</p>"},{"location":"architecture/llm-orchestration/#extension-patterns-custom-multi-agent-only","title":"Extension Patterns (Custom Multi-Agent Only):","text":"<ul> <li>Custom Agents - Add new YAML configs and register handlers</li> <li>Tool Integration - Extend tool registries with business logic  </li> <li>Orchestration Logic - Modify routing strategies in orchestrator</li> <li>Dependency Injection - Swap orchestration functions in provider</li> </ul> <p>This architecture enables rapid agent development through YAML configuration while maintaining full extensibility through the registry and dependency injection patterns for Custom Multi-Agent modes.</p>"},{"location":"architecture/speech-recognition/","title":"Speech Recognition","text":""},{"location":"architecture/speech-recognition/#speech-recognition-api","title":"Speech Recognition API","text":"<p>The Real-Time Voice Agent integrates Azure Cognitive Speech Services through multiple API endpoints, each optimized for different interaction patterns and streaming modes.</p>"},{"location":"architecture/speech-recognition/#api-integration-points","title":"API Integration Points","text":""},{"location":"architecture/speech-recognition/#websocket-endpoints-with-stt-integration","title":"WebSocket Endpoints with STT Integration","text":""},{"location":"architecture/speech-recognition/#apiv1mediastream-acs-media-streaming","title":"<code>/api/v1/media/stream</code> - ACS Media Streaming","text":"<p>Real-time speech recognition for Azure Communication Services calls:</p> <ul> <li>Handler: <code>ACSMediaHandler</code> or <code>VoiceLiveHandler</code> based on <code>ACS_STREAMING_MODE</code></li> <li>STT Integration: Pooled <code>StreamingSpeechRecognizerFromBytes</code> with three-thread architecture</li> <li>Features: Immediate barge-in detection, conversation memory, Azure OpenAI orchestration</li> <li>Use Case: Phone calls through Azure Communication Services</li> </ul> <pre><code>// Connect to ACS media streaming with speech recognition\nconst ws = new WebSocket(\n  `wss://api.domain.com/api/v1/media/stream?call_connection_id=${callId}`\n);\n\n// Send audio frames for recognition\nws.send(base64AudioData);\n\n// Receive transcripts and AI responses\nws.onmessage = (event) =&gt; {\n  const data = JSON.parse(event.data);\n  if (data.type === 'transcript') {\n    console.log('Recognized:', data.text);\n  }\n};\n</code></pre>"},{"location":"architecture/speech-recognition/#apiv1realtimeconversation-browser-voice-conversations","title":"<code>/api/v1/realtime/conversation</code> - Browser Voice Conversations","text":"<p>Speech recognition for web-based voice interactions:</p> <ul> <li>Handler: Dedicated orchestrator with STT/TTS pooling</li> <li>STT Integration: Per-connection speech recognizer with partial/final callbacks</li> <li>Features: Session persistence, dashboard broadcasting, connection queuing</li> <li>Use Case: Browser-based voice conversations and testing</li> </ul> <pre><code>// Connect for browser-based speech recognition\nconst ws = new WebSocket(\n  `wss://api.domain.com/api/v1/realtime/conversation?session_id=${sessionId}`\n);\n\n// Send audio bytes for real-time recognition\nws.send(audioBuffer);\n</code></pre>"},{"location":"architecture/speech-recognition/#core-speech-recognition-class","title":"Core Speech Recognition Class","text":"<p>All endpoints use the <code>StreamingSpeechRecognizerFromBytes</code> class for consistent speech processing:</p> <pre><code>from src.speech.speech_recognizer import StreamingSpeechRecognizerFromBytes\n\n# Initialized automatically by handlers based on endpoint\nrecognizer = StreamingSpeechRecognizerFromBytes(\n    speech_key=\"${AZURE_SPEECH_KEY}\",  # or DefaultAzureCredential\n    speech_region=\"eastus\",\n    languages=[\"en-US\", \"es-ES\"],\n    enable_diarization=True,\n)\n\n# Callbacks are set by handlers for integration\nasync def handle_partial_result(text):\n    # Immediate barge-in detection for ACS calls\n    print(\"Partial (barge-in):\", text)\n\nasync def handle_final_result(text):\n    # Complete utterance for orchestrator processing  \n    print(\"Final transcript:\", text)\n\nrecognizer.on_partial_result = handle_partial_result\nrecognizer.on_final_result = handle_final_result\n</code></pre>"},{"location":"architecture/speech-recognition/#handler-specific-speech-recognition","title":"Handler-Specific Speech Recognition","text":""},{"location":"architecture/speech-recognition/#acs-media-handler-acsmediahandler","title":"ACS Media Handler (<code>ACSMediaHandler</code>)","text":"<p>Streaming Mode: <code>MEDIA</code> or <code>TRANSCRIPTION</code> Endpoint: <code>/api/v1/media/stream</code></p> <p>Implements three-thread architecture for sub-50ms barge-in detection:</p> <pre><code># Thread 1: Speech SDK Thread (never blocks)\ndef on_partial_callback(text: str, lang: str, speaker_id: str):\n    \"\"\"Immediate barge-in detection - called from Speech SDK thread\"\"\"\n    # Schedule cancellation on main event loop\n    main_loop.call_soon_threadsafe(schedule_barge_in, text)\n\ndef on_final_callback(text: str, lang: str):  \n    \"\"\"Queue final speech for processing - called from Speech SDK thread\"\"\"\n    # Thread-safe queue operation\n    speech_queue.put_nowait((text, lang))\n\n# Thread 2: Route Turn Thread (blocks on queue only)\nwhile True:\n    final_text, lang = await speech_queue.get()\n    # Process through orchestrator (may take seconds)\n    await route_turn(memory_manager, final_text, websocket)\n\n# Thread 3: Main Event Loop (never blocks)\nasync def schedule_barge_in(partial_text: str):\n    \"\"\"Cancel current TTS playback immediately (&lt; 50ms)\"\"\"\n    if playback_task and not playback_task.done():\n        playback_task.cancel()\n        await send_stop_audio_to_acs()\n</code></pre> <p>Key Features:</p> <ul> <li>Immediate barge-in: Partial results trigger instant TTS cancellation</li> <li>Non-blocking recognition: Speech SDK runs in dedicated thread</li> <li>Queue-based processing: Final results processed sequentially</li> <li>Resource pooling: Shared STT clients across ACS calls</li> </ul>"},{"location":"architecture/speech-recognition/#voice-live-handler-voicelivehandler","title":"Voice Live Handler (<code>VoiceLiveHandler</code>)","text":"<p>Streaming Mode: <code>VOICE_LIVE</code> Endpoint: <code>/api/v1/media/stream</code></p> <p>Integrates with Azure Voice Live API for advanced conversation handling:</p> <pre><code># Voice Live integration handles STT internally\nvoice_live_agent = build_lva_from_yaml(agent_config)\nawait voice_live_agent.connect()\n\nasync def handle_audio_data(audio_base64: str):\n    \"\"\"Send audio to Voice Live API\"\"\"\n    await voice_live_agent.send_audio(audio_base64)\n\n# Responses come back through Voice Live websocket\ndef on_voice_live_response(response):\n    \"\"\"Handle AI response from Voice Live\"\"\"\n    await websocket.send_json({\n        \"type\": \"assistant_message\", \n        \"content\": response.text,\n        \"audio\": response.audio_data\n    })\n</code></pre> <p>Key Features:</p> <ul> <li>Azure Voice Live Integration: Direct API connection to advanced conversational AI</li> <li>Semantic Voice Activity: Advanced voice activity detection beyond traditional VAD</li> <li>Natural Conversations: Maintains conversation context and flow</li> <li>Emotion Detection: Can detect and respond to emotional cues</li> </ul>"},{"location":"architecture/speech-recognition/#realtime-conversation-handler","title":"Realtime Conversation Handler","text":"<p>Endpoint: <code>/api/v1/realtime/conversation</code></p> <p>Browser-based speech recognition with session persistence:</p> <pre><code># Per-connection STT client with callback registration\nstt_client = await stt_pool.acquire()\n\ndef on_partial(text: str, lang: str, speaker_id: str):\n    \"\"\"Handle partial results for barge-in\"\"\"\n    if websocket.state.is_synthesizing:\n        # Stop current TTS synthesis\n        websocket.state.tts_client.stop_speaking()\n        websocket.state.is_synthesizing = False\n\ndef on_final(text: str, lang: str):\n    \"\"\"Queue final text for orchestrator processing\"\"\"  \n    websocket.state.user_buffer += text.strip() + \"\\n\"\n\nstt_client.set_partial_result_callback(on_partial)\nstt_client.set_final_result_callback(on_final)\n\n# Process accumulated text through orchestrator\nif user_buffer.strip():\n    await route_turn(memory_manager, user_buffer, websocket, is_acs=False)\n</code></pre> <p>Key Features: - Session Management: Persistent conversation state across reconnections - Dashboard Integration: Real-time updates to connected dashboard clients - Resource Pooling: Dedicated STT/TTS clients per browser connection - Parallel Processing: Background orchestration tasks for non-blocking responses</p>"},{"location":"architecture/speech-recognition/#configuration-and-best-practices","title":"Configuration and Best Practices","text":""},{"location":"architecture/speech-recognition/#endpoint-selection","title":"Endpoint Selection","text":"<p>Use <code>/api/v1/media/stream</code> when: - Processing phone calls through Azure Communication Services - Need sub-50ms barge-in detection for natural conversations - Working with ACS call automation and media streaming - Require three-thread architecture for production call centers</p> <p>Use <code>/api/v1/realtime/conversation</code> when: - Building browser-based voice applications - Need session persistence across page reloads - Want dashboard integration and monitoring - Developing voice-enabled web experiences</p>"},{"location":"architecture/speech-recognition/#authentication-options","title":"Authentication Options","text":"<pre><code># Option 1: Azure Entra ID (Recommended for production)\nrecognizer = StreamingSpeechRecognizerFromBytes(\n    speech_region=\"eastus\",\n    use_default_credential=True,  # Uses DefaultAzureCredential\n    enable_tracing=True\n)\n\n# Option 2: API Key (Development/testing)\nrecognizer = StreamingSpeechRecognizerFromBytes(\n    speech_key=os.getenv(\"AZURE_SPEECH_KEY\"),\n    speech_region=\"eastus\",\n    enable_tracing=True\n)\n</code></pre>"},{"location":"architecture/speech-recognition/#audio-format-requirements","title":"Audio Format Requirements","text":"<p>All endpoints expect 16 kHz, mono PCM audio:</p> <pre><code># Audio preprocessing for optimal recognition\nSAMPLE_RATE = 16000\nCHANNELS = 1\nSAMPLE_WIDTH = 2  # 16-bit PCM\n\n# WebSocket audio streaming\naudio_data = resample_audio(raw_audio, target_rate=16000)\nbase64_audio = base64.b64encode(audio_data).decode('utf-8')\nwebsocket.send_text(base64_audio)\n</code></pre>"},{"location":"architecture/speech-recognition/#language-and-feature-configuration","title":"Language and Feature Configuration","text":"<pre><code># Multi-language auto-detection\nrecognizer = StreamingSpeechRecognizerFromBytes(\n    speech_region=\"eastus\",\n    languages=[\"en-US\", \"es-ES\", \"fr-FR\"],  # BCP-47 language codes\n    enable_diarization=True,               # Speaker identification\n    enable_profanity_filter=True,          # Content filtering\n    enable_detailed_results=True           # Word-level timing\n)\n</code></pre>"},{"location":"architecture/speech-recognition/#resource-pool-management","title":"Resource Pool Management","text":"<p>The API uses connection pooling for optimal performance:</p> <pre><code># STT Pool Configuration (managed by application)\nSTT_POOL_SIZE = 4  # Concurrent speech recognizers\nTTS_POOL_SIZE = 4  # Concurrent synthesizers\n\n# Handlers automatically acquire/release pool resources\n# No manual pool management required in client code\n</code></pre>"},{"location":"architecture/speech-recognition/#integration-with-state-management","title":"Integration with State Management","text":"<p>Speech recognition integrates with conversation memory:</p> <pre><code># Automatic session persistence via MemoManager\nmemory_manager = MemoManager.from_redis(session_id, redis_mgr)\n\n# Speech recognition handlers automatically:\n# 1. Load conversation history from Redis\n# 2. Add recognized text to conversation context  \n# 3. Pass to orchestrator for response generation\n# 4. Persist updated conversation state\n\n# Access conversation history\nhistory = memory_manager.get_chat_history()\nfor entry in history:\n    print(f\"{entry.role}: {entry.content}\")\n</code></pre>"},{"location":"architecture/speech-recognition/#observability-and-monitoring","title":"Observability and Monitoring","text":"<p>Speech recognition includes comprehensive tracing:</p> <pre><code># OpenTelemetry spans automatically created for:\n# - Speech recognition session lifecycle\n# - Audio frame processing \n# - Partial/final result callbacks\n# - Handler routing and processing\n\n# Correlation with call connection IDs\nrecognizer.enable_tracing = True\nrecognizer.call_connection_id = \"acs-call-123\"  # For ACS correlation\n\n# Custom attributes in spans include:\n# - Speech SDK session IDs\n# - Language detection results\n# - Processing latencies  \n# - Error conditions and recovery\n</code></pre> <p>See Streaming Modes Documentation for detailed configuration options and Speech Synthesis for TTS integration patterns.</p>"},{"location":"architecture/speech-synthesis/","title":"Speech Synthesis","text":""},{"location":"architecture/speech-synthesis/#speech-synthesis-api","title":"Speech Synthesis API","text":"<p>The Real-Time Voice Agent provides enterprise-grade text-to-speech capabilities through the <code>SpeechSynthesizer</code> class, built on Azure Speech Services with comprehensive integration features.</p>"},{"location":"architecture/speech-synthesis/#key-features","title":"Key Features","text":"<ul> <li>Multiple authentication methods: API Key and Azure Entra ID (Default Credentials)</li> <li>Real-time synthesis: Base64 frame streaming for WebSocket clients</li> <li>Local speaker playback: Intelligent headless environment detection</li> <li>OpenTelemetry tracing: Integration for Application Insights monitoring</li> <li>Concurrent synthesis limiting: Prevents service overload</li> <li>Advanced voice control: Neural styles, prosody, multilingual support</li> </ul>"},{"location":"architecture/speech-synthesis/#speechsynthesizer-class","title":"SpeechSynthesizer Class","text":"<p>Located in <code>src/speech/text_to_speech.py</code>, the <code>SpeechSynthesizer</code> provides comprehensive text-to-speech functionality with Azure integration.</p>"},{"location":"architecture/speech-synthesis/#authentication-methods","title":"Authentication Methods","text":""},{"location":"architecture/speech-synthesis/#azure-entra-id-recommended-for-production","title":"Azure Entra ID (Recommended for Production)","text":"<pre><code>from src.speech.text_to_speech import SpeechSynthesizer\n\n# Uses DefaultAzureCredential - no API key required\nsynthesizer = SpeechSynthesizer(\n    region=\"eastus\",\n    voice=\"en-US-JennyMultilingualNeural\",\n    enable_tracing=True\n)\n</code></pre>"},{"location":"architecture/speech-synthesis/#api-key-developmenttesting","title":"API Key (Development/Testing)","text":"<pre><code># Traditional API key authentication\nsynthesizer = SpeechSynthesizer(\n    key=\"your-speech-key\",\n    region=\"eastus\",\n    voice=\"en-US-EmmaNeural\"\n)\n</code></pre>"},{"location":"architecture/speech-synthesis/#basic-usage-examples","title":"Basic Usage Examples","text":""},{"location":"architecture/speech-synthesis/#simple-text-to-speech","title":"Simple Text-to-Speech","text":"<pre><code># Synthesize to memory\naudio_data = synthesizer.synthesize_speech(\n    \"Hello! Welcome to our voice application.\",\n    style=\"chat\",\n    rate=\"+10%\"\n)\n\n# Save to file\nwith open(\"output.wav\", \"wb\") as f:\n    f.write(audio_data)\n</code></pre>"},{"location":"architecture/speech-synthesis/#real-time-streaming-for-websocket","title":"Real-time Streaming for WebSocket","text":"<pre><code># Generate base64-encoded frames for streaming\nframes = synthesizer.synthesize_to_base64_frames(\n    \"This is real-time streaming audio\",\n    sample_rate=16000\n)\n\n# Send frames to WebSocket client\nfor frame in frames:\n    websocket.send(frame)\n</code></pre>"},{"location":"architecture/speech-synthesis/#local-speaker-playback","title":"Local Speaker Playback","text":"<pre><code># Play audio through system speakers (if available)\nsynthesizer = SpeechSynthesizer(\n    key=\"your-key\",\n    region=\"eastus\",\n    playback=\"auto\"  # Automatic hardware detection\n)\n\n# Speak text directly\nsynthesizer.start_speaking_text(\n    \"This will play through your speakers!\",\n    voice=\"en-US-EmmaNeural\",\n    style=\"excited\"\n)\n\n# Stop playback\nimport time\ntime.sleep(3)\nsynthesizer.stop_speaking()\n</code></pre>"},{"location":"architecture/speech-synthesis/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"architecture/speech-synthesis/#production-setup-with-managed-identity","title":"Production Setup with Managed Identity","text":"<pre><code>import os\nfrom src.speech.text_to_speech import SpeechSynthesizer\n\n# Production configuration\nsynthesizer = SpeechSynthesizer(\n    region=os.getenv(\"AZURE_SPEECH_REGION\"),\n    voice=\"en-US-JennyMultilingualNeural\", \n    playback=\"never\",  # Headless deployment\n    enable_tracing=True,  # OpenTelemetry monitoring\n    call_connection_id=\"session-abc123\"  # Correlation tracking\n)\n\n# Validate configuration\nif synthesizer.validate_configuration():\n    print(\"\u2705 Speech synthesizer ready for production\")\nelse:\n    print(\"\u274c Configuration validation failed\")\n</code></pre>"},{"location":"architecture/speech-synthesis/#voice-styles-and-prosody-control","title":"Voice Styles and Prosody Control","text":"<pre><code># Advanced voice styling\naudio = synthesizer.synthesize_speech(\n    \"Production-ready voice synthesis\",\n    voice=\"en-US-EmmaNeural\",\n    style=\"news\",  # Available: chat, cheerful, sad, angry, etc.\n    rate=\"+5%\",    # Speed adjustment\n    pitch=\"+2Hz\",  # Pitch control\n    volume=\"+10dB\" # Volume adjustment\n)\n</code></pre>"},{"location":"architecture/speech-synthesis/#environment-configuration","title":"Environment Configuration","text":"<p>Required environment variables for production deployment:</p> <pre><code># Azure Speech Services\nAZURE_SPEECH_REGION=eastus\nAZURE_SPEECH_RESOURCE_ID=/subscriptions/.../resourceGroups/.../providers/Microsoft.CognitiveServices/accounts/...\n\n# Optional: Custom endpoint\nAZURE_SPEECH_ENDPOINT=https://your-custom-endpoint.cognitiveservices.azure.com\n\n# Optional: Audio playback control\nTTS_ENABLE_LOCAL_PLAYBACK=false  # Set to false for headless environments\n</code></pre>"},{"location":"architecture/speech-synthesis/#error-handling-and-validation","title":"Error Handling and Validation","text":""},{"location":"architecture/speech-synthesis/#configuration-validation","title":"Configuration Validation","text":"<pre><code># Test configuration before use\nif synthesizer.validate_configuration():\n    print('\u2705 Configuration is valid')\n\n    # Test basic synthesis\n    audio_data = synthesizer.synthesize_speech(\"Hello, world!\")\n    print(f'\u2705 Generated {len(audio_data)} bytes of audio')\nelse:\n    print('\u274c Configuration validation failed')\n</code></pre>"},{"location":"architecture/speech-synthesis/#common-issues","title":"Common Issues","text":"<p>Authentication Errors <pre><code># Verify Azure credentials\naz account show\naz cognitiveservices account list\n</code></pre></p> <p>Audio Hardware Issues <pre><code># Check headless environment detection\nfrom src.speech.text_to_speech import _is_headless\nprint(f\"Headless environment: {_is_headless()}\")\n</code></pre></p> <p>Import Errors <pre><code># Ensure dependencies are installed\npip install azure-cognitiveservices-speech\npython -c \"import src.speech.text_to_speech; print('\u2705 Import successful')\"\n</code></pre></p>"},{"location":"architecture/speech-synthesis/#opentelemetry-integration","title":"OpenTelemetry Integration","text":"<p>The <code>SpeechSynthesizer</code> includes built-in tracing for production monitoring:</p> <pre><code># Enable comprehensive tracing\nsynthesizer = SpeechSynthesizer(\n    region=\"eastus\",\n    enable_tracing=True,\n    call_connection_id=\"acs-call-123\"  # Correlation ID\n)\n\n# All operations automatically traced with:\n# - Session-level spans for complete request lifecycle  \n# - Service dependency mapping for Azure Monitor App Map\n# - Call correlation across distributed components\n</code></pre>"},{"location":"architecture/speech-synthesis/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Connection pooling: Default limit of 4 concurrent synthesis operations</li> <li>Memory efficiency: Streaming operations with automatic resource cleanup</li> <li>Lazy initialization: Audio components initialized only when needed</li> <li>Headless detection: Automatic fallback for containerized environments</li> </ul>"},{"location":"architecture/speech-synthesis/#integration-with-container-apps","title":"Integration with Container Apps","text":"<p>For Azure Container Apps deployment, ensure proper configuration:</p> <pre><code># Dockerfile example\nFROM python:3.11-slim\n\n# Set environment for headless operation\nENV TTS_ENABLE_LOCAL_PLAYBACK=false\nENV AZURE_SPEECH_REGION=eastus\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy application\nCOPY src/ ./src/\nCMD [\"python\", \"-m\", \"your_app\"]\n</code></pre>"},{"location":"architecture/speech-synthesis/#api-integration","title":"API Integration","text":"<p>The speech synthesis functionality integrates with the main API endpoints - see API Reference for complete endpoint documentation:</p> <ul> <li>Call Management - TTS for outbound call prompts and conversation responses</li> <li>Media Streaming - Real-time TTS synthesis for ACS call conversations  </li> <li>Health Monitoring - TTS service validation and voice testing</li> </ul> <p>For complete API documentation, see the API Overview.</p>"},{"location":"architecture/streaming-modes/","title":"Streaming Modes","text":""},{"location":"architecture/streaming-modes/#acs-streaming-modes-configuration","title":"ACS Streaming Modes Configuration","text":"<p>The Real-Time Voice Agent supports multiple audio processing modes through the <code>ACS_STREAMING_MODE</code> configuration flag. This flag determines how audio data from Azure Communication Services (ACS) is processed, routed, and orchestrated within the application.</p>"},{"location":"architecture/streaming-modes/#overview","title":"Overview","text":"<p>The <code>ACS_STREAMING_MODE</code> environment variable controls the audio processing pipeline, allowing you to choose between different approaches for handling real-time audio streams from ACS calls:</p> <pre><code># Set the streaming mode\nexport ACS_STREAMING_MODE=media        # Default: Traditional media processing\nexport ACS_STREAMING_MODE=transcription # ACS transcription-only mode\nexport ACS_STREAMING_MODE=voice_live   # Azure Voice Live integration\n</code></pre>"},{"location":"architecture/streaming-modes/#available-streaming-modes","title":"Available Streaming Modes","text":""},{"location":"architecture/streaming-modes/#1-media-mode-default","title":"1. MEDIA Mode (Default)","text":"<p>Configuration: <code>ACS_STREAMING_MODE=media</code></p> <p>Traditional bidirectional media processing with comprehensive speech services integration.</p> <p>Audio Flow: <pre><code>ACS Call Audio \u279c WebSocket \u279c STT Pool \u279c Orchestrator \u279c TTS Pool \u279c ACS Audio Output\n</code></pre></p> <p>Features: - Bi-directional PCM audio streaming directly to/from ACS WebSocket - Connection pooling for Azure Speech STT/TTS services - Orchestrator integration for conversational logic processing - Session management with Redis-backed state persistence - Real-time transcription with speaker diarization support - Neural voice synthesis with style and prosody control</p> <p>Use Cases: - Traditional voice assistants and IVR systems - Call center automation with human handoff - Multi-turn conversations requiring context preservation - Applications needing fine-grained control over speech processing</p> <p>Configuration Example: <pre><code># API automatically uses MEDIA mode handlers\nif ACS_STREAMING_MODE == StreamMode.MEDIA:\n    # Acquire STT and TTS clients from pools\n    stt_client = await app.state.stt_pool.acquire()\n    tts_client = await app.state.tts_pool.acquire()\n\n    # Create media handler with orchestrator\n    handler = ACSMediaHandler(\n        websocket=websocket,\n        orchestrator_func=orchestrator,\n        recognizer=stt_client,\n        memory_manager=memory_manager,\n        session_id=session_id\n    )\n</code></pre></p>"},{"location":"architecture/streaming-modes/#2-transcription-mode","title":"2. TRANSCRIPTION Mode","text":"<p>Configuration: <code>ACS_STREAMING_MODE=transcription</code></p> <p>Audio-to-text processing focused on real-time transcription and analysis.</p> <p>Audio Flow: <pre><code>ACS Call Audio \u279c WebSocket \u279c Azure Speech Recognition \u279c Transcript Processing\n</code></pre></p> <p>Features: - Real-time transcription of ACS call audio streams - Multi-language detection with configurable candidate languages - Speaker diarization for multi-participant calls - Streaming text output via WebSocket to connected clients - Minimal latency optimized for live transcription needs - No audio synthesis - transcription-only pipeline</p> <p>Use Cases: - Call transcription and logging systems - Real-time captioning for accessibility - Voice analytics and sentiment analysis - Meeting transcription and note-taking applications</p> <p>Configuration Example: <pre><code># API routes to transcription handler\nelif ACS_STREAMING_MODE == StreamMode.TRANSCRIPTION:\n    await handler.handle_transcription_message(audio_message)\n</code></pre></p>"},{"location":"architecture/streaming-modes/#3-voice_live-mode","title":"3. VOICE_LIVE Mode","text":"<p>Configuration: <code>ACS_STREAMING_MODE=voice_live</code></p> <p>Advanced conversational AI using Azure Voice Live for sophisticated dialogue management.</p> <p>Audio Flow: <pre><code>ACS Call Audio \u279c WebSocket \u279c Azure Voice Live Agent \u279c Direct Audio Response\n</code></pre></p> <p>Features: - Azure Voice Live integration for advanced conversational AI - End-to-end audio processing with minimal intermediate steps - Context-aware responses using pre-trained conversation models - Low-latency interaction optimized for natural conversation flow - Advanced orchestration through Voice Live agents - Intelligent conversation management with built-in dialogue state</p> <p>Use Cases: - Advanced AI assistants with natural conversation flow - Customer service automation with complex query handling - Educational applications with interactive tutoring - Healthcare applications with conversational interfaces</p> <p>Pre-initialization Process: <pre><code># Voice Live agents are pre-initialized during call setup\nif ACS_STREAMING_MODE == StreamMode.VOICE_LIVE:\n    # Create and connect Voice Live agent\n    agent_yaml = os.getenv(\"VOICE_LIVE_AGENT_YAML\", \n                          \"apps/rtagent/backend/src/agents/Lvagent/agent_store/auth_agent.yaml\")\n    lva_agent = build_lva_from_yaml(agent_yaml, enable_audio_io=False)\n    await asyncio.to_thread(lva_agent.connect)\n\n    # Store agent for WebSocket session to claim later\n    await conn_manager.set_call_context(call_id, {\"lva_agent\": lva_agent})\n</code></pre></p> <p>Handler Integration: <pre><code># Voice Live handler with injected agent\nhandler = VoiceLiveHandler(\n    azure_endpoint=AZURE_VOICE_LIVE_ENDPOINT,\n    model_name=AZURE_VOICE_LIVE_MODEL,\n    session_id=session_id,\n    websocket=websocket,\n    orchestrator=orchestrator,\n    use_lva_agent=True,\n    lva_agent=injected_agent\n)\n</code></pre></p>"},{"location":"architecture/streaming-modes/#validation-and-error-handling","title":"Validation and Error Handling","text":"<p>The system includes comprehensive validation for streaming mode configuration:</p> <pre><code># Enum-based validation with clear error messages\n@classmethod\ndef from_string(cls, value: str) -&gt; \"StreamMode\":\n    \"\"\"Create StreamMode from string with validation\"\"\"\n    for mode in cls:\n        if mode.value == value:\n            return mode\n    raise ValueError(\n        f\"Invalid stream mode: {value}. Valid options: {[m.value for m in cls]}\"\n    )\n</code></pre>"},{"location":"architecture/streaming-modes/#api-integration","title":"API Integration","text":""},{"location":"architecture/streaming-modes/#websocket-media-streaming","title":"WebSocket Media Streaming","text":"<p>The streaming mode affects how the media WebSocket endpoint processes audio:</p> <pre><code>@router.websocket(\"/stream\")\nasync def acs_media_stream(websocket: WebSocket) -&gt; None:\n    \"\"\"WebSocket endpoint adapts behavior based on ACS_STREAMING_MODE\"\"\"\n\n    # Create appropriate handler based on mode\n    handler = await _create_media_handler(\n        websocket=websocket,\n        call_connection_id=call_connection_id,\n        session_id=session_id,\n        orchestrator=orchestrator,\n        conn_id=conn_id\n    )\n\n    # Process messages according to mode\n    while connected:\n        msg = await websocket.receive_text()\n\n        if ACS_STREAMING_MODE == StreamMode.MEDIA:\n            await handler.handle_media_message(msg)\n        elif ACS_STREAMING_MODE == StreamMode.TRANSCRIPTION:\n            await handler.handle_transcription_message(msg)\n        elif ACS_STREAMING_MODE == StreamMode.VOICE_LIVE:\n            await handler.handle_audio_data(msg)\n</code></pre>"},{"location":"architecture/streaming-modes/#status-and-monitoring","title":"Status and Monitoring","text":"<p>You can query the current streaming mode via the API:</p> <pre><code># Check current streaming configuration\ncurl https://your-api.com/api/v1/media/status\n\n# Response includes current mode\n{\n  \"status\": \"available\",\n  \"streaming_mode\": \"voice_live\",\n  \"websocket_endpoint\": \"/api/v1/media/stream\",\n  \"features\": {\n    \"real_time_audio\": true,\n    \"transcription\": true,\n    \"orchestrator_support\": true,\n    \"session_management\": true\n  }\n}\n</code></pre>"},{"location":"architecture/streaming-modes/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/streaming-modes/#resource-usage-by-mode","title":"Resource Usage by Mode","text":"Mode STT Pool TTS Pool Voice Live Agent Memory Usage MEDIA \u2705 High \u2705 High \u274c None High TRANSCRIPTION \u2705 Medium \u274c None \u274c None Low VOICE_LIVE \u274c None \u274c None \u2705 High Medium"},{"location":"architecture/streaming-modes/#latency-characteristics","title":"Latency Characteristics","text":"<ul> <li>MEDIA Mode: 100-300ms (STT + Orchestrator + TTS pipeline)</li> <li>TRANSCRIPTION Mode: 50-150ms (STT only, no synthesis)</li> <li>VOICE_LIVE Mode: 200-400ms (End-to-end Voice Live processing)</li> </ul>"},{"location":"architecture/streaming-modes/#scaling-considerations","title":"Scaling Considerations","text":"<pre><code># Pool sizing recommendations by mode\nMEDIA_MODE_POOLS = {\n    \"stt_pool_size\": 10,\n    \"tts_pool_size\": 10,\n    \"max_concurrent_calls\": 20\n}\n\nTRANSCRIPTION_MODE_POOLS = {\n    \"stt_pool_size\": 15,\n    \"max_concurrent_calls\": 50  # Lighter processing\n}\n\nVOICE_LIVE_MODE_POOLS = {\n    \"voice_live_pool_size\": 5,  # Resource intensive\n    \"max_concurrent_calls\": 10\n}\n</code></pre>"},{"location":"architecture/streaming-modes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/streaming-modes/#common-configuration-issues","title":"Common Configuration Issues","text":"<p>Invalid Mode Error: <pre><code>ValueError: Invalid stream mode: invalid_mode. \nValid options: ['media', 'transcription', 'voice_live']\n</code></pre> Solution: Check <code>ACS_STREAMING_MODE</code> environment variable spelling and case.</p> <p>Voice Live Agent Not Found: <pre><code>RuntimeError: Voice Live agent YAML not found\n</code></pre> Solution: Ensure <code>VOICE_LIVE_AGENT_YAML</code> points to a valid agent configuration file.</p> <p>Pool Resource Exhaustion: <pre><code>TimeoutError: Unable to acquire STT client from pool\n</code></pre> Solution: Increase pool size or reduce concurrent call limits based on your mode.</p>"},{"location":"architecture/streaming-modes/#debugging-mode-selection","title":"Debugging Mode Selection","text":"<p>Enable debug logging to trace mode selection:</p> <pre><code># Add to logging configuration\nimport logging\nlogging.getLogger(\"config.infrastructure\").setLevel(logging.DEBUG)\nlogging.getLogger(\"api.v1.endpoints.media\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"architecture/streaming-modes/#migration-guide","title":"Migration Guide","text":""},{"location":"architecture/streaming-modes/#switching-between-modes","title":"Switching Between Modes","text":"<p>When changing streaming modes, consider the following:</p> <ol> <li> <p>Update Environment Variables: <pre><code># Old configuration\nexport ACS_STREAMING_MODE=media\n\n# New configuration  \nexport ACS_STREAMING_MODE=voice_live\n</code></pre></p> </li> <li> <p>Restart Application Services:</p> </li> <li>Configuration changes require application restart</li> <li>Connection pools will be recreated with appropriate resources</li> <li> <p>Existing WebSocket connections will complete with old mode</p> </li> <li> <p>Update Client Integration:</p> </li> <li>WebSocket message handling may differ between modes</li> <li>Response formats and timing characteristics will change</li> <li>Test thoroughly in staging environment</li> </ol>"},{"location":"architecture/streaming-modes/#best-practices","title":"Best Practices","text":"<ul> <li>Development: Start with <code>media</code> mode for full control and debugging</li> <li>Production Transcription: Use <code>transcription</code> mode for lightweight, high-throughput scenarios</li> <li>Advanced AI: Use <code>voice_live</code> mode for sophisticated conversational experiences</li> <li>Monitoring: Always monitor resource usage and latency after mode changes</li> </ul> <p>For detailed implementation examples and handler-specific documentation, see the API Overview and Architecture Overview.</p>"},{"location":"deployment/","title":"Deployment Guide","text":""},{"location":"deployment/#deployment-guide","title":"Deployment Guide","text":"<p>Production-Ready Deployment</p> <p>Comprehensive guide to deploy your Real-Time Voice Agent using Terraform infrastructure and Azure Container Apps.</p>"},{"location":"deployment/#infrastructure-overview","title":"Infrastructure Overview","text":"<p>This deployment uses Terraform as Infrastructure as Code with Azure Container Apps for hosting, providing:</p> Core ServicesPlatform &amp; Monitoring <ul> <li> AI Services: Azure OpenAI (GPT-4 models) + Speech Services with Live Voice API</li> <li> Communication: Azure Communication Services for real-time voice and telephony</li> <li> Data Layer: Cosmos DB (MongoDB API) + Redis Enterprise + Blob Storage</li> <li> Security: Managed Identity with role-based access control (RBAC)</li> </ul> <ul> <li> Hosting: Azure Container Apps with auto-scaling and built-in TLS</li> <li> Monitoring: Application Insights + Log Analytics with OpenTelemetry tracing</li> <li> Networking: Private endpoints and VNet integration for enhanced security</li> </ul> <p>Infrastructure Details</p> <p>See the complete Terraform Infrastructure README for resource specifications and configuration options.</p>"},{"location":"deployment/#prerequisites","title":"Prerequisites","text":"<p>Before You Begin</p> <p>Ensure you have the following tools and permissions configured.</p> Tool Version Purpose Azure CLI &gt;=2.50.0 Azure resource management Azure Developer CLI (azd) Latest Simplified deployment Terraform &gt;=1.1.7, &lt;2.0.0 Infrastructure as Code Docker 20.10+ Containerization and local testing Node.js 18+ Frontend development Python 3.11+ Backend development"},{"location":"deployment/#azure-permissions","title":"Azure Permissions","text":"<p>Required Permissions</p> <p>Your Azure account needs these permissions in the target subscription:</p> <ul> <li>Owner or Contributor + User Access Administrator</li> <li>Permission to create managed identities and assign their roles</li> <li>Permission to create service principals (only needed when enabling EasyAuth)</li> <li>Permission to assign roles to resources</li> </ul> Verify Azure permissions<pre><code># Login to Azure\naz login\n\n# Check current subscription and permissions\naz account show\naz role assignment list --assignee $(az account show --query user.name -o tsv) --include-inherited\n</code></pre>"},{"location":"deployment/#quick-start-with-azure-developer-cli","title":"Quick Start with Azure Developer CLI","text":"<p>The easiest and recommended way to deploy this application is using the Azure Developer CLI with its Terraform backend.</p>"},{"location":"deployment/#step-1-clone-and-initialize","title":"Step 1: Clone and Initialize","text":"<pre><code>git clone https://github.com/Azure-Samples/art-voice-agent-accelerator.git\ncd art-voice-agent-accelerator\nazd auth login\nazd init\n</code></pre>"},{"location":"deployment/#step-2-set-environment-variables","title":"Step 2: Set Environment Variables","text":"<pre><code>azd env new &lt;environment-name&gt;\nazd env set AZURE_LOCATION \"eastus\"\nazd env set AZURE_ENV_NAME \"&lt;environment-name&gt;\"\n</code></pre>"},{"location":"deployment/#step-3-deploy-infrastructure-and-applications","title":"Step 3: Deploy Infrastructure and Applications","text":"<pre><code>azd up\n</code></pre> <p>Total deployment time: ~15 minutes for complete infrastructure and application deployment.</p> <p>Additional Resources</p> <p>For more comprehensive guidance on development and operations:</p> <ul> <li>Repository Structure - Understand the codebase layout</li> <li>Utilities &amp; Services - Core infrastructure components</li> <li>Local Development Guide - Set up and test on your local machine</li> </ul>"},{"location":"deployment/#alternative-direct-terraform-deployment","title":"Alternative: Direct Terraform Deployment","text":"<p>For users who prefer direct Terraform control or in environments where <code>azd</code> is not available:</p>"},{"location":"deployment/#step-1-initialize-terraform-backend","title":"Step 1: Initialize Terraform Backend","text":"<pre><code># Set your Azure subscription\nexport ARM_SUBSCRIPTION_ID=$(az account show --query id -o tsv)\nexport AZURE_ENV_NAME=\"dev\"  # or your preferred environment name\n\n# Configure backend storage (see Backend Storage Configuration below)\ncd infra/terraform\ncp backend.tf.example backend.tf\n# Edit backend.tf with your storage account details\n</code></pre>"},{"location":"deployment/#step-2-configure-variables","title":"Step 2: Configure Variables","text":"<pre><code># Copy and customize terraform variables\ncp terraform.tfvars.example terraform.tfvars\n\n# Get your principal ID for RBAC assignments\nPRINCIPAL_ID=$(az ad signed-in-user show --query id -o tsv)\necho \"principal_id = \\\"$PRINCIPAL_ID\\\"\" &gt;&gt; terraform.tfvars\n</code></pre>"},{"location":"deployment/#step-3-deploy-infrastructure","title":"Step 3: Deploy Infrastructure","text":"<pre><code>terraform init\nterraform plan\nterraform apply\n</code></pre>"},{"location":"deployment/#step-4-deploy-your-application","title":"Step 4: Deploy your application","text":"<p>Review the deployment steps to deploy a container application after infrastructure is provisioned.</p> <p>Quickstart: Deploy your first container app with containerapp up</p>"},{"location":"deployment/#detailed-deployment-steps","title":"Detailed Deployment Steps","text":""},{"location":"deployment/#1-environment-configuration","title":"1. Environment Configuration","text":""},{"location":"deployment/#azure-developer-cli-setup","title":"Azure Developer CLI Setup","text":"<p>Configure your deployment environment with the required parameters:</p> <pre><code># Create production environment\nazd env new production\n\n# Set core parameters\nazd env set AZURE_LOCATION \"eastus\"\nazd env set AZURE_ENV_NAME \"production\"\n\n# Optional: Configure specific settings\nazd env set AZURE_PRINCIPAL_ID $(az ad signed-in-user show --query id -o tsv)\n</code></pre>"},{"location":"deployment/#direct-terraform-setup","title":"Direct Terraform Setup","text":"<p>For direct Terraform deployments, configure your <code>terraform.tfvars</code>:</p> <pre><code># Environment configuration\nenvironment_name = \"dev\"\nname            = \"rtaudioagent\"\nlocation        = \"eastus\"\n\n# Principal configuration (replace with your user ID)\nprincipal_id   = \"your-user-principal-id-here\"\nprincipal_type = \"User\"\n\n# Azure Communication Services data location\nacs_data_location = \"United States\"\n\n# Authentication settings\ndisable_local_auth = true\n\n# Redis Enterprise SKU (adjust based on your needs and regional availability)\nredis_sku = \"MemoryOptimized_M10\"\n\n# OpenAI model deployments with latest models\nmodel_deployments = [\n  {\n    name     = \"gpt-4-1-mini\"\n    version  = \"2024-11-20\"\n    sku_name = \"DataZoneStandard\"\n    capacity = 50\n  },\n  {\n    name     = \"o3-mini\"\n    version  = \"2025-01-31\"\n    sku_name = \"DataZoneStandard\"\n    capacity = 30\n  }\n]\n</code></pre>"},{"location":"deployment/#2-terraform-infrastructure-provisioning","title":"2. Terraform Infrastructure Provisioning","text":"<p>Deploy Azure resources using Terraform:</p>"},{"location":"deployment/#with-azure-developer-cli-recommended","title":"With Azure Developer CLI (Recommended)","text":"<p><pre><code># Full deployment (provisions infrastructure and deploys applications)\nazd up\n\n# Infrastructure only\nazd provision\n</code></pre> What happens during <code>azd up</code>:</p> <ol> <li>Pre-provision hooks (configured in <code>azure.yaml</code>) automatically set up Terraform backend storage</li> <li>Infrastructure provisioning uses Terraform modules in <code>infra/terraform/</code></li> <li>Post-provision hooks configure phone numbers and generate environment files</li> <li>Application deployment builds and deploys containers to Azure Container Apps</li> </ol> <p>Automation scripts (located in <code>devops/scripts/azd/</code>):</p> <ul> <li><code>preprovision.sh</code> - Sets up Terraform backend storage and validates prerequisites</li> <li><code>postprovision.sh</code> - Configures ACS phone numbers and generates environment files</li> </ul> <p>See <code>azure.yaml</code> for the complete hook configuration and script orchestration.</p>"},{"location":"deployment/#with-direct-terraform","title":"With Direct Terraform","text":"<pre><code>cd infra/terraform\nterraform init\nterraform plan\nterraform apply\n</code></pre> <p>Resources Created:</p> <ul> <li>Azure Container Apps Environment with auto-scaling and ingress management</li> <li>Azure OpenAI Service (GPT-4.1-mini, O3-mini models) with intelligent model routing</li> <li>Azure Communication Services with Live Voice API integration</li> <li>Redis Enterprise Cache for session management and real-time data</li> <li>Key Vault with managed identity authentication and secure secret rotation</li> <li>Azure Container Registry for application image management</li> <li>Storage Account with blob containers for audio and conversation data</li> <li>Cosmos DB (MongoDB API) for persistent conversation history and agent memory</li> <li>Application Insights &amp; Log Analytics with OpenTelemetry distributed tracing</li> <li>User-assigned managed identities with comprehensive RBAC permissions</li> </ul> <p>For detailed infrastructure information, see the Terraform Infrastructure README.</p>"},{"location":"deployment/#3-application-deployment","title":"3. Application Deployment","text":"<p>Deploy your application code to the provisioned infrastructure:</p>"},{"location":"deployment/#with-azure-developer-cli","title":"With Azure Developer CLI","text":"<pre><code># Deploy applications to existing infrastructure\nazd deploy\n</code></pre>"},{"location":"deployment/#with-direct-terraform-make","title":"With Direct Terraform + Make","text":"<pre><code># Deploy both backend and frontend\nmake deploy_backend\nmake deploy_frontend\n\n# Monitor deployment progress\nmake monitor_backend_deployment\nmake monitor_frontend_deployment\n</code></pre>"},{"location":"deployment/#build-and-publish-container-images","title":"Build and Publish Container Images","text":"<p>Before running <code>make deploy_*</code> or Terraform application modules, build and push your containers to the Azure Container Registry created earlier.</p> <pre><code># From repo root\nACR_NAME=$(terraform output -raw container_registry_name)   # or azd env get-value\nACR_LOGIN_SERVER=\"$ACR_NAME.azurecr.io\"\n\naz acr login --name $ACR_NAME\n\n# Backend image (Dockerfile: apps/rtagent/backend/Dockerfile)\ndocker build \\\n  -f apps/rtagent/backend/Dockerfile \\\n  -t $ACR_LOGIN_SERVER/voice-agent-backend:$(git rev-parse --short HEAD) \\\n  apps/rtagent/backend\ndocker push $ACR_LOGIN_SERVER/voice-agent-backend:$(git rev-parse --short HEAD)\n\n# Frontend image (Dockerfile: apps/rtagent/frontend/Dockerfile)\ndocker build \\\n  -f apps/rtagent/frontend/Dockerfile \\\n  -t $ACR_LOGIN_SERVER/voice-agent-frontend:$(git rev-parse --short HEAD) \\\n  apps/rtagent/frontend\ndocker push $ACR_LOGIN_SERVER/voice-agent-frontend:$(git rev-parse --short HEAD)\n</code></pre> <p>Update your Terraform variables (for example, <code>backend_image_tag</code> and <code>frontend_image_tag</code>) to match the tags you pushed so the Container Apps pick up the correct images.</p> <p>Need a local integration pass before pushing? Use the root <code>docker-compose.yml</code> to build and validate the services together:</p> <pre><code>docker compose build\ndocker compose up\n</code></pre> <p>Stop the compose stack when finished, publish fresh images, then re-run your Terraform or Make-based deployment.</p>"},{"location":"deployment/#4-phone-number-configuration","title":"4. Phone Number Configuration","text":"<p>Configure an Azure Communication Services phone number for voice calls:</p>"},{"location":"deployment/#automatic-via-azd-recommended","title":"Automatic via azd (Recommended)","text":"<p>The <code>azd up</code> command automatically handles phone number provisioning through post-provision hooks.</p>"},{"location":"deployment/#manual-configuration","title":"Manual Configuration","text":"<pre><code># Purchase a phone number using the helper script\nmake purchase_acs_phone_number\n\n# Or set an existing number\nazd env set ACS_SOURCE_PHONE_NUMBER \"+1234567890\"\n</code></pre>"},{"location":"deployment/#via-azure-portal","title":"Via Azure Portal","text":"<ol> <li>Navigate to your Azure Communication Services resource in the Azure Portal</li> <li>Go to Phone numbers \u2192 Get in the left navigation menu</li> <li>Select your country/region, number type (Geographic or Toll-free), and required features</li> <li>Complete the purchase process and wait for number provisioning</li> <li>Update your environment configuration with the purchased number</li> <li>Configure webhook endpoints for incoming call handling</li> </ol> <p>Detailed Guide: Get a phone number for Azure Communication Services</p>"},{"location":"deployment/#configure-inbound-call-webhook","title":"Configure Inbound Call Webhook","text":"<ol> <li>Open your Azure Communication Services resource in the Azure Portal.</li> <li>Select Events \u2192 + Event Subscription.</li> <li>Choose Inbound Call as the event type.</li> <li>Set the endpoint type to Web Hook and provide the callback URL:</li> <li>Local development: <code>https://&lt;your-devtunnel-host&gt;/api/v1/calls/answer</code></li> <li>Deployed backend: <code>https://&lt;backend-container-app-endpoint&gt;/api/v1/calls/answer</code></li> <li>Complete the subscription wizard to enable webhook delivery for inbound calls.</li> </ol> <p>Optional: Secure Event Grid Delivery with Microsoft Entra ID</p> <p>If you need authenticated delivery, configure the Event Grid subscription to use Microsoft Entra ID for webhook validation. Follow the Entra ID authentication guidance and grant your event handler the required app registration and role assignments before enabling the subscription.</p>"},{"location":"deployment/#5-connectivity-testing","title":"5. Connectivity Testing","text":"<p>Test your deployed application to ensure everything works correctly:</p>"},{"location":"deployment/#health-check","title":"Health Check","text":"<pre><code># Get backend URL\nBACKEND_URL=$(azd env get-value BACKEND_CONTAINER_APP_URL)\n\n# Test health endpoint\ncurl -I $BACKEND_URL/health\n</code></pre>"},{"location":"deployment/#websocket-testing","title":"WebSocket Testing","text":"<pre><code># Install wscat for WebSocket testing\nnpm install -g wscat\n\n# Test WebSocket connection with the media endpoint\nBACKEND_FQDN=$(azd env get-value BACKEND_CONTAINER_APP_FQDN)\nwscat -c wss://$BACKEND_FQDN/api/v1/media/stream\n\n# Test real-time communication endpoint\nwscat -c wss://$BACKEND_FQDN/api/v1/stream\n</code></pre> <p>Expected Behavior: - Health endpoint returns 200 OK with service status information - WebSocket connection establishes successfully without errors - Receives connection confirmation message with session details - Real-time audio streaming capabilities are functional - Use <code>Ctrl+C</code> to disconnect gracefully</p> <p>Need help? See our troubleshooting section below.</p>"},{"location":"deployment/#environment-management","title":"Environment Management","text":""},{"location":"deployment/#switch-between-environments","title":"Switch Between Environments","text":"<pre><code># List all environments\nazd env list\n\n# Switch environment\nazd env select &lt;environment-name&gt;\n\n# View current variables\nazd env get-values\n</code></pre>"},{"location":"deployment/#update-configurations","title":"Update Configurations","text":"<pre><code># View all environment variables\nazd env get-values\n\n# Update location\nazd env set AZURE_LOCATION &lt;azure-region&gt;\n\n# Update phone number\nazd env set ACS_SOURCE_PHONE_NUMBER &lt;phone-number&gt;\n\n# Apply changes\nazd deploy\n</code></pre>"},{"location":"deployment/#environment-files-for-local-development","title":"Environment Files for Local Development","text":"<p>Generate environment files from deployed infrastructure:</p> <pre><code># Generate .env file from Terraform outputs\nmake generate_env_from_terraform\n\n# Update with Key Vault secrets\nmake update_env_with_secrets\n\n# View current environment file\nmake show_env_file\n</code></pre>"},{"location":"deployment/#backend-storage-configuration","title":"Backend Storage Configuration","text":""},{"location":"deployment/#terraform-remote-state","title":"Terraform Remote State","text":""},{"location":"deployment/#for-azure-developer-cli-deployments","title":"For Azure Developer CLI Deployments","text":"<p>Remote state is automatically configured by the <code>azd</code> pre-provision hooks. No manual setup required.</p>"},{"location":"deployment/#for-direct-terraform-deployments","title":"For Direct Terraform Deployments","text":"<p>You have two options for managing Terraform state:</p> <p>Option 1: Bring Your Own Storage (BYOS) Set environment variables for your existing storage account:</p> <pre><code>export RS_STORAGE_ACCOUNT=\"yourstorageaccount\"\nexport RS_CONTAINER_NAME=\"tfstate\"\nexport RS_RESOURCE_GROUP=\"your-rg\"\nexport RS_STATE_KEY=\"rtaudioagent.tfstate\"\n</code></pre> <p>Option 2: Configure backend.tf manually <pre><code># Copy the example and configure\ncp infra/terraform/backend.tf.example infra/terraform/backend.tf\n\n# Edit backend.tf with your storage account details\nterraform {\n  backend \"azurerm\" {\n    resource_group_name  = \"your-terraform-state-rg\"\n    storage_account_name = \"yourtfstateaccount\"\n    container_name       = \"tfstate\"\n    key                  = \"rtaudioagent.tfstate\"\n    use_azuread_auth     = true\n    subscription_id      = \"your-subscription-id\"\n  }\n}\n</code></pre></p>"},{"location":"deployment/#create-storage-account-for-terraform-state","title":"Create Storage Account for Terraform State","text":"<p>If you don't have a storage account for Terraform state:</p> <pre><code># Set variables\nRG_NAME=\"rg-terraform-state\"\nSTORAGE_NAME=\"tfstate$(openssl rand -hex 4)\"\nLOCATION=\"eastus\"\n\n# Create resource group and storage account\naz group create --name $RG_NAME --location $LOCATION\naz storage account create \\\n  --name $STORAGE_NAME \\\n  --resource-group $RG_NAME \\\n  --location $LOCATION \\\n  --sku Standard_LRS \\\n  --encryption-services blob\n\n# Create container\naz storage container create \\\n  --name tfstate \\\n  --account-name $STORAGE_NAME \\\n  --auth-mode login\n\necho \"Configure your backend.tf with:\"\necho \"  storage_account_name = \\\"$STORAGE_NAME\\\"\"\necho \"  resource_group_name  = \\\"$RG_NAME\\\"\"\n</code></pre>"},{"location":"deployment/#required-terraform-versions","title":"Required Terraform Versions","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.1.7, &lt; 2.0.0\"\n\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~&gt; 4.0\"\n    }\n    azuread = {\n      source  = \"hashicorp/azuread\"\n      version = \"~&gt; 3.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~&gt; 3.0\"\n    }\n    azapi = {\n      source = \"Azure/azapi\"\n    }\n  }\n}\n</code></pre>"},{"location":"deployment/#monitoring-and-troubleshooting","title":"Monitoring and Troubleshooting","text":""},{"location":"deployment/#deployment-monitoring","title":"Deployment Monitoring","text":""},{"location":"deployment/#azure-developer-cli","title":"Azure Developer CLI","text":"<pre><code># Check deployment status\nazd show\n\n# View environment details\nazd env get-values\n\n# View deployment logs\nazd deploy --debug\n</code></pre>"},{"location":"deployment/#direct-terraform","title":"Direct Terraform","text":"<pre><code># Check Terraform state\nterraform show\n\n# View outputs\nterraform output\n\n# Monitor deployment\nmake monitor_backend_deployment\nmake monitor_frontend_deployment\n</code></pre>"},{"location":"deployment/#container-app-logs","title":"Container App Logs","text":"<pre><code># Real-time logs\naz containerapp logs show \\\n    --name ca-voice-agent-backend \\\n    --resource-group $(azd env get-value AZURE_RESOURCE_GROUP) \\\n    --follow\n\n# Recent logs (last 100 lines)\naz containerapp logs show \\\n    --name ca-voice-agent-backend \\\n    --resource-group $(azd env get-value AZURE_RESOURCE_GROUP) \\\n    --tail 100\n</code></pre>"},{"location":"deployment/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":"Issue Symptoms Solution Terraform Init Fails Backend configuration errors, state lock issues Check storage account permissions, verify backend.tf configuration, ensure unique state key Container Won't Start App unavailable, startup errors, health check failures Check environment variables, verify managed identity permissions, review container logs Redis Connection Issues Cache connection timeouts, authentication failures Verify Redis Enterprise configuration, check firewall rules, validate access policies Phone Number Issues ACS calling fails, webhook errors Verify phone number is purchased and configured correctly, check webhook endpoints OpenAI Rate Limits API quota exceeded, throttling errors Check deployment capacity, monitor usage in Azure Portal, consider scaling up WebSocket Connection Fails Connection refused, handshake errors, timeout issues Check Container App ingress settings, test health endpoint, verify CORS configuration Live Voice API Issues Audio streaming problems, voice quality issues Verify Azure Speech Live Voice API configuration, check network connectivity, review audio codecs Agent Routing Problems Incorrect model selection, tool call failures Check agent configuration, verify model deployments, validate tool registry setup"},{"location":"deployment/#health-check-commands","title":"Health Check Commands","text":"<pre><code># Basic health check with detailed output\nBACKEND_URL=$(azd env get-value BACKEND_CONTAINER_APP_URL)\ncurl -v $BACKEND_URL/health\n\n# Test specific agent endpoints\ncurl $BACKEND_URL/api/v1/agents/health\ncurl $BACKEND_URL/api/v1/media/health\n\n# Test WebSocket connection with timeout\nBACKEND_FQDN=$(azd env get-value BACKEND_CONTAINER_APP_FQDN)\ntimeout 10s wscat -c wss://$BACKEND_FQDN/api/v1/stream\n\n# Check all service endpoints with status\necho \"Backend: https://$BACKEND_FQDN\"\necho \"Frontend: https://$(azd env get-value FRONTEND_CONTAINER_APP_FQDN)\"\necho \"Health: $BACKEND_URL/health\"\necho \"API Docs: $BACKEND_URL/docs\"\n</code></pre>"},{"location":"deployment/#advanced-debugging","title":"Advanced Debugging","text":""},{"location":"deployment/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Deploy with debug logging\nazd deploy --debug\n\n# Check container environment variables\naz containerapp show \\\n    --name $(azd env get-value BACKEND_CONTAINER_APP_NAME) \\\n    --resource-group $(azd env get-value AZURE_RESOURCE_GROUP) \\\n    --query \"properties.template.containers[0].env\"\n</code></pre>"},{"location":"deployment/#verify-rbac-assignments","title":"Verify RBAC Assignments","text":"<pre><code># Check managed identity assignments\naz role assignment list \\\n    --assignee $(azd env get-value BACKEND_UAI_PRINCIPAL_ID) \\\n    --all \\\n    --output table\n\n# Verify Key Vault access\naz keyvault show \\\n    --name $(azd env get-value AZURE_KEY_VAULT_NAME) \\\n    --query \"properties.accessPolicies\"\n</code></pre> <p>Need more help? For detailed troubleshooting steps, diagnostic commands, and solutions to common issues, see the comprehensive Troubleshooting Guide.</p>"},{"location":"deployment/#cleanup","title":"Cleanup","text":"<p>Remove all deployed resources:</p> <pre><code># Delete all resources (recommended)\nazd down\n\n# Delete specific environment\nazd env delete &lt;environment-name&gt;\n\n# Direct Terraform cleanup\ncd infra/terraform\nterraform destroy\n</code></pre>"},{"location":"deployment/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"deployment/#container-apps-scaling-configuration","title":"Container Apps Scaling Configuration","text":"<p>Update container app scaling in your <code>terraform.tfvars</code>:</p> <pre><code># Adjust based on expected load\ncontainer_apps_configuration = {\n  backend = {\n    min_replicas = 1\n    max_replicas = 10\n    cpu_limit    = \"1.0\"\n    memory_limit = \"2Gi\"\n  }\n  frontend = {\n    min_replicas = 1\n    max_replicas = 5\n    cpu_limit    = \"0.5\"\n    memory_limit = \"1Gi\"\n  }\n}\n</code></pre>"},{"location":"deployment/#model-configuration","title":"Model Configuration","text":"<p>Customize OpenAI model deployments for the latest supported models:</p> <pre><code>model_deployments = [\n  {\n    name     = \"gpt-4-1-mini\"\n    version  = \"2024-11-20\"\n    sku_name = \"DataZoneStandard\"\n    capacity = 100  # Increase for higher throughput\n  },\n  {\n    name     = \"o3-mini\"\n    version  = \"2025-01-31\"\n    sku_name = \"DataZoneStandard\"\n    capacity = 50   # Adjust based on reasoning workload\n  }\n]\n</code></pre>"},{"location":"deployment/#security-hardening","title":"Security Hardening","text":"<p>For production deployments, consider:</p> <pre><code># Enhanced security settings\ndisable_local_auth = true\nenable_redis_ha    = true\nprincipal_type     = \"ServicePrincipal\"  # For CI/CD deployments\n\n# Use higher Redis SKU for production\nredis_sku = \"Enterprise_E20\"\n</code></pre>"},{"location":"deployment/#multi-region-deployment","title":"Multi-Region Deployment","text":"<p>Configure secondary regions for OpenAI and Cosmos DB:</p> <pre><code># Primary location\nlocation = \"eastus\"\n\n# Secondary locations for specific services\nopenai_location   = \"westus2\"\ncosmosdb_location = \"westus\"\n</code></pre>"},{"location":"deployment/#support-next-steps","title":"Support &amp; Next Steps","text":"<p>Additional Resources &amp; Best Practices</p> <p>Always test locally first to isolate issues before deploying to Azure. Use the comprehensive load testing framework in <code>tests/load/</code> to validate performance under realistic conditions.</p> <ul> <li>Local Development Guide - Set up and test on your local machine</li> <li>Troubleshooting Guide - Comprehensive problem-solving guide</li> <li>Repository Structure - Understand the codebase layout</li> <li>Utilities &amp; Services - Core infrastructure components</li> <li>Terraform Infrastructure README - Detailed infrastructure documentation</li> </ul>"},{"location":"deployment/cicd/","title":"CI/CD","text":""},{"location":"deployment/cicd/#cicd-configuration-guide","title":"CI/CD Configuration Guide","text":"<p>This guide explains how to configure the deployment scripts for CI/CD environments where interactive prompts are not possible.</p>"},{"location":"deployment/cicd/#environment-detection","title":"Environment Detection","text":"<p>The scripts automatically detect CI/CD environments by checking: - <code>CI</code> environment variable (set by most CI systems) - <code>GITHUB_ACTIONS</code> environment variable (set by GitHub Actions) - <code>AZD_SKIP_INTERACTIVE</code> environment variable (custom override)</p>"},{"location":"deployment/cicd/#bypass-interactive-prompts","title":"Bypass Interactive Prompts","text":""},{"location":"deployment/cicd/#method-1-automatic-detection","title":"Method 1: Automatic Detection","text":"<p>Most CI/CD systems set the <code>CI</code> environment variable automatically: <pre><code># GitHub Actions - automatically sets CI=true\n# Azure DevOps - automatically sets CI=true\n# Jenkins - automatically sets CI=true\n</code></pre></p>"},{"location":"deployment/cicd/#method-2-manual-override","title":"Method 2: Manual Override","text":"<p>Set the bypass flag explicitly: <pre><code>export AZD_SKIP_INTERACTIVE=true\nazd up\n</code></pre></p>"},{"location":"deployment/cicd/#phone-number-configuration-in-cicd","title":"Phone Number Configuration in CI/CD","text":""},{"location":"deployment/cicd/#option-1-pre-configured-phone-number","title":"Option 1: Pre-configured Phone Number","text":"<pre><code># Set phone number via environment variable\nexport ACS_SOURCE_PHONE_NUMBER=\"+1234567890\"\nazd up\n</code></pre>"},{"location":"deployment/cicd/#option-2-auto-provision-phone-number","title":"Option 2: Auto-provision Phone Number","text":"<pre><code># Enable auto-provisioning\nazd env set ACS_AUTO_PROVISION_PHONE true\nazd up\n</code></pre>"},{"location":"deployment/cicd/#option-3-skip-phone-number","title":"Option 3: Skip Phone Number","text":"<pre><code># Just run without phone number (can be added later)\nazd up\n</code></pre>"},{"location":"deployment/cicd/#ssl-certificates-for-bicep-deployments","title":"SSL Certificates for Bicep Deployments","text":"<p>For Bicep deployments requiring SSL certificates:</p> <pre><code># Encode certificates to base64\nexport SSL_CERT_BASE64=$(base64 -w 0 &lt; path/to/cert.pem)\nexport SSL_KEY_BASE64=$(base64 -w 0 &lt; path/to/key.pem)\nazd up\n</code></pre>"},{"location":"deployment/cicd/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: Deploy Infrastructure\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Install azd\n        uses: Azure/setup-azd@v0.1.0\n\n      - name: Deploy with azd\n        env:\n          AZURE_ENV_NAME: production\n          AZURE_LOCATION: eastus\n          ACS_SOURCE_PHONE_NUMBER: ${{ secrets.ACS_PHONE_NUMBER }}\n          # CI is automatically set by GitHub Actions\n        run: |\n          azd auth login --client-id ${{ secrets.AZURE_CLIENT_ID }} \\\n            --client-secret ${{ secrets.AZURE_CLIENT_SECRET }} \\\n            --tenant-id ${{ secrets.AZURE_TENANT_ID }}\n\n          azd env new $AZURE_ENV_NAME\n          azd up --no-prompt\n</code></pre>"},{"location":"deployment/cicd/#azure-devops-pipeline-example","title":"Azure DevOps Pipeline Example","text":"<pre><code>trigger:\n  - main\n\npool:\n  vmImage: 'ubuntu-latest'\n\nvariables:\n  AZURE_ENV_NAME: production\n  AZURE_LOCATION: eastus\n\nsteps:\n  - task: AzureCLI@2\n    displayName: 'Deploy Infrastructure'\n    inputs:\n      azureSubscription: 'Your-Service-Connection'\n      scriptType: 'bash'\n      scriptLocation: 'inlineScript'\n      inlineScript: |\n        # Install azd\n        curl -fsSL https://aka.ms/install-azd.sh | bash\n\n        # CI is automatically set by Azure DevOps\n        export ACS_SOURCE_PHONE_NUMBER=$(ACS_PHONE_NUMBER)\n\n        azd auth login --client-id $(AZURE_CLIENT_ID) \\\n          --client-secret $(AZURE_CLIENT_SECRET) \\\n          --tenant-id $(AZURE_TENANT_ID)\n\n        azd env new $(AZURE_ENV_NAME)\n        azd up --no-prompt\n</code></pre>"},{"location":"deployment/cicd/#environment-variables-reference","title":"Environment Variables Reference","text":"Variable Description Required <code>AZD_SKIP_INTERACTIVE</code> Force non-interactive mode No (auto-detected) <code>CI</code> Standard CI indicator No (set by CI system) <code>GITHUB_ACTIONS</code> GitHub Actions indicator No (set by GitHub) <code>ACS_SOURCE_PHONE_NUMBER</code> Pre-configured phone number No <code>ACS_AUTO_PROVISION_PHONE</code> Auto-provision phone if missing No <code>SSL_CERT_BASE64</code> Base64 encoded SSL certificate No (Bicep only) <code>SSL_KEY_BASE64</code> Base64 encoded SSL private key No (Bicep only)"},{"location":"deployment/cicd/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/cicd/#scripts-still-prompting","title":"Scripts Still Prompting","text":"<ul> <li>Ensure <code>CI</code> or <code>AZD_SKIP_INTERACTIVE</code> is set</li> <li>Check script output for \"CI/CD mode detected\" message</li> </ul>"},{"location":"deployment/cicd/#phone-number-not-set","title":"Phone Number Not Set","text":"<ul> <li>Verify <code>ACS_SOURCE_PHONE_NUMBER</code> format (+1234567890)</li> <li>Check azd environment: <code>azd env get-values</code></li> </ul>"},{"location":"deployment/cicd/#ssl-certificate-issues-bicep","title":"SSL Certificate Issues (Bicep)","text":"<ul> <li>Ensure certificates are base64 encoded without line breaks</li> <li>Use <code>base64 -w 0</code> on Linux/Mac or <code>[Convert]::ToBase64String()</code> on PowerShell</li> </ul>"},{"location":"deployment/production/","title":"Production","text":""},{"location":"deployment/production/#real-time-agentic-ai-audio-application-production-readiness-checklist-call-center-scale","title":"\ud83d\udcde Real-Time Agentic AI Audio Application - Production Readiness Checklist (Call Center Scale)","text":"<p>Target scale: 10,000+ concurrent calls per minute Focus areas: Latency, Scalability, Resilience, Security, Observability</p>"},{"location":"deployment/production/#tier-1-critical-for-scale-stability-and-sla","title":"\ud83d\udd34 Tier 1 \u2013 Critical for Scale, Stability, and SLA","text":""},{"location":"deployment/production/#infrastructure-throughput","title":"\u2699\ufe0f Infrastructure &amp; Throughput","text":"<ul> <li>[ ] ACS Media Streaming endpoints regionally distributed and load-tested</li> <li>[ ] FastAPI backend horizontally scalable (Azure Container Apps with managed identity)</li> <li>[ ] Azure Managed Redis Enterprise with partitioned key strategy (<code>user:{id}:session:{sid}</code>)</li> <li>[ ] Azure Speech Services (STT/TTS) scaled using concurrency-aware provisioning</li> <li>[ ] Azure OpenAI with proper quota management and rate limiting</li> <li>[ ] Event Grid topics with dead letter queues for failed webhook deliveries</li> <li>[ ] Load tests simulate call volume end-to-end (ACS \u2192 EventGrid \u2192 STT \u2192 LLM \u2192 TTS \u2192 ACS)</li> <li>[ ] Container Registry with vulnerability scanning enabled</li> <li>[ ] Azure Container Apps Environment with dedicated compute and networking</li> <li>[ ] Cosmos DB with MongoDB API scaled for concurrent session storage</li> </ul>"},{"location":"deployment/production/#state-session-handling","title":"\ud83e\udde0 State &amp; Session Handling","text":"<ul> <li>[ ] Redis TTL and namespaced keys to isolate concurrent sessions</li> <li>[ ] Cosmos DB backup of session transcript, TTS responses, and agent logs with geo-redundancy</li> <li>[ ] Blob Storage for audio recordings with lifecycle management policies</li> <li>[ ] Correlation IDs (<code>callConnectionId</code>, <code>session_id</code>, <code>agent_id</code>) used across all layers</li> <li>[ ] Session state recovery mechanisms for mid-call failures</li> <li>[ ] Memory agents (labs/04-memory-agents.ipynb) with persistent context storage</li> <li>[ ] Barge-in detection and real-time audio stream management</li> </ul>"},{"location":"deployment/production/#observability-resilience","title":"\ud83d\udd0d Observability &amp; Resilience","text":"<ul> <li>[ ] Health checks at every stage: WebSocket \u2192 STT \u2192 LLM \u2192 TTS \u2192 ACS injection</li> <li>[ ] Circuit breakers and fallback utterances if STT/LLM/TTS fails</li> <li>[ ] Application Insights distributed tracing linked across services</li> <li>[ ] Real-time alerting on:</li> <li>STT delay &gt; 500ms</li> <li>TTS generation &gt; 1s</li> <li>Agent latency &gt; 2.5s</li> <li>Event Grid delivery failures</li> <li>Container Apps scaling events</li> <li>Redis connection failures</li> <li>[ ] Structured logging with correlation IDs in FastAPI backend</li> <li>[ ] Dead letter queue monitoring for failed events</li> </ul>"},{"location":"deployment/production/#tier-2-optimization-and-cost-control","title":"\ud83d\udfe1 Tier 2 \u2013 Optimization and Cost Control","text":""},{"location":"deployment/production/#latency-and-response-optimization","title":"\u23f1\ufe0f Latency and Response Optimization","text":"<ul> <li>[ ] STT chunking tuned (PushAudioInputStream at 250ms intervals)</li> <li>[ ] Intermediate STT results enabled for real-time transcription</li> <li>[ ] Common TTS phrases pre-cached in Redis or Blob Storage</li> <li>[ ] LLM prompt optimization with token management and summarization</li> <li>[ ] STT/LLM parallel processing (speculative execution where possible)</li> <li>[ ] Voice cloning and neural voice switching optimized for latency</li> <li>[ ] Multilingual support (labs/05-speech-to-text-multilingual.ipynb) with auto-detection</li> <li>[ ] Real-time transcription streaming via WebSocket connections</li> <li>[ ] Audio quality optimization for different network conditions</li> </ul>"},{"location":"deployment/production/#cost-optimization","title":"\ud83d\udcb0 Cost Optimization","text":"<ul> <li>[ ] Container Apps with consumption-based scaling and spot instances where appropriate</li> <li>[ ] Redis Enterprise sized based on peak concurrency with reserved instances</li> <li>[ ] Speech Services quota management and regional failover</li> <li>[ ] Azure OpenAI token usage monitoring and optimization</li> <li>[ ] Auto-end idle sessions after 30\u201360 seconds with graceful cleanup</li> <li>[ ] Call admission control at ingress layer with queue management</li> <li>[ ] Blob Storage tiering for long-term audio archive storage</li> <li>[ ] Cosmos DB autoscale configuration based on RU consumption patterns</li> </ul>"},{"location":"deployment/production/#development-deployment-pipeline","title":"\ud83d\udd27 Development &amp; Deployment Pipeline","text":"<ul> <li>[ ] Terraform infrastructure (infra-tf/) with state management and drift detection</li> <li>[ ] Azure Developer CLI (azd) deployment pipeline with environment promotion</li> <li>[ ] Pre-commit hooks for code quality and security scanning</li> <li>[ ] Container image vulnerability scanning and signing</li> <li>[ ] Blue-green deployment strategy for zero-downtime updates</li> <li>[ ] Feature flags for gradual rollout of new capabilities</li> <li>[ ] Load testing pipeline (labs/03-latency-arena.ipynb) integrated with CI/CD</li> <li>[ ] Infrastructure as Code validation and policy compliance</li> </ul>"},{"location":"deployment/production/#tier-3-compliance-security-and-ux","title":"\ud83d\udfe2 Tier 3 \u2013 Compliance, Security, and UX","text":""},{"location":"deployment/production/#security-privacy","title":"\ud83d\udd10 Security &amp; Privacy","text":"<ul> <li>[ ] Managed Identity authentication across all Azure services (no connection strings in production)</li> <li>[ ] Key Vault integration for all secrets with rotation policies</li> <li>[ ] Private endpoints and RBAC enforced on Redis, Cosmos DB, Blob, Speech Services</li> <li>[ ] Network security groups and application gateway with WAF</li> <li>[ ] PII/PHI redaction in logs and stored transcripts</li> <li>[ ] Data retention policies with automated cleanup and compliance reporting</li> <li>[ ] GDPR/HIPAA compliance documentation and data processing agreements</li> <li>[ ] Audit logging for all data access and modifications</li> <li>[ ] Encryption at rest and in transit for all data stores</li> <li>[ ] Certificate management and TLS termination</li> </ul>"},{"location":"deployment/production/#voice-experience-agent-ux","title":"\ud83d\udde3\ufe0f Voice Experience &amp; Agent UX","text":"<ul> <li>[ ] Live interruption (barge-in) stops TTS playback with smooth transitions</li> <li>[ ] Graceful fallback on silence, disconnection, or misunderstanding</li> <li>[ ] Dynamic voice switching based on context and user preferences</li> <li>[ ] Voice biometric or MFA verification for sensitive operations</li> <li>[ ] Emotion detection and adaptive response generation</li> <li>[ ] Real-time sentiment analysis with escalation triggers</li> <li>[ ] Multi-turn conversation context management with memory persistence</li> <li>[ ] Language detection with automatic switching capabilities</li> </ul>"},{"location":"deployment/production/#analytics-business-intelligence","title":"\ud83d\udcca Analytics &amp; Business Intelligence","text":"<ul> <li>[ ] Call analytics dashboard with real-time metrics</li> <li>[ ] Conversation quality scoring and improvement recommendations</li> <li>[ ] Business metrics tracking (resolution rates, satisfaction scores, etc.)</li> <li>[ ] A/B testing framework for agent response optimization</li> <li>[ ] Performance benchmarking against baseline metrics</li> <li>[ ] Customer journey mapping and interaction analysis</li> <li>[ ] Predictive analytics for call volume and resource planning</li> </ul>"},{"location":"deployment/production/#tier-4-advanced-features-and-innovation","title":"\ud83d\ude80 Tier 4 \u2013 Advanced Features and Innovation","text":""},{"location":"deployment/production/#aiml-enhancements","title":"\ud83e\udd16 AI/ML Enhancements","text":"<ul> <li>[ ] Real-time model fine-tuning based on conversation outcomes</li> <li>[ ] Multi-agent orchestration for complex scenarios</li> <li>[ ] Retrieval-Augmented Generation (RAG) with dynamic knowledge updates</li> <li>[ ] Intent recognition and automatic routing</li> <li>[ ] Conversation summarization with key insights extraction</li> <li>[ ] Proactive engagement based on user behavior patterns</li> <li>[ ] Voice synthesis optimization for brand consistency</li> </ul>"},{"location":"deployment/production/#enterprise-integration","title":"\ud83c\udf10 Enterprise Integration","text":"<ul> <li>[ ] CRM integration with real-time data synchronization</li> <li>[ ] Knowledge base integration with dynamic content updates</li> <li>[ ] Workflow automation with business process integration</li> <li>[ ] Third-party API resilience and failover mechanisms</li> <li>[ ] SSO integration with enterprise identity providers</li> <li>[ ] Multi-tenant architecture for enterprise customers</li> <li>[ ] API versioning and backward compatibility</li> </ul>"},{"location":"deployment/production/#operational-excellence","title":"\ud83d\udd04 Operational Excellence","text":"<ul> <li>[ ] Chaos engineering with failure injection testing</li> <li>[ ] Capacity planning with predictive scaling</li> <li>[ ] Disaster recovery with RTO/RPO objectives</li> <li>[ ] Business continuity planning and testing</li> <li>[ ] Performance regression testing automation</li> <li>[ ] Incident response playbooks and automated remediation</li> <li>[ ] Configuration management with environment consistency</li> </ul>"},{"location":"deployment/production/#production-readiness-gates","title":"\ud83d\udccb Production Readiness Gates","text":""},{"location":"deployment/production/#pre-production-checklist","title":"Pre-Production Checklist","text":"<ul> <li>[ ] All Tier 1 items completed and validated</li> <li>[ ] Load testing passed at target scale (10,000+ concurrent calls)</li> <li>[ ] Security penetration testing completed</li> <li>[ ] Disaster recovery procedures tested</li> <li>[ ] Monitoring and alerting validated</li> <li>[ ] Support procedures documented and trained</li> </ul>"},{"location":"deployment/production/#go-live-checklist","title":"Go-Live Checklist","text":"<ul> <li>[ ] Production environment validated</li> <li>[ ] Rollback procedures tested</li> <li>[ ] Support team on standby</li> <li>[ ] Monitoring dashboards active</li> <li>[ ] Incident response team briefed</li> <li>[ ] Performance baselines established</li> </ul>"},{"location":"deployment/production/#post-launch-checklist","title":"Post-Launch Checklist","text":"<ul> <li>[ ] Performance metrics within SLA bounds</li> <li>[ ] User feedback collection active</li> <li>[ ] Cost optimization opportunities identified</li> <li>[ ] Scaling patterns documented</li> <li>[ ] Lessons learned documented</li> <li>[ ] Continuous improvement roadmap updated</li> </ul>"},{"location":"deployment/production/#success-metrics","title":"\ud83d\udcc8 Success Metrics","text":""},{"location":"deployment/production/#technical-kpis","title":"Technical KPIs","text":"<ul> <li>Latency: &lt; 2.5s end-to-end response time</li> <li>Availability: 99.9% uptime SLA</li> <li>Scalability: Handle 10,000+ concurrent calls</li> <li>Quality: &lt; 1% call drop rate</li> <li>Security: Zero security incidents</li> </ul>"},{"location":"deployment/production/#business-kpis","title":"Business KPIs","text":"<ul> <li>Customer Satisfaction: &gt; 4.5/5 rating</li> <li>Resolution Rate: &gt; 85% first-call resolution</li> <li>Cost per Call: &lt; $X target (define based on business model)</li> <li>Agent Efficiency: &gt; 90% automation rate for common queries</li> <li>Revenue Impact: Measurable improvement in customer outcomes</li> </ul>"},{"location":"deployment/production/#tools-and-resources","title":"\ud83d\udd27 Tools and Resources","text":""},{"location":"deployment/production/#monitoring-stack","title":"Monitoring Stack","text":"<ul> <li>Application Insights for distributed tracing</li> <li>Azure Monitor for infrastructure metrics</li> <li>Log Analytics for centralized logging</li> <li>Grafana/Power BI for business dashboards</li> </ul>"},{"location":"deployment/production/#testing-tools","title":"Testing Tools","text":"<ul> <li>Azure Load Testing for performance validation</li> <li>Chaos Mesh for resilience testing</li> <li>Postman/Newman for API testing</li> <li>Playwright for end-to-end testing</li> </ul>"},{"location":"deployment/production/#security-tools","title":"Security Tools","text":"<ul> <li>Azure Security Center for compliance monitoring</li> <li>Azure Sentinel for threat detection</li> <li>Defender for Cloud for vulnerability scanning</li> <li>Azure Policy for governance enforcement</li> </ul>"},{"location":"getting-started/","title":"Quick Start Guide","text":""},{"location":"getting-started/#getting-started","title":"Getting Started","text":"<p>Real-Time Voice AI Accelerator</p> <p>Get your voice agent running with Azure Communication Services, Speech Services, and AI in just a few steps.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"System RequirementsAzure Requirements <ul> <li>Python: 3.11 or higher</li> <li>Operating System: Windows 10+, macOS 10.15+, or Linux</li> <li>Memory: Minimum 4GB RAM (8GB recommended)</li> <li>Network: Internet connectivity for Azure services</li> </ul> <ul> <li>Azure Subscription: Create one for free if you don't have one</li> <li>Azure CLI: Install Azure CLI for resource management</li> </ul> <p>Microsoft Learn Resources</p> <ul> <li>Azure Free Account Setup - Step-by-step account creation</li> <li>Azure CLI Fundamentals - Essential CLI commands</li> </ul>"},{"location":"getting-started/#learning-paths","title":"Learning Paths","text":"\ud83d\ude80 Quick Start (15 minutes)\ud83c\udfd7\ufe0f Infrastructure First\ud83d\udd27 Deep Dive <p>Get up and running fast:</p> <ol> <li>Local Development Guide - Complete setup with raw commands</li> <li>Architecture Overview - Understand the system design</li> <li>API Reference - Explore available endpoints</li> </ol> <p>Best for: Developers who want to see the accelerator in action immediately</p> <p>Set up Azure resources properly:</p> <ol> <li>Production Deployment - Infrastructure provisioning</li> <li>Configuration Details - Advanced configuration options</li> <li>Local Development Guide - Connect to your infrastructure</li> </ol> <p>Best for: Architects and teams planning production deployments</p> <p>Understand the complete system:</p> <ol> <li>Architecture Overview - System design and patterns</li> <li>Data Flow Patterns - Processing pipeline architecture</li> <li>LLM Orchestration - AI routing and conversation management</li> <li>Operations Guide - Monitoring and troubleshooting</li> </ol> <p>Best for: Technical leads and teams building custom voice applications</p>"},{"location":"getting-started/#azure-setup-requirements","title":"Azure Setup Requirements","text":"<p>Required Azure Resources</p> <p>The accelerator requires these Azure services for full functionality:</p> Service Purpose Required For Speech Services Text-to-Speech, Speech-to-Text All voice features Communication Services Phone calls, WebSocket media Phone integration AI Foundry / OpenAI Conversation intelligence AI agent responses Redis Cache Session state management Multi-turn conversations Cosmos DB Conversation persistence Analytics, compliance <p>Quick Azure Setup: <pre><code># Clone the repository\ngit clone https://github.com/Azure-Samples/art-voice-agent-accelerator.git\ncd art-voice-agent-accelerator\n\n# Deploy infrastructure (choose one)\nazd provision  # Azure Developer CLI (recommended)\n# or use Terraform/Bicep directly\n</code></pre></p>"},{"location":"getting-started/#development-approaches","title":"Development Approaches","text":"\ud83c\udfc3\u200d\u2642\ufe0f Fast Track\ud83c\udfed Production Ready\ud83d\udd2c Custom Development <p>Start developing immediately:</p> <ul> <li>Goal: Voice agent running locally in 15 minutes</li> <li>Path: Local Development Guide</li> <li>Infrastructure: Minimal (Speech Services only)</li> <li>Best for: Proof of concepts, learning, simple demos</li> </ul> <p>Enterprise deployment preparation:</p> <ul> <li>Goal: Scalable, secure, monitored deployment</li> <li>Path: Production Deployment \u2192 Local Development</li> <li>Infrastructure: Complete (all Azure services)</li> <li>Best for: Production applications, enterprise environments</li> </ul> <p>Extend and customize the accelerator:</p> <ul> <li>Goal: Build custom voice applications</li> <li>Path: Architecture Deep Dive \u2192 Local Development</li> <li>Infrastructure: As needed for your use case</li> <li>Best for: Custom voice solutions, specialized industries</li> </ul>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<p>Community &amp; Support Resources</p> <p>Documentation: - Troubleshooting Guide - Common issues and solutions - API Reference - Complete endpoint documentation - Examples &amp; Samples - Practical implementation examples</p> <p>Community: - GitHub Issues - Report bugs and request features - GitHub Discussions - Community Q&amp;A - Microsoft Q&amp;A - Official Microsoft support</p>"},{"location":"getting-started/#whats-next","title":"What's Next?","text":"<p>Choose your path above and start building your voice-powered applications! Most developers find success starting with the Local Development Guide to see the accelerator in action immediately.</p> <p>New to Voice AI?</p> <p>Check out the Architecture Overview first to understand how real-time voice processing works with Azure Communication Services and Speech Services.</p>"},{"location":"getting-started/configuration/","title":"Configuration Guide","text":""},{"location":"getting-started/configuration/#configuration-guide","title":"Configuration Guide","text":"<p>Fine-Tune Your Voice Agent</p> <p>Comprehensive configuration options for environment variables, authentication, and optional features.</p>"},{"location":"getting-started/configuration/#environment-setup","title":"Environment Setup","text":""},{"location":"getting-started/configuration/#step-1-environment-file-creation","title":"Step 1: Environment File Creation","text":"<p>Quick Setup</p> <p>Start with the provided template for all required variables.</p> Copy and configure environment template<pre><code># Copy the environment template\ncp .env.example .env\n\n# Edit with your preferred editor\ncode .env  # VS Code\n# or nano .env, vim .env, etc.\n</code></pre>"},{"location":"getting-started/configuration/#step-2-required-configuration","title":"Step 2: Required Configuration","text":"Azure Speech ServicesAzure Communication ServicesOptional Services Variable Required Description Example <code>AZURE_SPEECH_KEY</code> \u2705 (unless using managed identity) Speech resource key <code>1a2b3c4d5e6f...</code> <code>AZURE_SPEECH_REGION</code> \u2705 Azure region identifier <code>eastus</code>, <code>westeurope</code> <code>AZURE_SPEECH_ENDPOINT</code> Optional Custom endpoint URL <code>https://custom.cognitiveservices.azure.com</code> <code>AZURE_SPEECH_RESOURCE_ID</code> Optional Full resource ID for managed identity <code>/subscriptions/.../accounts/speech-svc</code> Variable Required Description Example <code>AZURE_COMMUNICATION_CONNECTION_STRING</code> \u2705 for call automation ACS connection string <code>endpoint=https://...;accesskey=...</code> <code>ACS_RESOURCE_CONNECTION_STRING</code> Alternative Legacy naming convention Same format as above Variable Required Description Example <code>AZURE_OPENAI_ENDPOINT</code> Optional Azure OpenAI service endpoint <code>https://my-openai.openai.azure.com</code> <code>AZURE_OPENAI_KEY</code> Optional Azure OpenAI API key <code>sk-...</code> <code>REDIS_CONNECTION_STRING</code> For session state Redis cache connection <code>redis://localhost:6379</code> <p>Microsoft Learn Resources</p> <ul> <li>Speech Services Keys - Get your Speech Services credentials</li> <li>Communication Services Setup - Create ACS resources</li> <li>Azure OpenAI Service - Set up OpenAI integration</li> </ul>"},{"location":"getting-started/configuration/#managed-identity-recommended-for-production","title":"Managed Identity (Recommended for Production)","text":"<p>Enhanced Security</p> <p>Use managed identity to eliminate API keys in production environments.</p>"},{"location":"getting-started/configuration/#configuration-for-managed-identity","title":"Configuration for Managed Identity","text":"Managed identity environment variables<pre><code># Disable API key authentication\nAZURE_SPEECH_KEY=\"\"\n\n# Required: Region and Resource ID\nAZURE_SPEECH_REGION=eastus\nAZURE_SPEECH_RESOURCE_ID=/subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;resource-group&gt;/providers/Microsoft.CognitiveServices/accounts/&lt;speech-service-name&gt;\n\n# Enable managed identity\nUSE_MANAGED_IDENTITY=true\n</code></pre>"},{"location":"getting-started/configuration/#azure-role-assignments","title":"Azure Role Assignments","text":"Required RolesOptional Roles <p>For Speech Services: Assign Speech Services role<pre><code># Get your managed identity principal ID\nIDENTITY_PRINCIPAL_ID=$(az identity show \\\n    --name your-managed-identity \\\n    --resource-group your-resource-group \\\n    --query principalId -o tsv)\n\n# Assign Cognitive Services User role\naz role assignment create \\\n    --assignee $IDENTITY_PRINCIPAL_ID \\\n    --role \"Cognitive Services User\" \\\n    --scope \"/subscriptions/&lt;sub&gt;/resourceGroups/&lt;rg&gt;/providers/Microsoft.CognitiveServices/accounts/&lt;speech-name&gt;\"\n</code></pre></p> <p>For Azure OpenAI: Assign OpenAI role<pre><code>az role assignment create \\\n    --assignee $IDENTITY_PRINCIPAL_ID \\\n    --role \"Cognitive Services OpenAI User\" \\\n    --scope \"/subscriptions/&lt;sub&gt;/resourceGroups/&lt;rg&gt;/providers/Microsoft.CognitiveServices/accounts/&lt;openai-name&gt;\"\n</code></pre></p> <p>Microsoft Learn Resources</p> <ul> <li>Managed Identity Overview - Understanding managed identities</li> <li>Role-Based Access Control - Azure RBAC fundamentals</li> </ul>"},{"location":"getting-started/configuration/#voice-configuration","title":"Voice Configuration","text":"<p>Customization Options</p> <p>Tailor voice characteristics for your specific use case and audience.</p>"},{"location":"getting-started/configuration/#default-voice-settings","title":"Default Voice Settings","text":"<p>Customize default voices via <code>apps/rtagent/backend/config/voice_config.py</code>. You can override values with environment variables:</p> Voice SelectionAdvanced Settings Voice configuration options<pre><code># Primary voice selection\nDEFAULT_VOICE_ALIAS=support_contact_center\nDEFAULT_VOICE_NAME=en-US-JennyMultilingualNeural\n\n# Voice characteristics  \nDEFAULT_VOICE_STYLE=customer-service\nDEFAULT_VOICE_RATE=+10%\nDEFAULT_VOICE_PITCH=medium\n</code></pre> Advanced voice options<pre><code># Audio quality settings\nAUDIO_OUTPUT_FORMAT=audio-24khz-48kbitrate-mono-mp3\nSAMPLE_RATE=24000\n\n# Streaming configuration\nENABLE_STREAMING=true\nSTREAM_CHUNK_SIZE=1024\n\n# Pronunciation and SSML\nENABLE_SSML_PROCESSING=true\nPRONUNCIATION_LEXICON_URI=https://example.com/lexicon.xml\n</code></pre>"},{"location":"getting-started/configuration/#voice-aliases","title":"Voice Aliases","text":"<p>Configure voice aliases for different scenarios:</p> Alias Voice Style Use Case <code>support_contact_center</code> <code>en-US-JennyMultilingualNeural</code> <code>customer-service</code> Customer support calls <code>sales_assistant</code> <code>en-US-EmmaNeural</code> <code>friendly</code> Sales and marketing <code>technical_narrator</code> <code>en-US-BrianNeural</code> <code>newscast</code> Technical documentation <code>casual_chat</code> <code>en-US-SaraNeural</code> <code>chat</code> Informal conversations <p>Microsoft Learn Resources</p> <ul> <li>Voice Gallery - Browse all available voices</li> <li>SSML Reference - Speech Synthesis Markup Language</li> <li>Voice Tuning - Advanced voice customization</li> </ul>"},{"location":"getting-started/configuration/#telemetry-observability","title":"Telemetry &amp; Observability","text":"<p>Production Monitoring</p> <p>Enable comprehensive monitoring and tracing for production deployments.</p>"},{"location":"getting-started/configuration/#opentelemetry-configuration","title":"OpenTelemetry Configuration","text":"OpenTelemetry environment variables<pre><code># Azure Monitor integration\nOTEL_EXPORTER_OTLP_ENDPOINT=https://&lt;workspace-id&gt;.monitor.azure.com/v1/traces\nOTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Bearer &lt;instrumentation-key&gt;\"\nOTEL_SERVICE_NAME=rt-voice-agent\nOTEL_SERVICE_VERSION=1.0.0\n\n# Service identification\nOTEL_RESOURCE_ATTRIBUTES=service.name=rt-voice-agent,service.version=1.0.0,deployment.environment=production\n\n# Tracing configuration\nOTEL_TRACES_EXPORTER=otlp\nOTEL_METRICS_EXPORTER=otlp\nOTEL_LOGS_EXPORTER=otlp\n</code></pre>"},{"location":"getting-started/configuration/#logging-configuration","title":"Logging Configuration","text":"DevelopmentProduction Development logging<pre><code>LOG_LEVEL=DEBUG\nLOG_FORMAT=human-readable\nENABLE_CORRELATION_ID=true\nLOG_TO_FILE=false\n</code></pre> Production logging<pre><code>LOG_LEVEL=INFO\nLOG_FORMAT=json\nENABLE_CORRELATION_ID=true\nLOG_TO_FILE=true\nLOG_FILE_PATH=/var/log/voice-agent/app.log\nLOG_ROTATION_SIZE=10MB\nLOG_RETENTION_DAYS=30\n</code></pre>"},{"location":"getting-started/configuration/#application-insights-setup","title":"Application Insights Setup","text":"<p>Quick Setup</p> <p>Use the Makefile command to bootstrap Application Insights automatically.</p> Bootstrap Application Insights<pre><code># Configure Azure Monitor and Application Insights\nmake configure_observability\n\n# This will:\n# 1. Create Application Insights workspace\n# 2. Configure connection strings\n# 3. Set up log analytics workspace\n# 4. Update .env with correct values\n</code></pre> <p>Microsoft Learn Resources</p> <ul> <li>Application Insights - Application performance monitoring</li> <li>OpenTelemetry with Azure - OpenTelemetry integration guide</li> <li>Log Analytics - Centralized logging solution</li> </ul>"},{"location":"getting-started/configuration/#storage-and-file-management","title":"Storage and File Management","text":""},{"location":"getting-started/configuration/#local-storage-configuration","title":"Local Storage Configuration","text":"Storage environment variables<pre><code># Audio output configuration\nAUDIO_OUTPUT_DIR=./output/audio\nENABLE_AUDIO_CACHE=true\nAUDIO_CACHE_TTL=3600  # 1 hour in seconds\n\n# Application cache\nVOICE_AGENT_CACHE_DIR=./cache\nCACHE_MAX_SIZE=1GB\n\n# Temporary files\nTEMP_FILE_DIR=./tmp\nTEMP_FILE_CLEANUP_INTERVAL=300  # 5 minutes\n</code></pre>"},{"location":"getting-started/configuration/#headless-environment-settings","title":"Headless Environment Settings","text":"<p>CI/CD and Headless Deployments</p> <p>Disable audio playback for automated environments and server deployments.</p> Headless configuration<pre><code># Disable local audio playback\nTTS_ENABLE_LOCAL_PLAYBACK=false\n\n# Headless environment detection\nFORCE_HEADLESS_MODE=true\n\n# Alternative audio output\nAUDIO_OUTPUT_FORMAT=file  # Options: file, stream, buffer\nSAVE_AUDIO_FILES=true     # Save to disk for debugging\n```## :material-key: Secrets Management\n\n!!! danger \"Security Best Practices\"\n    Never commit secrets to version control. Use secure secret management for all environments.\n\n### Local Development\n\n=== \"Using direnv\"\n    ```bash title=\"Setup direnv for automatic environment loading\"\n    # Install direnv (macOS)\n    brew install direnv\n\n    # Add to shell configuration\n    echo 'eval \"$(direnv hook zsh)\"' &gt;&gt; ~/.zshrc\n    source ~/.zshrc\n\n    # Create .envrc file\n    echo \"dotenv .env\" &gt; .envrc\n    direnv allow .\n    ```\n\n=== \"Using python-dotenv\"\n    ```python title=\"Load environment variables in Python\"\n    from dotenv import load_dotenv\n    import os\n\n    # Load .env file\n    load_dotenv()\n\n    # Access variables\n    speech_key = os.getenv('AZURE_SPEECH_KEY')\n    speech_region = os.getenv('AZURE_SPEECH_REGION')\n    ```\n\n### GitHub Actions\n\n```yaml title=\"GitHub Actions secrets configuration\"\n# .github/workflows/deploy.yml\nenv:\n  AZURE_SPEECH_KEY: ${{ secrets.AZURE_SPEECH_KEY }}\n  AZURE_SPEECH_REGION: ${{ secrets.AZURE_SPEECH_REGION }}\n  AZURE_COMMUNICATION_CONNECTION_STRING: ${{ secrets.ACS_CONNECTION_STRING }}\n</code></pre> <p>Setup Steps: 1. Go to Settings \u2192 Secrets and variables \u2192 Actions 2. Click New repository secret 3. Add each required secret from your <code>.env</code> file</p>"},{"location":"getting-started/configuration/#azure-key-vault-integration","title":"Azure Key Vault Integration","text":"Terraform/AZD DeploymentManual Key Vault Setup Sync Key Vault secrets to local environment<pre><code># After infrastructure deployment\nmake update_env_with_secrets\n\n# This will:\n# 1. Read secrets from Azure Key Vault\n# 2. Update your local .env file\n# 3. Validate all required variables are set\n</code></pre> Azure Key Vault commands<pre><code># Store secrets in Key Vault\naz keyvault secret set \\\n    --vault-name your-key-vault \\\n    --name \"azure-speech-key\" \\\n    --value \"your-speech-key-here\"\n\n# Retrieve secrets\naz keyvault secret show \\\n    --vault-name your-key-vault \\\n    --name \"azure-speech-key\" \\\n    --query \"value\" -o tsv\n</code></pre>"},{"location":"getting-started/configuration/#environment-validation","title":"Environment Validation","text":"Validate environment configuration<pre><code># Check required variables are set\npython -c \"\nimport os\nrequired_vars = [\n    'AZURE_SPEECH_REGION',\n    'AZURE_COMMUNICATION_CONNECTION_STRING'\n]\n\nmissing = [var for var in required_vars if not os.getenv(var)]\nif missing:\n    print(f'\u274c Missing required variables: {missing}')\n    exit(1)\nelse:\n    print('\u2705 All required environment variables are set')\n\"\n</code></pre> <p>Microsoft Learn Resources</p> <ul> <li>Azure Key Vault - Secure secret management</li> <li>Key Vault Integration - Application integration patterns</li> <li>GitHub Actions with Azure - Secure GitHub workflows</li> </ul>"},{"location":"getting-started/configuration/#configuration-validation","title":"Configuration Validation","text":""},{"location":"getting-started/configuration/#environment-health-check","title":"Environment Health Check","text":"Comprehensive configuration validation<pre><code>#!/usr/bin/env python3\n\"\"\"Configuration validation script\"\"\"\n\nimport os\nfrom typing import Dict, List, Tuple\n\ndef validate_config() -&gt; Tuple[bool, List[str]]:\n    \"\"\"Validate all configuration settings.\"\"\"\n    issues = []\n\n    # Required variables\n    required = {\n        'AZURE_SPEECH_REGION': 'Azure Speech Services region',\n        'AZURE_COMMUNICATION_CONNECTION_STRING': 'Azure Communication Services connection',\n    }\n\n    # Check managed identity vs API key\n    use_managed_identity = os.getenv('USE_MANAGED_IDENTITY', '').lower() == 'true'\n\n    if use_managed_identity:\n        if not os.getenv('AZURE_SPEECH_RESOURCE_ID'):\n            issues.append('AZURE_SPEECH_RESOURCE_ID required for managed identity')\n    else:\n        if not os.getenv('AZURE_SPEECH_KEY'):\n            issues.append('AZURE_SPEECH_KEY required (or enable managed identity)')\n\n    # Check required variables\n    for var, description in required.items():\n        if not os.getenv(var):\n            issues.append(f'Missing {var} ({description})')\n\n    # Validate region format\n    region = os.getenv('AZURE_SPEECH_REGION', '')\n    if region and ' ' in region:\n        issues.append(f'Invalid region format: \"{region}\". Use format like \"eastus\", not \"East US\"')\n\n    return len(issues) == 0, issues\n\nif __name__ == '__main__':\n    valid, issues = validate_config()\n    if valid:\n        print('\u2705 Configuration validation passed')\n    else:\n        print('\u274c Configuration validation failed:')\n        for issue in issues:\n            print(f'  - {issue}')\n</code></pre>"},{"location":"getting-started/configuration/#quick-configuration-test","title":"Quick Configuration Test","text":"Quick configuration test<pre><code># Run configuration validation\npython scripts/validate_config.py\n\n# Test Speech Services connection\npython -c \"\nfrom src.speech.text_to_speech import SpeechSynthesizer\nimport os\n\ntry:\n    synthesizer = SpeechSynthesizer(\n        key=os.getenv('AZURE_SPEECH_KEY'),\n        region=os.getenv('AZURE_SPEECH_REGION')\n    )\n    if synthesizer.validate_configuration():\n        print('\u2705 Speech Services configuration valid')\n    else:\n        print('\u274c Speech Services configuration invalid')\nexcept Exception as e:\n    print(f'\u274c Error: {e}')\n\"\n</code></pre> <p>Configuration Complete</p> <p>Your Real-Time Voice Agent is now configured and ready for deployment. Next, explore the API Reference to start building your voice application.</p>"},{"location":"getting-started/local-development/","title":"Local Development","text":""},{"location":"getting-started/local-development/#local-development","title":"\u26a1 Local Development","text":"<p>Run the ARTVoice Accelerator locally with raw commands. No Makefile usage. Keep secrets out of git and rotate any previously exposed keys.</p>"},{"location":"getting-started/local-development/#1-scope","title":"1. Scope","text":"<p>What this covers:</p> <ul> <li>Local backend (FastAPI + Uvicorn) and frontend (Vite/React)</li> <li>Dev tunnel for inbound Azure Communication Services callbacks</li> <li>Environment setup via venv OR Conda</li> <li>Minimal <code>.env</code> files (root + frontend)</li> </ul> <p>What this does NOT cover: - Full infra provisioning - CI/CD - Persistence hardening</p>"},{"location":"getting-started/local-development/#2-prerequisites","title":"2. Prerequisites","text":"Tool Notes Python 3.11 Required runtime Node.js \u2265 22 Frontend Azure CLI <code>az login</code> first Dev Tunnels Getting Started Guide (Optional) Conda If using <code>environment.yaml</code> Provisioned Azure resources For real STT/TTS/LLM/ACS <p>If you only want a browser demo (no phone), ACS variables are optional.</p>"},{"location":"getting-started/local-development/#3-clone-repository","title":"3. Clone Repository","text":"<pre><code>git clone https://github.com/Azure-Samples/art-voice-agent-accelerator.git\ncd art-voice-agent-accelerator\n</code></pre>"},{"location":"getting-started/local-development/#4-python-environment-choose-one","title":"4. Python Environment (Choose One)","text":""},{"location":"getting-started/local-development/#option-a-venv","title":"Option A: venv","text":"<pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/local-development/#option-b-conda","title":"Option B: Conda","text":"<pre><code>conda env create -f environment.yaml\nconda activate audioagent\npip install -r requirements.txt   # sync with lock\n</code></pre>"},{"location":"getting-started/local-development/#5-root-env-create-in-repo-root","title":"5. Root <code>.env</code> (Create in repo root)","text":"<p>Sample Configuration</p> <p>Use <code>.env.sample</code> as a starting template and customize with your Azure resource values.</p> <p>Using Azure Developer CLI (azd)</p> <p>If you provisioned infrastructure using <code>azd provision</code>, an environment file will be automatically generated for you in the format <code>.env.&lt;azd-env-name&gt;</code>. </p> <p>To use the azd-generated configuration: <pre><code># Copy the azd-generated environment file\ncp .env.&lt;your-azd-env-name&gt; .env\n\n# Example: if your azd environment is named \"dev\"\ncp .env.dev .env\n</code></pre></p> <p>The azd-generated file contains all the Azure resource endpoints and configuration needed for local development.</p> <p>Manual Configuration Template (edit placeholders; DO NOT commit real values):</p> <pre><code># ===== Azure OpenAI =====\nAZURE_OPENAI_ENDPOINT=https://&lt;your-aoai&gt;.openai.azure.com\nAZURE_OPENAI_KEY=&lt;aoai-key&gt;\nAZURE_OPENAI_DEPLOYMENT=gpt-4-1-mini\nAZURE_OPENAI_API_VERSION=2024-12-01-preview\nAZURE_OPENAI_CHAT_DEPLOYMENT_ID=gpt-4-1-mini\nAZURE_OPENAI_CHAT_DEPLOYMENT_VERSION=2024-11-20\n\n# ===== Speech =====\nAZURE_SPEECH_REGION=&lt;speech-region&gt;\nAZURE_SPEECH_KEY=&lt;speech-key&gt;\n\n# ===== ACS (optional unless using phone/PSTN) =====\nACS_CONNECTION_STRING=endpoint=https://&lt;your-acs&gt;.communication.azure.com/;accesskey=&lt;acs-key&gt;\nACS_SOURCE_PHONE_NUMBER=+1XXXXXXXXXX\nACS_ENDPOINT=https://&lt;your-acs&gt;.communication.azure.com\n\n# ===== Optional Data Stores =====\nREDIS_HOST=&lt;redis-host&gt;\nREDIS_PORT=6380\nREDIS_PASSWORD=&lt;redis-password&gt;\nAZURE_COSMOS_CONNECTION_STRING=&lt;cosmos-conn-string&gt;\nAZURE_COSMOS_DATABASE_NAME=audioagentdb\nAZURE_COSMOS_COLLECTION_NAME=audioagentcollection\n\n# ===== Runtime =====\nENVIRONMENT=dev\nACS_STREAMING_MODE=media\n\n# ===== Filled after dev tunnel starts =====\nBASE_URL=https://&lt;tunnel-url&gt;\n</code></pre> <p>Ensure <code>.env</code> is in <code>.gitignore</code>.</p>"},{"location":"getting-started/local-development/#6-start-dev-tunnel","title":"6. Start Dev Tunnel","text":"<p>Required if you want ACS callbacks (phone flow) or remote test:</p> <pre><code>devtunnel host -p 8010 --allow-anonymous\n</code></pre> <p>Copy the printed HTTPS URL and set <code>BASE_URL</code> in root <code>.env</code>. Update it again if the tunnel restarts (URL changes).</p> <p>The Dev Tunnel URL will look similar to: <pre><code>https://abc123xy-8010.usw3.devtunnels.ms\n</code></pre></p> <p>Security Considerations for Operations Teams</p> <p>Dev Tunnels create public endpoints that expose your local development environment to the internet. Review the following security guidelines:</p> <ul> <li>Azure Dev Tunnels Security - Comprehensive security guidance</li> <li>Access Control: Use <code>--allow-anonymous</code> only for development; consider authentication for sensitive environments</li> <li>Network Policies: Ensure dev tunnels comply with organizational network security policies</li> <li>Monitoring: Dev tunnels should be monitored and logged like any public endpoint</li> <li>Temporary Usage: Tunnels are for development only; use proper Azure services for production</li> <li>Credential Protection: Never expose production credentials through dev tunnels</li> </ul> <p>InfoSec Recommendation: Review tunnel usage with your security team before use in corporate environments.</p>"},{"location":"getting-started/local-development/#7-run-backend","title":"7. Run Backend","text":"<pre><code>cd apps/rtagent/backend\nuvicorn apps.rtagent.backend.main:app --host 0.0.0.0 --port 8010 --reload\n</code></pre>"},{"location":"getting-started/local-development/#8-frontend-environment","title":"8. Frontend Environment","text":"<p>Create or edit <code>apps/rtagent/frontend/.env</code>:</p> <p>Sample Configuration</p> <p>Use <code>apps/rtagent/frontend/.env.sample</code> as a starting template.</p> <p>Use the dev tunnel URL by default so the frontend (and any external device or ACS-related flows) reaches your backend consistently\u2014even if you open the UI on another machine or need secure HTTPS.</p> <pre><code># Recommended (works across devices / matches ACS callbacks)\nVITE_BACKEND_BASE_URL=https://&lt;tunnel-url&gt;\n</code></pre> <p>If the tunnel restarts (URL changes), update both <code>BASE_URL</code> in the root <code>.env</code> and this value.</p>"},{"location":"getting-started/local-development/#9-run-frontend","title":"9. Run Frontend","text":"<pre><code>cd apps/rtagent/frontend\nnpm install\nnpm run dev\n</code></pre> <p>Open: http://localhost:5173</p> <p>WebSocket URL is auto-derived by replacing <code>http/https</code> with <code>ws/wss</code>.</p>"},{"location":"getting-started/local-development/#10-alternative-vs-code-debugging","title":"10. Alternative: VS Code Debugging","text":"<p>Built-in debugger configurations are available in <code>.vscode/launch.json</code>:</p>"},{"location":"getting-started/local-development/#backend-debugging","title":"Backend Debugging","text":"<ol> <li>Set breakpoints in Python code</li> <li>Press F5 or go to Run &amp; Debug view</li> <li>Select \"[RT Agent] Python Debugger: FastAPI\"</li> <li>Debug session starts with hot reload enabled</li> </ol>"},{"location":"getting-started/local-development/#frontend-debugging","title":"Frontend Debugging","text":"<ol> <li>Start the React dev server (<code>npm run dev</code>)</li> <li>Press F5 or go to Run &amp; Debug view</li> <li>Select \"[RT Agent] React App: Browser Debug\"</li> <li>Browser opens with debugger attached</li> </ol> <p>Benefits: - Set breakpoints in both Python and TypeScript/React code - Step through code execution - Inspect variables and call stacks - Hot reload for both frontend and backend</p>"},{"location":"getting-started/local-development/#11-alternative-docker-compose","title":"11. Alternative: Docker Compose","text":"<p>For containerized local development, use the provided <code>docker-compose.yml</code>:</p> <pre><code># Ensure .env files are configured (see sections 5 &amp; 8 above)\n\n# Build and run both frontend and backend containers\ndocker-compose up --build\n\n# Or run in detached mode\ndocker-compose up --build -d\n\n# View logs\ndocker-compose logs -f\n\n# Stop containers\ndocker-compose down\n</code></pre> <p>Container Ports:</p> <ul> <li>Frontend: http://localhost:8080 (containerized)</li> <li>Backend: http://localhost:8010 (same as manual setup)</li> </ul> <p>When to use Docker Compose:</p> <ul> <li>Consistent environment across team members</li> <li>Testing containerized deployment locally</li> <li>Isolating dependencies from host system</li> <li>Matching production container behavior</li> </ul> <p>Dev Tunnel with Docker</p> <p>You still need to run <code>devtunnel host -p 8010 --allow-anonymous</code> for ACS callbacks, as the containers need external access for webhook endpoints.</p>"},{"location":"getting-started/local-development/#12-optional-phone-pstn-flow","title":"12. Optional: Phone (PSTN) Flow","text":"<ol> <li> <p>Purchase ACS phone number (Portal or CLI).</p> </li> <li> <p>Ensure these vars are set in your root <code>.env</code> (with real values):</p> </li> </ol> <pre><code>ACS_CONNECTION_STRING=endpoint=...\nACS_SOURCE_PHONE_NUMBER=+1XXXXXXXXXX\nACS_ENDPOINT=https://&lt;your-acs&gt;.communication.azure.com\nBASE_URL=https://&lt;tunnel-hash&gt;-8010.usw3.devtunnels.ms\n</code></pre> <ol> <li>Create a single Event Grid subscription for the Incoming Call event pointing to your answer handler:</li> <li>Inbound endpoint: <code>https://&lt;tunnel-hash&gt;-8010.usw3.devtunnels.ms/api/v1/calls/answer</code></li> <li>Event type: <code>Microsoft.Communication.IncomingCall</code></li> <li>(Callbacks endpoint <code>/api/v1/calls/callbacks</code> is optional unless you need detailed lifecycle events.)</li> </ol> <p>If tunnel URL changes, update the subscription (delete &amp; recreate or update endpoint).</p> <p>Reference: Subscribing to events</p> <ol> <li>Dial the number; observe:</li> <li>Call connection established</li> <li>Media session events</li> <li>STT transcripts</li> <li>TTS audio frames</li> </ol>"},{"location":"getting-started/local-development/#13-quick-browser-test","title":"13. Quick Browser Test","text":"<ol> <li>Backend + frontend running.</li> <li>Open app, allow microphone.</li> <li>Speak \u2192 expect:</li> <li>Interim/final transcripts</li> <li>Model response</li> <li>Audio playback</li> </ol>"},{"location":"getting-started/local-development/#14-troubleshooting","title":"14. Troubleshooting","text":"Symptom Likely Cause Fix 404 on callbacks Stale <code>BASE_URL</code> Restart tunnel, update <code>.env</code> No audio Speech key/region invalid Verify Azure Speech resource WS closes fast Wrong <code>VITE_BACKEND_BASE_URL</code> Use exact backend/tunnel URL Slow first reply Cold pool warm-up Keep process running Phone call no events ACS callback not updated to tunnel Reconfigure Event Grid subscription Import errors Missing dependencies Re-run <code>pip install -r requirements.txt</code>"},{"location":"getting-started/local-development/#15-testing-your-setup","title":"15. Testing Your Setup","text":""},{"location":"getting-started/local-development/#quick-unit-tests","title":"Quick Unit Tests","text":"<p>Validate your local setup with the comprehensive test suite:</p> <pre><code># Run core component tests\npython -m pytest tests/test_acs_media_lifecycle.py -v\n\n# Test event handling and WebSocket integration\npython -m pytest tests/test_acs_events_handlers.py -v\n\n# Validate DTMF processing (if using phone features)\npython -m pytest tests/test_dtmf_validation.py -v\n</code></pre>"},{"location":"getting-started/local-development/#load-testing-advanced","title":"Load Testing (Advanced)","text":"<p>Validate ACS media relay and real-time conversation paths with the maintained Locust scripts and Make targets:</p> <pre><code># Generate or refresh PCM fixtures shared by both load tests\nmake generate_audio\n\n# ACS media relay flow (/api/v1/media/stream)\nmake run_load_test_acs_media HOST=wss://&lt;your-backend-host&gt;\n\n# Real-time conversation flow (/api/v1/realtime/conversation)\nmake run_load_test_realtime_conversation HOST=wss://&lt;your-backend-host&gt;\n</code></pre> <p>Adjust concurrency via <code>USERS</code>, <code>SPAWN_RATE</code>, <code>TIME</code>, and pass extra Locust flags with <code>EXTRA_ARGS='--headless --html report.html'</code>.</p> <p>Metrics reported in Locust: - <code>ttfb[...]</code> \u2014 time-to-first-byte after the client stops streaming audio. - <code>barge_latency[...]</code> \u2014 recovery time after simulated barge-in traffic. - <code>turn_complete[...]</code> \u2014 end-to-end latency covering audio send, response, and barge handling.</p> <p>The targets wrap <code>tests/load/locustfile.acs_media.py</code> and <code>tests/load/locustfile.realtime_conversation.py</code>. To run them manually:</p> <pre><code>locust -f tests/load/locustfile.acs_media.py --host wss://&lt;backend-host&gt; --users 10 --spawn-rate 2 --run-time 5m --headless\nlocust -f tests/load/locustfile.realtime_conversation.py --host wss://&lt;backend-host&gt; --users 10 --spawn-rate 2 --run-time 5m --headless\n</code></pre> <p>What the load tests validate:</p> <ul> <li>\u2705 Real-time audio streaming - 20ms PCM chunks via WebSocket</li> <li>\u2705 Multi-turn conversations - Insurance inquiries and quick questions</li> <li>\u2705 Response timing - TTFB (Time-to-First-Byte) measurement</li> <li>\u2705 Barge-in handling - Response interruption simulation</li> <li>\u2705 Connection stability - Automatic WebSocket reconnection</li> </ul> <p>Additional Resources</p> <p>For more comprehensive guidance on development and operations:</p> <ul> <li>Troubleshooting Guide - Detailed problem resolution for common issues</li> <li>Testing Guide - Comprehensive unit and integration testing (85%+ coverage)</li> <li>Load Testing - WebSocket performance testing and Azure Load Testing integration</li> <li>Repository Structure - Understand the codebase layout</li> <li>Utilities &amp; Services - Core infrastructure components</li> </ul> <p>Keep secrets out of commits. Rotate anything that has leaked.</p>"},{"location":"guides/repository-structure/","title":"Repository Structure","text":""},{"location":"guides/repository-structure/#repository-structure","title":"Repository Structure","text":"<p>This document provides a complete 5-level deep map of the ARTVoice accelerator repository, designed for engineers who need to understand the codebase architecture, locate specific components, and contribute effectively.</p>"},{"location":"guides/repository-structure/#overview","title":"Overview","text":"<p>The repository follows a modular, microservice-oriented structure with clear separation of concerns:</p> <ul> <li><code>apps/</code> \u2014 Deployable applications (backend API, frontend UI, helper scripts)</li> <li><code>src/</code> \u2014 Core business logic libraries (reusable across apps)</li> <li><code>infra/</code> \u2014 Infrastructure-as-Code (Bicep, Terraform)</li> <li><code>docs/</code> \u2014 Documentation and guides</li> <li><code>tests/</code> \u2014 Test suites and load testing</li> <li><code>utils/</code> \u2014 Cross-cutting utilities (logging, telemetry, images)</li> </ul>"},{"location":"guides/repository-structure/#complete-repository-map-5-levels-deep","title":"Complete Repository Map (5 Levels Deep)","text":"<pre><code>\ud83d\udcc1 art-voice-agent-accelerator/\n\u251c\u2500\u2500 \ud83d\udcc4 azure.yaml                          # Azure Developer CLI configuration\n\u251c\u2500\u2500 \ud83d\udcc4 CHANGELOG.md                        # Release notes and version history\n\u251c\u2500\u2500 \ud83d\udcc4 CONTRIBUTING.md                     # Contribution guidelines\n\u251c\u2500\u2500 \ud83d\udcc4 docker-compose.yml                  # Local development containers\n\u251c\u2500\u2500 \ud83d\udcc4 environment.yaml                    # Conda environment specification\n\u251c\u2500\u2500 \ud83d\udcc4 LICENSE                             # MIT license\n\u251c\u2500\u2500 \ud83d\udcc4 Makefile                            # Automation commands (deploy, env setup)\n\u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml                          # Documentation site configuration\n\u251c\u2500\u2500 \ud83d\udcc4 pyproject.toml                      # Python project metadata and dependencies\n\u251c\u2500\u2500 \ud83d\udcc4 README.md                           # Main project documentation\n\u251c\u2500\u2500 \ud83d\udcc4 requirements.txt                    # Python dependencies (production)\n\u251c\u2500\u2500 \ud83d\udcc4 requirements-codequality.txt        # Development tools (black, flake8, etc.)\n\u251c\u2500\u2500 \ud83d\udcc4 requirements-docs.txt               # Documentation dependencies\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 apps/                               # Deployable applications\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 README.md                       # Apps overview and usage\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 rtagent/                        # Real-time voice agent application\n\u2502       \u251c\u2500\u2500 \ud83d\udcc1 backend/                    # FastAPI backend service\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 .env.example            # Environment variables template\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile              # Container definition\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.py                 # FastAPI application entry point\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 Makefile                # Backend-specific commands\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 requirements.txt       # Backend dependencies\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc1 app/                    # Application logic\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 api/                # REST API endpoints\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 calls.py        # ACS call management endpoints\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 health.py       # Health check endpoints\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 v1/             # API version 1\n\u2502       \u2502   \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 calls.py    # Call endpoints v1\n\u2502       \u2502   \u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 speech.py   # Speech processing endpoints\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 core/               # Core application logic\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 config.py       # Configuration management\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 dependencies.py # Dependency injection\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 security.py     # Authentication/authorization\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 models/             # Pydantic data models\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 call.py         # Call-related models\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 speech.py       # Speech data models\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 response.py     # API response models\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 services/           # Business logic services\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 call_service.py # Call orchestration logic\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 speech_service.py # Speech processing logic\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 agent_service.py # AI agent coordination\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 ws/                 # WebSocket handlers\n\u2502       \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 connection.py   # WebSocket connection management\n\u2502       \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 handlers.py     # WebSocket message handlers\n\u2502       \u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 media.py        # Real-time media streaming\n\u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 tests/                  # Backend unit tests\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc4 conftest.py         # Test configuration\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc1 api/                # API endpoint tests\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc1 services/           # Service layer tests\n\u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 ws/                 # WebSocket tests\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 \ud83d\udcc1 frontend/                   # React frontend application\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 .env.example            # Frontend environment template\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile              # Frontend container definition\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 index.html              # Main HTML template\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 package.json            # Node.js dependencies and scripts\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 tsconfig.json           # TypeScript configuration\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 vite.config.ts          # Vite build configuration\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc1 public/                 # Static assets\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 favicon.ico\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 icons/              # Application icons\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc1 src/                    # React source code\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 App.tsx             # Main React component\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.tsx            # React application entry point\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 vite-env.d.ts       # Vite type definitions\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 components/         # Reusable React components\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 AudioPlayer.tsx # Audio playback component\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 CallControls.tsx # Call control buttons\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 ChatInterface.tsx # Chat UI component\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 ui/             # Basic UI components\n\u2502       \u2502   \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 Button.tsx\n\u2502       \u2502   \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 Input.tsx\n\u2502       \u2502   \u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 Modal.tsx\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 hooks/              # React custom hooks\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 useAudio.ts     # Audio processing hooks\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 useWebSocket.ts # WebSocket connection hooks\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 useCall.ts      # Call state management\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 pages/              # Page components\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 Home.tsx        # Home page\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 Demo.tsx        # Demo interface\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 NotFound.tsx    # 404 page\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 services/           # API client services\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 api.ts          # Base API client\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 callService.ts  # Call API client\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 speechService.ts # Speech API client\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 store/              # State management\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 index.ts        # Store configuration\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 callSlice.ts    # Call state slice\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 uiSlice.ts      # UI state slice\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 types/              # TypeScript type definitions\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 api.ts          # API response types\n\u2502       \u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 call.ts         # Call-related types\n\u2502       \u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 speech.ts       # Speech data types\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 utils/              # Frontend utilities\n\u2502       \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 audio.ts        # Audio processing utilities\n\u2502       \u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 websocket.ts    # WebSocket utilities\n\u2502       \u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 constants.ts    # Application constants\n\u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 tests/                  # Frontend tests\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc4 setup.ts            # Test setup\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc1 components/         # Component tests\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc1 hooks/              # Hook tests\n\u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 utils/              # Utility tests\n\u2502       \u2502\n\u2502       \u2514\u2500\u2500 \ud83d\udcc1 scripts/                    # Helper scripts and automation\n\u2502           \u251c\u2500\u2500 \ud83d\udcc4 README.md               # Scripts documentation\n\u2502           \u251c\u2500\u2500 \ud83d\udcc4 start-backend.sh        # Backend startup script\n\u2502           \u251c\u2500\u2500 \ud83d\udcc4 start-frontend.sh       # Frontend startup script\n\u2502           \u251c\u2500\u2500 \ud83d\udcc4 setup-tunnel.sh         # Dev tunnel setup\n\u2502           \u2514\u2500\u2500 \ud83d\udcc1 deployment/             # Deployment scripts\n\u2502               \u251c\u2500\u2500 \ud83d\udcc4 deploy-backend.sh   # Backend deployment\n\u2502               \u251c\u2500\u2500 \ud83d\udcc4 deploy-frontend.sh  # Frontend deployment\n\u2502               \u2514\u2500\u2500 \ud83d\udcc4 health-check.sh     # Post-deployment validation\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 src/                                # Core business logic libraries\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py                     # Package initialization\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 acs/                            # Azure Communication Services\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 client.py                   # ACS client wrapper\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 events.py                   # Event handling\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 media.py                    # Media streaming\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 models/                     # ACS data models\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 call.py                 # Call models\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 participant.py          # Participant models\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 agenticmemory/                  # Agent memory management\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 memory.py                   # Memory interfaces\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 store.py                    # Memory storage implementations\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 adapters/                   # Memory adapter implementations\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 cosmos.py               # Cosmos DB adapter\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 redis.py                # Redis adapter\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 aoai/                           # Azure OpenAI integration\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 client.py                   # AOAI client wrapper\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 models.py                   # Model management\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 streaming.py                # Streaming responses\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 tools/                      # Function calling tools\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 registry.py             # Tool registry\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 validators.py           # Tool validation\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 blob/                           # Azure Blob Storage\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 client.py                   # Blob client wrapper\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 upload.py                   # Upload utilities\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 cosmosdb/                       # Cosmos DB integration\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 client.py                   # Cosmos client wrapper\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 models.py                   # Document models\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 collections/                # Collection managers\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 calls.py                # Call collection\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 sessions.py             # Session collection\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 enums/                          # Enumeration definitions\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 call_states.py              # Call state enums\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 speech_events.py            # Speech event enums\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 latency/                        # Latency measurement and optimization\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 tracker.py                  # Latency tracking\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 metrics.py                  # Performance metrics\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 pools/                          # Connection and resource pools\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 speech_pool.py              # Speech service pool\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 aoai_pool.py                # AOAI service pool\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 postcall/                       # Post-call processing\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 analytics.py                # Call analytics\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 summary.py                  # Call summarization\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 prompts/                        # AI prompt templates\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 system.py                   # System prompts\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 user.py                     # User prompts\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 templates/                  # Prompt templates\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 customer_service.py     # Customer service prompts\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 healthcare.py           # Healthcare prompts\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 redis/                          # Redis integration\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 client.py                   # Redis client wrapper\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 cache.py                    # Caching utilities\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 pubsub.py                   # Pub/sub messaging\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 speech/                         # Speech processing\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 recognizer.py               # Speech-to-text\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 synthesizer.py              # Text-to-speech\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 streaming.py                # Real-time streaming\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 models/                     # Speech models\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 transcript.py           # Transcript models\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 audio.py                # Audio data models\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 stateful/                       # Stateful processing\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 session.py                  # Session management\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 context.py                  # Context tracking\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 tools/                          # Function calling tools\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 base.py                     # Base tool interface\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 calendar.py                 # Calendar integration\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 weather.py                  # Weather API tool\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 integrations/               # Third-party integrations\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 salesforce.py           # Salesforce integration\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 dynamics.py             # Dynamics 365 integration\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 vad/                            # Voice Activity Detection\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 detector.py                 # VAD implementation\n\u2502       \u2514\u2500\u2500 \ud83d\udcc4 silence.py                  # Silence detection\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 infra/                              # Infrastructure as Code\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 README.md                       # Infrastructure documentation\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 bicep/                          # Azure Bicep templates\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 abbreviations.json          # Resource naming abbreviations\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.bicep                  # Main infrastructure template\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 ai-gateway.bicep            # AI Gateway configuration\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 app.bicep                   # Application services\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 appgw.bicep                 # Application Gateway\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 data.bicep                  # Data services\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc1 modules/                    # Reusable Bicep modules\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 storage.bicep           # Storage account module\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 keyvault.bicep          # Key Vault module\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 cosmosdb.bicep          # Cosmos DB module\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 redis.bicep             # Redis module\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 containerapp.bicep      # Container Apps module\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 parameters/                 # Parameter files\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 main.parameters.json    # Main parameters\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 dev.parameters.json     # Development parameters\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 prod.parameters.json    # Production parameters\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 terraform/                      # Terraform configurations\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 main.tf                     # Main Terraform configuration\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 variables.tf                # Variable definitions\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 outputs.tf                  # Output definitions\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 terraform.tfvars.example    # Variables template\n\u2502       \u251c\u2500\u2500 \ud83d\udcc1 modules/                    # Terraform modules\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc1 acs/                    # Azure Communication Services\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 variables.tf\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 outputs.tf\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc1 speech/                 # Azure Speech Services\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 variables.tf\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 outputs.tf\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc1 aoai/                   # Azure OpenAI\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 variables.tf\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 outputs.tf\n\u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 networking/             # Network infrastructure\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502       \u2502       \u251c\u2500\u2500 \ud83d\udcc4 variables.tf\n\u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc4 outputs.tf\n\u2502       \u2514\u2500\u2500 \ud83d\udcc1 environments/               # Environment-specific configs\n\u2502           \u251c\u2500\u2500 \ud83d\udcc1 dev/                    # Development environment\n\u2502           \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502           \u2502   \u2514\u2500\u2500 \ud83d\udcc4 terraform.tfvars\n\u2502           \u251c\u2500\u2500 \ud83d\udcc1 staging/                # Staging environment\n\u2502           \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502           \u2502   \u2514\u2500\u2500 \ud83d\udcc4 terraform.tfvars\n\u2502           \u2514\u2500\u2500 \ud83d\udcc1 prod/                   # Production environment\n\u2502               \u251c\u2500\u2500 \ud83d\udcc4 main.tf\n\u2502               \u2514\u2500\u2500 \ud83d\udcc4 terraform.tfvars\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 docs/                               # Documentation\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 docs-overview.md                # Documentation index\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Architecture.md                 # System architecture\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 AuthForHTTPandWSS.md           # Authentication guide\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 CICDGuide.md                   # CI/CD setup\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 DataArchitecture.md            # Data architecture\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 DeploymentGuide.md             # Deployment instructions\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 EventGridAuth.md               # Event Grid authentication\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 HealthcareUsecases.md          # Healthcare use cases\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 IntegrationPoints.md           # Integration documentation\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 LoadTesting.md                 # Load testing guide\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 PathToProduction.md            # Production readiness\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Troubleshooting.md             # Troubleshooting guide\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 WebsocketAuth.md               # WebSocket authentication\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 quickstart-local-development.md # Local development guide\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 repo-structure.md              # This document\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 api/                           # API documentation\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 overview.md                # API overview\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 architecture.md        # Speech API docs\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 endpoints/                 # Endpoint documentation\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc4 calls.md               # Call endpoints\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc4 speech.md              # Speech endpoints\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 assets/                        # Documentation assets\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 MVPDeploy_infratf.png      # Architecture diagrams\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 RTAudio_AWSConnect_Forward_to_Azure.png\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 RTAudio_AWSMapped.png\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 RTAudio.v0.png\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 getting-started/               # Getting started guides\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 installation.md            # Installation guide\n\u2502       \u2514\u2500\u2500 \ud83d\udcc4 quickstart.md              # Quick start guide\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 tests/                             # Test suites\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py                    # Test package initialization\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 conftest.py                    # Pytest configuration\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 apim-test.http                 # API Management tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 backend.http                   # Backend API tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 test_acs_events_handlers.py    # ACS event handler tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 test_acs_media_lifecycle.py    # ACS media lifecycle tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 test_acs_simple.py             # Simple ACS tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 test_dtmf_validation.py        # DTMF validation tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 test_speech_queue.py           # Speech queue tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 test_v1_events_integration.py  # V1 events integration tests\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 validate_tool_functions.py     # Tool function validation\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 load/                          # Load testing scripts\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 README.md                  # Load testing documentation\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 locustfile.py              # Locust load test script\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 artillery.yml              # Artillery load test config\n\u2502       \u251c\u2500\u2500 \ud83d\udcc1 scenarios/                 # Test scenarios\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 basic_call.py          # Basic call scenario\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 concurrent_calls.py    # Concurrent calls scenario\n\u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc4 stress_test.py         # Stress test scenario\n\u2502       \u2514\u2500\u2500 \ud83d\udcc1 reports/                   # Test reports\n\u2502           \u251c\u2500\u2500 \ud83d\udcc4 .gitkeep               # Keep directory in git\n\u2502           \u2514\u2500\u2500 \ud83d\udcc1 latest/                # Latest test results\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 utils/                             # Cross-cutting utilities\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py                    # Utilities package initialization\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 azure_auth.py                  # Azure authentication utilities\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 ml_logging.py                  # Machine learning logging\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 telemetry_config.py            # Telemetry configuration\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 trace_context.py               # Distributed tracing context\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 docstringtool/                 # Documentation tools\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 extractor.py               # Docstring extraction\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 generator.py               # Documentation generation\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 images/                        # Project images and diagrams\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 ARTAGENT.png               # Main logo\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 RTAGENT.png                # RT Agent logo\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 ARTAgentarch.png           # Architecture diagram\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 LIVEVOICEApi.png           # Live Voice API diagram\n\u2502       \u2514\u2500\u2500 \ud83d\udcc4 RTAgentArch.png            # RT Agent architecture\n\u2502\n\u2514\u2500\u2500 \ud83d\udcc1 samples/                           # Sample implementations\n    \u251c\u2500\u2500 \ud83d\udcc4 README.md                      # Samples documentation\n    \u251c\u2500\u2500 \ud83d\udcc1 hello_world/                   # Hello world examples\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 README.md                  # Hello world documentation\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 01-simple-speech.py        # Simple speech example\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 02-acs-integration.py      # ACS integration example\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 03-websocket-demo.py       # WebSocket demo\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 04-exploring-live-api.ipynb # Live API exploration notebook\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc4 05-create-your-first-livevoice.ipynb # Live voice tutorial\n    \u2514\u2500\u2500 \ud83d\udcc1 labs/                          # Advanced examples and labs\n        \u251c\u2500\u2500 \ud83d\udcc4 README.md                  # Labs documentation\n        \u251c\u2500\u2500 \ud83d\udcc1 advanced-routing/          # Advanced call routing\n        \u2502   \u251c\u2500\u2500 \ud83d\udcc4 README.md\n        \u2502   \u251c\u2500\u2500 \ud83d\udcc4 ivr_tree.py            # IVR tree implementation\n        \u2502   \u2514\u2500\u2500 \ud83d\udcc4 skill_routing.py       # Skill-based routing\n        \u251c\u2500\u2500 \ud83d\udcc1 custom-tools/              # Custom tool examples\n        \u2502   \u251c\u2500\u2500 \ud83d\udcc4 README.md\n        \u2502   \u251c\u2500\u2500 \ud83d\udcc4 crm_integration.py     # CRM tool example\n        \u2502   \u2514\u2500\u2500 \ud83d\udcc4 knowledge_base.py      # Knowledge base tool\n        \u2514\u2500\u2500 \ud83d\udcc1 performance/               # Performance optimization labs\n            \u251c\u2500\u2500 \ud83d\udcc4 README.md\n            \u251c\u2500\u2500 \ud83d\udcc4 latency_optimization.py # Latency optimization\n            \u2514\u2500\u2500 \ud83d\udcc4 throughput_testing.py   # Throughput testing\n</code></pre>"},{"location":"guides/repository-structure/#key-concepts","title":"Key Concepts","text":""},{"location":"guides/repository-structure/#application-architecture","title":"Application Architecture","text":"<ul> <li>Backend (<code>apps/rtagent/backend/</code>): FastAPI-based REST API with WebSocket support for real-time communication</li> <li>Frontend (<code>apps/rtagent/frontend/</code>): React + TypeScript SPA with Vite for fast development</li> <li>Core Libraries (<code>src/</code>): Reusable business logic that can be imported across applications</li> </ul>"},{"location":"guides/repository-structure/#infrastructure-patterns","title":"Infrastructure Patterns","text":"<ul> <li>Multi-Cloud Support: Both Bicep (Azure-native) and Terraform (cloud-agnostic) templates</li> <li>Environment Separation: Dev/staging/prod configurations with parameter files</li> <li>Modular Design: Reusable infrastructure modules for common services</li> </ul>"},{"location":"guides/repository-structure/#code-organization","title":"Code Organization","text":"<ul> <li>Domain-Driven Design: Code organized by business domain (ACS, Speech, AI, etc.)</li> <li>Dependency Injection: Clean separation of concerns using FastAPI's dependency system</li> <li>Type Safety: Full TypeScript frontend and Python type hints in backend</li> </ul>"},{"location":"guides/repository-structure/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Unit Tests: Co-located with source code in each module</li> <li>Integration Tests: In <code>tests/</code> directory for cross-module functionality</li> <li>Load Tests: Dedicated load testing with Locust and Artillery</li> <li>API Tests: HTTP files for manual and automated API testing</li> </ul>"},{"location":"guides/repository-structure/#quick-navigation-for-engineers","title":"Quick Navigation for Engineers","text":""},{"location":"guides/repository-structure/#finding-components","title":"\ud83d\udd0d Finding Components","text":"What you need Where to look API endpoints <code>apps/rtagent/backend/app/api/</code> Business logic <code>apps/rtagent/backend/app/services/</code> WebSocket handlers <code>apps/rtagent/backend/app/ws/</code> React components <code>apps/rtagent/frontend/src/components/</code> Speech processing <code>src/speech/</code> ACS integration <code>src/acs/</code> AI/LLM logic <code>src/aoai/</code> Database models <code>src/cosmosdb/models.py</code> Infrastructure <code>infra/bicep/</code> or <code>infra/terraform/</code> Documentation <code>docs/</code> Tests <code>tests/</code>"},{"location":"guides/repository-structure/#getting-started-paths","title":"\ud83d\ude80 Getting Started Paths","text":"<ol> <li>Frontend Developer: Start with <code>apps/rtagent/frontend/src/App.tsx</code></li> <li>Backend Developer: Start with <code>apps/rtagent/backend/main.py</code> </li> <li>DevOps Engineer: Start with <code>infra/</code> and <code>Makefile</code></li> <li>AI Engineer: Start with <code>src/aoai/</code> and <code>src/speech/</code></li> <li>Integration Developer: Start with <code>src/acs/</code> and <code>src/tools/</code></li> </ol>"},{"location":"guides/repository-structure/#documentation-priority","title":"\ud83d\udcda Documentation Priority","text":"<ol> <li>Quick Start: <code>docs/quickstart-local-development.md</code></li> <li>Architecture: <code>docs/Architecture.md</code> </li> <li>Deployment: <code>docs/DeploymentGuide.md</code></li> <li>API Reference: <code>docs/api/</code></li> <li>Troubleshooting: <code>docs/Troubleshooting.md</code></li> </ol> <p>This structure enables rapid navigation and understanding of the codebase while maintaining clear separation of concerns and supporting both development and production workflows.</p>"},{"location":"guides/utilities/","title":"Utilities & Services","text":""},{"location":"guides/utilities/#utilities-and-infrastructure-services","title":"Utilities and Infrastructure Services","text":"<p>Supporting utilities and infrastructure services provide the foundation for the Real-Time Voice Agent's scalability, resilience, and configurability. These modules are shared across all API endpoints and handlers.</p>"},{"location":"guides/utilities/#handler-selection-and-routing","title":"Handler Selection and Routing","text":"<p>The API uses a factory pattern to select appropriate handlers based on configuration and endpoint:</p>"},{"location":"guides/utilities/#handler-factory-apiv1endpointsmediapy","title":"Handler Factory (<code>/api/v1/endpoints/media.py</code>)","text":"<pre><code>async def _create_media_handler(websocket, call_connection_id, session_id, orchestrator):\n    \"\"\"Factory function creates handler based on ACS_STREAMING_MODE\"\"\"\n\n    if ACS_STREAMING_MODE == StreamMode.MEDIA:\n        # Three-thread architecture for traditional STT \u2192 LLM \u2192 TTS\n        return ACSMediaHandler(\n            websocket=websocket,\n            orchestrator_func=orchestrator,\n            call_connection_id=call_connection_id,\n            recognizer=await stt_pool.acquire(),\n            memory_manager=memory_manager,\n            session_id=session_id,\n        )\n\n    elif ACS_STREAMING_MODE == StreamMode.VOICE_LIVE:\n        # Azure Voice Live API integration\n        return VoiceLiveHandler(\n            azure_endpoint=AZURE_VOICE_LIVE_ENDPOINT,\n            model_name=AZURE_VOICE_LIVE_MODEL,\n            session_id=session_id,\n            websocket=websocket,\n            orchestrator=orchestrator,\n            lva_agent=injected_agent,\n        )\n</code></pre>"},{"location":"guides/utilities/#configuration-driven-routing","title":"Configuration-Driven Routing","text":"<pre><code># Environment configuration determines handler selection\nACS_STREAMING_MODE = StreamMode.MEDIA      # Default: three-thread architecture\nACS_STREAMING_MODE = StreamMode.VOICE_LIVE # Azure Voice Live integration  \nACS_STREAMING_MODE = StreamMode.TRANSCRIPTION # Lightweight transcription only\n\n# Handlers automatically selected at runtime based on configuration\n# No code changes required to switch between modes\n</code></pre>"},{"location":"guides/utilities/#resource-pool-management","title":"Resource Pool Management","text":""},{"location":"guides/utilities/#speech-to-text-pool-srcpoolsstt_pool","title":"Speech-to-Text Pool (<code>src.pools.stt_pool</code>)","text":"<pre><code>from src.pools.stt_pool import STTResourcePool\n\n# Managed pool of speech recognizers\nstt_pool = STTResourcePool(\n    pool_size=4,  # Concurrent recognizers\n    region=\"eastus\",\n    enable_diarization=True\n)\n\n# Automatic resource lifecycle in handlers\nrecognizer = await stt_pool.acquire()  # Get from pool\n# ... use recognizer ...\nawait stt_pool.release(recognizer)     # Return to pool\n</code></pre>"},{"location":"guides/utilities/#text-to-speech-pool-srcpoolstts_pool","title":"Text-to-Speech Pool (<code>src.pools.tts_pool</code>)","text":"<pre><code>from src.pools.tts_pool import TTSResourcePool\n\n# Shared TTS synthesizers across connections\ntts_pool = TTSResourcePool(\n    pool_size=4,  # Concurrent synthesizers\n    region=\"eastus\",\n    voice_name=\"en-US-JennyMultilingualV2Neural\"\n)\n\n# Pool-based resource management\nsynthesizer = await tts_pool.acquire()\nawait synthesizer.speak_text_async(\"Hello world\")\nawait tts_pool.release(synthesizer)\n</code></pre>"},{"location":"guides/utilities/#azure-openai-pool-srcpoolsaoai_pool","title":"Azure OpenAI Pool (<code>src.pools.aoai_pool</code>)","text":"<pre><code>from src.pools.aoai_pool import AOAIResourcePool\n\n# Managed OpenAI client connections\naoai_pool = AOAIResourcePool(\n    pool_size=8,  # Higher concurrency for AI processing\n    endpoint=AZURE_OPENAI_ENDPOINT,\n    model=\"gpt-4o\",\n    max_tokens=150\n)\n\n# Used by orchestrator for conversation processing\nclient = await aoai_pool.acquire()\nresponse = await client.chat_completions_create(messages=conversation_history)\nawait aoai_pool.release(client)\n</code></pre>"},{"location":"guides/utilities/#connection-management-srcpoolsconnection_manager","title":"Connection Management (<code>src.pools.connection_manager</code>)","text":"<p>Centralized WebSocket connection tracking and lifecycle management:</p> <pre><code>from src.pools.connection_manager import ConnectionManager\n\n# Single connection manager instance per application\nconn_manager = ConnectionManager()\n\n# Register connections with metadata and topic subscriptions\nconn_id = await conn_manager.register(\n    websocket=websocket,\n    client_type=\"media\",  # or \"dashboard\", \"conversation\"\n    call_id=call_connection_id,\n    session_id=session_id,\n    topics={\"media\", \"session\"}\n)\n\n# Topic-based broadcasting\nawait conn_manager.broadcast_topic(\"media\", {\n    \"type\": \"audio_status\", \n    \"status\": \"playing\"\n})\n\n# Session-isolated broadcasting  \nawait conn_manager.broadcast_session(session_id, {\n    \"type\": \"transcript\",\n    \"text\": \"User spoke something\"\n})\n\n# Automatic cleanup on disconnect\nawait conn_manager.unregister(conn_id)\n</code></pre>"},{"location":"guides/utilities/#state-management-and-persistence","title":"State Management and Persistence","text":""},{"location":"guides/utilities/#memory-manager-srcstatefulstate_managmentmemomanager","title":"Memory Manager (<code>src.stateful.state_managment.MemoManager</code>)","text":"<p>Conversation state and session persistence:</p> <pre><code>from src.stateful.state_managment import MemoManager\n\n# Load existing conversation or create new session\nmemory_manager = MemoManager.from_redis(session_id, redis_mgr)\n\n# Conversation history management\nmemory_manager.append_to_history(\"user\", \"Hello\")\nmemory_manager.append_to_history(\"assistant\", \"Hi there!\")\n\n# Context storage and retrieval\nmemory_manager.set_context(\"target_number\", \"+1234567890\")\nphone_number = memory_manager.get_context(\"target_number\")\n\n# Persistent storage to Redis\nawait memory_manager.persist_to_redis_async(redis_mgr)\n</code></pre>"},{"location":"guides/utilities/#redis-session-management-srcredismanager","title":"Redis Session Management (<code>src.redis.manager</code>)","text":"<pre><code>from src.redis.manager import AzureRedisManager\n\n# Azure-native Redis integration with Entra ID\nredis_mgr = AzureRedisManager(\n    host=\"your-redis.redis.cache.windows.net\",\n    credential=DefaultAzureCredential()\n)\n\n# Session data storage with TTL\nawait redis_mgr.set_value_async(f\"session:{session_id}\", session_data, expire=3600)\n\n# Call connection mapping for UI coordination\nawait redis_mgr.set_value_async(\n    f\"call_session_map:{call_connection_id}\", \n    browser_session_id\n)\n</code></pre>"},{"location":"guides/utilities/#voice-configuration-and-neural-voices","title":"Voice Configuration and Neural Voices","text":""},{"location":"guides/utilities/#voice-configuration-configvoice_config","title":"Voice Configuration (<code>config.voice_config</code>)","text":"<pre><code>from config.voice_config import VoiceConfiguration\n\n# Centralized voice metadata and selection\nvoice_config = VoiceConfiguration.from_env()\n\n# Get optimized voice for use case\nsupport_voice = voice_config.get_voice_alias(\"support_contact_center\")\nprint(f\"Voice: {support_voice.neural_voice}\")\nprint(f\"Style: {support_voice.style}\")  # cheerful, empathetic, etc.\n\n# Multi-language voice selection\nspanish_voice = voice_config.get_voice_for_language(\"es-ES\")\n</code></pre>"},{"location":"guides/utilities/#authentication-and-security","title":"Authentication and Security","text":""},{"location":"guides/utilities/#azure-entra-id-integration-srcauth","title":"Azure Entra ID Integration (<code>src.auth</code>)","text":"<pre><code>from azure.identity import DefaultAzureCredential\n\n# Keyless authentication for all Azure services\ncredential = DefaultAzureCredential()\n\n# Automatic token refresh and service principal authentication\n# Used by STT/TTS pools, Redis manager, and ACS clients\n</code></pre>"},{"location":"guides/utilities/#websocket-authentication-appsrtagentbackendsrcutilsauth","title":"WebSocket Authentication (<code>apps.rtagent.backend.src.utils.auth</code>)","text":"<pre><code>from apps.rtagent.backend.src.utils.auth import validate_acs_ws_auth\n\n# Optional WebSocket authentication for secure environments\ntry:\n    await validate_acs_ws_auth(websocket, required_scope=\"media.stream\")\n    # Proceed with authenticated connection\nexcept AuthError as e:\n    await websocket.close(code=4001, reason=\"Authentication required\")\n</code></pre>"},{"location":"guides/utilities/#observability-and-monitoring","title":"Observability and Monitoring","text":""},{"location":"guides/utilities/#opentelemetry-integration-utilstelemetry_config","title":"OpenTelemetry Integration (<code>utils.telemetry_config</code>)","text":"<pre><code>from utils.telemetry_config import configure_tracing\n\n# Comprehensive distributed tracing\nconfigure_tracing(\n    service_name=\"voice-agent-api\",\n    service_version=\"v1.0.0\",\n    otlp_endpoint=OTEL_EXPORTER_OTLP_ENDPOINT\n)\n\n# Automatic span creation for:\n# - WebSocket connections and lifecycle\n# - Speech recognition sessions  \n# - TTS synthesis operations\n# - Azure service calls\n# - Orchestrator processing\n</code></pre>"},{"location":"guides/utilities/#structured-logging-utilsml_logging","title":"Structured Logging (<code>utils.ml_logging</code>)","text":"<pre><code>from utils.ml_logging import get_logger\n\nlogger = get_logger(\"api.v1.media\")\n\n# Consistent JSON logging with correlation IDs\nlogger.info(\n    \"Media session started\",\n    extra={\n        \"session_id\": session_id,\n        \"call_connection_id\": call_connection_id,\n        \"streaming_mode\": str(ACS_STREAMING_MODE)\n    }\n)\n</code></pre>"},{"location":"guides/utilities/#performance-monitoring-srctoolslatency_tool","title":"Performance Monitoring (<code>src.tools.latency_tool</code>)","text":"<pre><code>from src.tools.latency_tool import LatencyTool\n\n# Track conversation timing metrics\nlatency_tool = LatencyTool(memory_manager)\n\n# Measure time to first byte for greeting\nlatency_tool.start(\"greeting_ttfb\")\nawait send_greeting_audio()\nlatency_tool.stop(\"greeting_ttfb\")\n\n# Automatic span attributes for performance analysis\n</code></pre>"},{"location":"guides/utilities/#development-and-testing-utilities","title":"Development and Testing Utilities","text":""},{"location":"guides/utilities/#load-testing-framework-testsload","title":"Load Testing Framework (<code>tests/load/</code>)","text":"<pre><code>from tests.load.utils.load_test_conversations import ConversationSimulator\n\n# Simulate high-load scenarios\nsimulator = ConversationSimulator(\n    base_url=\"wss://api.domain.com\",\n    concurrent_sessions=50,\n    conversation_length=10\n)\n\nawait simulator.run_load_test()\n</code></pre>"},{"location":"guides/utilities/#acs-event-simulation-testsconftestpy","title":"ACS Event Simulation (<code>tests/conftest.py</code>)","text":"<pre><code># Test fixtures for ACS webhook simulation\n@pytest.fixture\ndef acs_call_connected_event():\n    return {\n        \"eventType\": \"Microsoft.Communication.CallConnected\",\n        \"data\": {\n            \"callConnectionId\": \"test-call-123\",\n            \"correlationId\": \"test-correlation-456\"\n        }\n    }\n\n# Integration testing with mock ACS events\nasync def test_call_lifecycle(acs_call_connected_event):\n    response = await client.post(\"/api/v1/calls/callbacks\", \n                               json=[acs_call_connected_event])\n    assert response.status_code == 200\n</code></pre>"},{"location":"guides/utilities/#integration-patterns","title":"Integration Patterns","text":"<p>See Streaming Modes for detailed configuration options, Speech Recognition for STT integration patterns, and Speech Synthesis for TTS implementation details.</p>"},{"location":"industry/healthcare/","title":"Healthcare","text":""},{"location":"industry/healthcare/#healthcare-voice-agent-use-cases","title":"Healthcare Voice Agent Use Cases","text":""},{"location":"industry/healthcare/#voice-agent-platform-for-healthcare","title":"Voice Agent Platform for Healthcare","text":"flowchart TD     %% Business Drivers     subgraph Business [\"\ud83c\udfaf Healthcare Business Drivers\"]         A[\"\ud83d\udcb0 Cost Pressures\"]         B[\"\ud83d\udccb Documentation Burden\"]         C[\"\ud83c\udfe5 Care Complexity\"]     end      %% Healthcare Solutions     subgraph Solutions [\"\ud83c\udfe5 Voice Agent Solutions\"]         D[\"\ud83c\udfad Virtual Care\"]         E[\"\ud83d\udcdd Real-time Docs\"]         F[\"\u2695\ufe0f Patient Monitoring\"]         G[\"\ud83d\udd10 Prior Auth\"]         H[\"\ud83d\udd2c Trial Screening\"]         I[\"\ud83e\udded Health Navigation\"]         M[\"\ud83d\udde3\ufe0f EMR Voice Interface\"]     end      %% Technical Platform     subgraph Platform [\"\u26a1 Voice Agent Platform\"]          %% Voice Layer         J[\"\ud83c\udf99\ufe0f Voice ProcessingACS | Speech | OpenAI\"]          %% Agent Layer         K[\"\ud83e\udd16 AI Agents\ud83e\ude7a Medical | \ud83d\udee1\ufe0f Insurance | \ud83c\udfaf Routing\"]          %% Integration Layer         L[\"\ud83d\udd0c Integrations\ud83c\udfe5 Clinical | \ud83d\udcb0 Payer | \ud83d\udcbe Data | \ud83d\udccb EMR\"]     end      %% Connections     Business --&gt; Solutions     Solutions --&gt; J     J --&gt; K     K --&gt; L      %% Styling     classDef business fill:#3498db,stroke:#2c3e50,stroke-width:2px,color:#ffffff     classDef solution fill:#2ecc71,stroke:#27ae60,stroke-width:2px,color:#ffffff     classDef tech fill:#e67e22,stroke:#d35400,stroke-width:2px,color:#ffffff      class A,B,C business     class D,E,F,G,H,I,M solution     class J,K,L tech"},{"location":"industry/healthcare/#healthcare-voice-agent-use-cases_1","title":"Healthcare Voice Agent Use Cases","text":"<p>Powered by Azure Communication Services &amp; AI</p>"},{"location":"industry/healthcare/#clinical-care-patient-services","title":"Clinical Care &amp; Patient Services","text":"# Use Case Who Benefits How ACS Powers It Business Impact 1 Nurse Triage Hotline Patients seeking symptom guidance PSTN \u2192 Call Automation routes to AI triageReal-time speech \u2192 symptom analysisSeamless handoff to on-call nurse via Teams 30-50% reduction in routine callsFaster patient care 2 Smart Appointment Scheduling Outpatient clinics &amp; scheduling teams 24/7 bot handles inbound calls/textsFHIR integration for real-time slot availabilityAutomated SMS/email confirmations 10-15% reduction in no-shows24/7 self-service availability 5 Post-Discharge Follow-Up Care management &amp; readmission teams Event Grid triggers after EHR dischargeAutomated vitals surveys via ACS callsAlert escalation to nurses via Teams 5-10% readmission reductionProactive care monitoring 6 Crisis Mental Health Line Behavioral health services 24/7 hotline with sentiment analysisAuto-conference licensed counselorsHigh-risk phrase detection &amp; escalation Faster crisis intervention988 compliance ready"},{"location":"industry/healthcare/#pharmacy-prior-authorization","title":"Pharmacy &amp; Prior Authorization","text":"# Use Case Who Benefits How ACS Powers It Business Impact 3 Prescription Refill &amp; Prior-Auth Pharmacies &amp; PBM operations IVR captures Rx numbers automaticallyAzure Speech + LUIS for intent recognitionSmart escalation for complex cases 40 seconds average handle time reductionAutomated routine requests 9 Insurance Verification &amp; Appeals Revenue cycle operations Self-service IVR with GPT explanationsAuto-generated appeal letter draftsIntelligent case routing Faster reimbursementsReduced manual processing"},{"location":"industry/healthcare/#specialized-services","title":"Specialized Services","text":"# Use Case Who Benefits How ACS Powers It Business Impact 4 On-Demand Interpreters Emergency departments &amp; inpatient units Language detection via Speech servicesThree-way calls with remote interpretersLive captioning + real-time translation Joint Commission LEP complianceNo onsite interpreter staff needed 7 Clinical Documentation Assistant Physicians &amp; medical coders Real-time audio transcriptionAI-generated SOAP notes + CPT/ICD codesDirect EHR integration via HL7/FHIR 2-4 minutes saved per encounterHigher coding accuracy 8 Rural Tele-Consult Network Community hospitals &amp; specialists Emergency-triggered specialist callsTeams integration with screen sharingDICOM viewer support in same session Faster critical decisionsLower transfer costs 10 Secure Research Study Hotline Clinical trial coordinators Unique numbers per study armEncrypted recordings in Key VaultPower BI dashboards for PIs HIPAA-compliant participant engagementAuditable research processes"},{"location":"industry/healthcare/#platform-benefits-summary","title":"Platform Benefits Summary","text":"Operational Excellence Clinical Impact Financial Results 24/7 Availability Faster Care Delivery Cost Reduction Automated Workflows Better Outcomes Revenue Protection Enterprise Security Improved Experience Compliance Ready <p>Legend \u2014 Key ACS building blocks used Call Automation, WebSocket media streaming, Teams interop, Azure Speech &amp; OpenAI, Event Grid, Cosmos DB, API Management, App Gateway / WAF.</p>"},{"location":"industry/healthcare/#core-azure-building-blocks","title":"Core Azure Building Blocks","text":"Component Purpose Call Automation Programmable voice workflows WebSocket Media Streaming Real-time audio processing Teams Interop Seamless handoffs to live agents Azure Speech &amp; OpenAI STT/TTS and intelligent responses Event Grid Trigger-based automation Cosmos DB Patient data and session state API Management Secure healthcare integrations App Gateway / WAF Enterprise security and routing"},{"location":"operations/load-testing/","title":"Load Testing","text":""},{"location":"operations/load-testing/#load-testing","title":"Load Testing","text":"<p>Comprehensive WebSocket load testing framework for real-time voice agent using Locust with realistic conversation simulation and Azure Load Testing integration.</p> <p>Note: For unit tests, integration tests, and code quality validation, see Testing Framework.</p>"},{"location":"operations/load-testing/#overview","title":"Overview","text":"<p>The load testing framework validates WebSocket performance under realistic conversation scenarios using: - Locust-based testing: WebSocket simulation with real audio streaming - Audio generation: Production TTS-generated conversation audio - Azure integration: Seamless deployment to Azure Load Testing service - Realistic scenarios: Multi-turn conversation patterns</p>"},{"location":"operations/load-testing/#audio-generation","title":"Audio Generation","text":""},{"location":"operations/load-testing/#production-tts-integration","title":"Production TTS Integration","text":"<p>The audio generator uses production Azure Speech Services to create realistic conversation audio:</p> <pre><code># Audio generator configuration\nsynthesizer = SpeechSynthesizer(\n    region=os.getenv(\"AZURE_SPEECH_REGION\"),\n    key=os.getenv(\"AZURE_SPEECH_KEY\"),\n    language=\"en-US\",\n    voice=\"en-US-JennyMultilingualNeural\",\n    playback=\"never\",  # Disable for load testing\n    enable_tracing=False  # Performance optimization\n)\n</code></pre>"},{"location":"operations/load-testing/#quick-start-generate-audio-files","title":"Quick Start: Generate Audio Files","text":"<pre><code># Using Makefile (recommended)\nmake generate_audio\n\n# Direct command with options\npython tests/load/utils/audio_generator.py \\\n  --max-turns 5 \\\n  --scenarios insurance_inquiry quick_question\n</code></pre> <p>Generated Structure: <pre><code>tests/load/audio_cache/\n\u251c\u2500\u2500 insurance_inquiry_turn_1_of_5_abc123.pcm\n\u251c\u2500\u2500 insurance_inquiry_turn_2_of_5_def456.pcm\n\u251c\u2500\u2500 insurance_inquiry_turn_3_of_5_ghi789.pcm\n\u251c\u2500\u2500 quick_question_turn_1_of_3_pqr678.pcm\n\u251c\u2500\u2500 quick_question_turn_2_of_3_stu901.pcm\n\u2514\u2500\u2500 manifest.jsonl  # Audio file metadata\n</code></pre></p>"},{"location":"operations/load-testing/#conversation-scenarios","title":"Conversation Scenarios","text":""},{"location":"operations/load-testing/#insurance-inquiry-5-turns","title":"Insurance Inquiry (5 turns)","text":"<ol> <li>\"Hello, my name is Alice Brown, my social is 1234, and my zip code is 60601\"</li> <li>\"I'm calling about my auto insurance policy\"</li> <li>\"I need to understand what's covered under my current plan\"</li> <li>\"What happens if I get into an accident?\"</li> <li>\"Thank you for all the information, that's very helpful\"</li> </ol>"},{"location":"operations/load-testing/#quick-question-3-turns","title":"Quick Question (3 turns)","text":"<ol> <li>\"Hi there, I have a quick question\"</li> <li>\"Can you help me check my account balance?\"</li> <li>\"Thanks, that's all I needed to know\"</li> </ol>"},{"location":"operations/load-testing/#audio-requirements","title":"Audio Requirements","text":"Property Value Notes Format 16-bit PCM Compatible with WebSocket streaming Sample Rate 16 kHz Optimized for voice recognition Channels Mono Single channel for conversation Encoding Base64 WebSocket transmission format"},{"location":"operations/load-testing/#locust-load-testing-framework","title":"Locust Load Testing Framework","text":""},{"location":"operations/load-testing/#core-features","title":"Core Features","text":"<p>The Locust framework provides WebSocket load testing with:</p> <ul> <li>Real-time audio streaming: 20ms PCM chunks via WebSocket</li> <li>TTFB measurement: Time-to-first-byte response tracking</li> <li>Barge-in testing: Response interruption simulation</li> <li>Connection management: Automatic WebSocket reconnection</li> <li>Configurable scenarios: Multi-turn conversation patterns</li> </ul>"},{"location":"operations/load-testing/#websocket-testing-implementation","title":"WebSocket Testing Implementation","text":"<p>The actual Locust implementation simulates realistic WebSocket voice conversation patterns:</p> <pre><code># From locustfile.py - actual implementation\nWS_URL = os.getenv(\"WS_URL\", \"ws://127.0.0.1:8010/api/v1/media/stream\")\nPCM_DIR = os.getenv(\"PCM_DIR\", \"tests/load/audio_cache\")\nTURNS_PER_USER = int(os.getenv(\"TURNS_PER_USER\", \"3\"))\nCHUNKS_PER_TURN = int(os.getenv(\"CHUNKS_PER_TURN\", \"100\"))  # ~2s @20ms\nCHUNK_MS = int(os.getenv(\"CHUNK_MS\", \"20\"))  # 20 ms chunks\nFIRST_BYTE_TIMEOUT_SEC = float(os.getenv(\"FIRST_BYTE_TIMEOUT_SEC\", \"5.0\"))\nBARGE_QUIET_MS = int(os.getenv(\"BARGE_QUIET_MS\", \"400\"))\n</code></pre>"},{"location":"operations/load-testing/#audio-streaming-process","title":"Audio Streaming Process","text":"<p>Based on the actual <code>locustfile.py</code> implementation:</p> <ol> <li>Connection Setup: WebSocket connection with ACS correlation headers</li> <li>Audio Metadata: Initial format specification (16kHz PCM mono)</li> <li>Chunk Streaming: 20ms audio frames from PCM files at regular intervals</li> <li>Silence Frames: End-of-speech detection with generated low-level noise</li> <li>Response Measurement: TTFB and barge-in timing using <code>_measure_ttfb()</code></li> <li>Turn Rotation: Cycles through available PCM files for realistic conversation flow</li> </ol>"},{"location":"operations/load-testing/#configuration-options","title":"Configuration Options","text":"<pre><code># Environment variables for locustfile.py\nexport WS_URL=\"ws://localhost:8010/api/v1/media/stream\"\nexport PCM_DIR=\"tests/load/audio_cache\"\nexport TURNS_PER_USER=3\nexport CHUNKS_PER_TURN=100\nexport CHUNK_MS=20\nexport FIRST_BYTE_TIMEOUT_SEC=5.0\nexport BARGE_QUIET_MS=400\nexport WS_IGNORE_CLOSE_EXCEPTIONS=true\n</code></pre>"},{"location":"operations/load-testing/#performance-metrics-tracked","title":"Performance Metrics Tracked","text":""},{"location":"operations/load-testing/#real-time-metrics","title":"Real-time Metrics","text":"<ul> <li>TTFB (Time-to-First-Byte): Server response latency after audio completion</li> <li>Barge-in latency: Response interruption timing measured with <code>_wait_for_end_of_response()</code></li> <li>WebSocket stability: Connection durability under load with reconnection handling</li> <li>Audio streaming: Chunk transmission success rates with error handling</li> <li>Turn completion: End-to-end conversation success</li> </ul>"},{"location":"operations/load-testing/#test-implementation-example","title":"Test Implementation Example","text":"<pre><code>class ACSUser(User):\n    def _measure_ttfb(self, max_wait_sec: float) -&gt; tuple[bool, float]:\n        \"\"\"Time-To-First-Byte after EOS: measure server response time\"\"\"\n        start = time.time()\n        deadline = start + max_wait_sec\n        while time.time() &lt; deadline:\n            msg = self._recv_with_timeout(0.05)\n            if msg:\n                return True, (time.time() - start) * 1000.0\n        return False, (time.time() - start) * 1000.0\n</code></pre>"},{"location":"operations/load-testing/#running-load-tests","title":"Running Load Tests","text":""},{"location":"operations/load-testing/#local-testing","title":"Local Testing","text":"<pre><code># Basic local test\nmake run_load_test\n\n# Custom configuration via Makefile\nmake run_load_test \\\n  URL=wss://your-backend.azurecontainerapps.io/api/v1/media/stream \\\n  CONVERSATIONS=50 \\\n  CONCURRENT=10\n\n# Direct Locust command\nlocust -f tests/load/locustfile.py \\\n  --host=http://localhost:8010 \\\n  --users 20 \\\n  --spawn-rate 5 \\\n  --run-time 300s\n</code></pre>"},{"location":"operations/load-testing/#makefile-integration","title":"Makefile Integration","text":""},{"location":"operations/load-testing/#available-commands","title":"Available Commands","text":"<pre><code># Generate audio files for testing\nmake generate_audio\n\n# Run local load test with defaults\nmake run_load_test\n\n# Run with custom parameters\nmake run_load_test \\\n  URL=wss://prod-backend.azurecontainerapps.io/api/v1/media/stream \\\n  CONVERSATIONS=100 \\\n  CONCURRENT=20\n</code></pre>"},{"location":"operations/load-testing/#makefile-implementation","title":"Makefile Implementation","text":"<p>The actual implementation from the Makefile:</p> <pre><code># Audio generation target\ngenerate_audio:\n    python $(SCRIPTS_LOAD_DIR)/utils/audio_generator.py --max-turns 5\n\n# Load testing target with configurable parameters\nrun_load_test:\n    @echo \"Running load test (override with make run_load_test URL=wss://host)\"\n    $(eval URL ?= wss://$(LOCAL_URL)/api/v1/media/stream)\n    $(eval TURNS ?= 5)\n    $(eval CONVERSATIONS ?= 20)\n    $(eval CONCURRENT ?= 20)\n    @locust -f $(SCRIPTS_LOAD_DIR)/locustfile.py \\\n        --headless \\\n        -u $(CONVERSATIONS) \\\n        -r $(CONCURRENT) \\\n        --run-time 10m \\\n        --host $(URL) \\\n        --stop-timeout 60 \\\n        --csv=locust_report \\\n        --only-summary\n</code></pre> <p>Key Parameters: - <code>URL</code>: WebSocket endpoint to test (default: <code>wss://localhost:8010/api/v1/media/stream</code>) - <code>CONVERSATIONS</code>: Number of concurrent users (default: 20) - <code>CONCURRENT</code>: Spawn rate per second (default: 20) - <code>TURNS</code>: Number of conversation turns (default: 5)</p> <p>Output Files: - <code>locust_report_stats.csv</code>: Detailed performance statistics - <code>locust_report_failures.csv</code>: Error analysis - <code>locust_report_exceptions.csv</code>: Exception tracking</p>"},{"location":"operations/load-testing/#azure-load-testing-integration","title":"Azure Load Testing Integration","text":""},{"location":"operations/load-testing/#overview_1","title":"Overview","text":"<p>Azure Load Testing provides a fully managed load testing service that supports Locust-based testing for WebSocket applications.</p>"},{"location":"operations/load-testing/#setup-steps","title":"Setup Steps","text":""},{"location":"operations/load-testing/#1-create-azure-load-testing-resource","title":"1. Create Azure Load Testing Resource","text":"<pre><code># Create load testing resource\naz load create \\\n  --name \"voice-agent-loadtest\" \\\n  --resource-group \"rg-voice-agent\" \\\n  --location \"eastus\"\n</code></pre>"},{"location":"operations/load-testing/#2-prepare-test-files","title":"2. Prepare Test Files","text":"<p>Upload the following files to Azure Load Testing:</p> <p>Required Files: - <code>tests/load/locustfile.py</code> (rename to <code>locustfile.py</code>) - All PCM files from <code>tests/load/audio_cache/*.pcm</code></p> <p>File Organization: <pre><code>Azure Load Testing Upload:\n\u251c\u2500\u2500 locustfile.py                    # Main test script\n\u251c\u2500\u2500 insurance_inquiry_turn_1_of_5_abc123.pcm\n\u251c\u2500\u2500 insurance_inquiry_turn_2_of_5_def456.pcm\n\u251c\u2500\u2500 quick_question_turn_1_of_3_pqr678.pcm\n\u2514\u2500\u2500 manifest.jsonl                   # Audio file metadata\n</code></pre></p>"},{"location":"operations/load-testing/#3-configure-environment-variables","title":"3. Configure Environment Variables","text":"<p>Set the following environment variables in Azure Load Testing:</p> <pre><code># Target configuration\nWS_URL=wss://your-backend.azurecontainerapps.io/api/v1/media/stream\nPCM_DIR=./  # Azure places files in working directory\n\n# Performance tuning\nTURNS_PER_USER=3\nCHUNKS_PER_TURN=100\nCHUNK_MS=20\nFIRST_BYTE_TIMEOUT_SEC=5.0\nBARGE_QUIET_MS=400\nWS_IGNORE_CLOSE_EXCEPTIONS=true\n\n# Optional: Custom scenarios\nRESPONSE_TOKENS=recognizer,greeting,response,transcript,result\nEND_TOKENS=final,end,completed,stopped,barge\n</code></pre>"},{"location":"operations/load-testing/#4-configure-load-parameters","title":"4. Configure Load Parameters","text":"<p>Following Azure Load Testing best practices:</p> Parameter Development Staging Production Virtual Users 5-10 50-100 200-500 Spawn Rate 1-2/sec 5-10/sec 20-50/sec Test Duration 5-10 min 15-30 min 30-60 min Engine Instances 1-2 3-5 5-10"},{"location":"operations/load-testing/#5-add-server-monitoring","title":"5. Add Server Monitoring","text":"<p>Integrate Azure resources for comprehensive monitoring:</p> <pre><code># Add monitored resources using azd-env-name tag\naz load test server-metric create \\\n  --test-id \"voice-agent-test\" \\\n  --load-test-resource \"voice-agent-loadtest\" \\\n  --resource-group \"rg-voice-agent\" \\\n  --metric-id \"app-service-cpu\" \\\n  --resource-id \"/subscriptions/{subscription}/resourceGroups/{rg}/providers/Microsoft.Web/sites/{app-name}\"\n</code></pre>"},{"location":"operations/load-testing/#performance-targets","title":"Performance Targets","text":""},{"location":"operations/load-testing/#latency-benchmarks","title":"Latency Benchmarks","text":"Metric Target Acceptable Notes TTFB P95 &lt;2000ms &lt;3000ms Time to first server response Barge-in P95 &lt;500ms &lt;1000ms Response interruption latency Connection Success &gt;98% &gt;95% WebSocket establishment rate Turn Success &gt;95% &gt;90% Successful conversation completion"},{"location":"operations/load-testing/#capacity-targets","title":"Capacity Targets","text":"Environment Concurrent Users Duration Success Rate Development 10 users 5 minutes &gt;95% Staging 100 users 30 minutes &gt;95% Production 500+ users 60 minutes &gt;98%"},{"location":"operations/load-testing/#load-test-scenarios","title":"Load Test Scenarios","text":""},{"location":"operations/load-testing/#development-testing","title":"Development Testing","text":"<pre><code>make run_load_test \\\n  URL=ws://localhost:8010/api/v1/media/stream \\\n  CONVERSATIONS=5 \\\n  CONCURRENT=2\n</code></pre>"},{"location":"operations/load-testing/#staging-validation","title":"Staging Validation","text":"<pre><code>make run_load_test \\\n  URL=wss://staging-backend.azurecontainerapps.io/api/v1/media/stream \\\n  CONVERSATIONS=50 \\\n  CONCURRENT=10\n</code></pre>"},{"location":"operations/load-testing/#production-scale-testing","title":"Production Scale Testing","text":"<pre><code>make run_load_test \\\n  URL=wss://prod-backend.azurecontainerapps.io/api/v1/media/stream \\\n  CONVERSATIONS=200 \\\n  CONCURRENT=50\n</code></pre>"},{"location":"operations/load-testing/#performance-analysis","title":"Performance Analysis","text":""},{"location":"operations/load-testing/#result-interpretation","title":"Result Interpretation","text":""},{"location":"operations/load-testing/#locust-output-analysis","title":"Locust Output Analysis","text":"<pre><code># View Locust results\ncat locust_report_stats.csv | column -t -s,\n\n# Analyze specific metrics\ngrep \"speech_turns\" locust_report_stats.csv\n\n# Check error rates\ncat locust_report_failures.csv\n</code></pre>"},{"location":"operations/load-testing/#azure-monitor-integration","title":"Azure Monitor Integration","text":"<pre><code># Monitor Azure resources during test\naz monitor metrics list \\\n  --resource \"/subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.Web/sites/{app}\" \\\n  --metric \"CpuPercentage,MemoryPercentage\" \\\n  --start-time \"2024-01-01T00:00:00Z\" \\\n  --end-time \"2024-01-01T01:00:00Z\"\n</code></pre>"},{"location":"operations/load-testing/#key-performance-indicators","title":"Key Performance Indicators","text":""},{"location":"operations/load-testing/#response-time-metrics","title":"Response Time Metrics","text":"<ul> <li>TTFB percentiles: P50, P95, P99 response times</li> <li>Barge-in timing: Response interruption effectiveness</li> <li>End-to-end latency: Complete conversation turn timing</li> </ul>"},{"location":"operations/load-testing/#throughput-metrics","title":"Throughput Metrics","text":"<ul> <li>Requests per second: WebSocket message throughput</li> <li>Concurrent connections: Maximum sustainable WebSocket connections</li> <li>Audio streaming rate: PCM chunk transmission rates</li> </ul>"},{"location":"operations/load-testing/#error-metrics","title":"Error Metrics","text":"<ul> <li>Connection failures: WebSocket establishment errors</li> <li>Timeout rates: TTFB and response timeouts</li> <li>Audio streaming errors: PCM transmission failures</li> </ul>"},{"location":"operations/load-testing/#best-practices","title":"Best Practices","text":""},{"location":"operations/load-testing/#local-development-testing","title":"Local Development Testing","text":"<ol> <li>Start small: Begin with 5-10 concurrent users</li> <li>Validate setup: Ensure audio files are generated correctly</li> <li>Monitor resources: Watch local CPU/memory usage</li> <li>Check endpoints: Verify WebSocket connection establishment</li> </ol>"},{"location":"operations/load-testing/#azure-load-testing-deployment","title":"Azure Load Testing Deployment","text":"<ol> <li>File size optimization: Compress PCM files if needed for upload</li> <li>Environment parity: Match production WebSocket endpoints</li> <li>Monitoring integration: Include all relevant Azure resources</li> <li>Gradual scaling: Increase load incrementally</li> <li>Result analysis: Review both client and server metrics</li> </ol>"},{"location":"operations/load-testing/#performance-optimization","title":"Performance Optimization","text":""},{"location":"operations/load-testing/#websocket-configuration","title":"WebSocket Configuration","text":"<ul> <li>Connection pooling: Reuse WebSocket connections where possible</li> <li>Message batching: Optimize audio chunk transmission</li> <li>Error handling: Implement robust reconnection logic</li> </ul>"},{"location":"operations/load-testing/#audio-processing","title":"Audio Processing","text":"<ul> <li>Chunk sizing: Optimize PCM chunk size for performance</li> <li>Silence detection: Efficient end-of-speech handling</li> <li>Memory management: Proper audio buffer cleanup</li> </ul>"},{"location":"operations/load-testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/load-testing/#common-issues","title":"Common Issues","text":""},{"location":"operations/load-testing/#audio-generation-failures","title":"Audio Generation Failures","text":"<pre><code># Check Azure Speech Service credentials\necho $AZURE_SPEECH_KEY\necho $AZURE_SPEECH_REGION\n\n# Verify TTS functionality\npython tests/load/utils/audio_generator.py --test-connection\n</code></pre>"},{"location":"operations/load-testing/#websocket-connection-issues","title":"WebSocket Connection Issues","text":"<pre><code># Test WebSocket endpoint\nexport WS_URL=\"ws://localhost:8010/api/v1/media/stream\"\npython -c \"import websocket; ws = websocket.create_connection('$WS_URL'); print('Connected'); ws.close()\"\n</code></pre>"},{"location":"operations/load-testing/#azure-load-testing-upload-issues","title":"Azure Load Testing Upload Issues","text":"<ul> <li>Ensure file sizes are under Azure limits</li> <li>Verify all PCM files are in the correct format</li> <li>Check that locustfile.py is named correctly</li> </ul>"},{"location":"operations/load-testing/#debugging-load-test-issues","title":"Debugging Load Test Issues","text":""},{"location":"operations/load-testing/#locust-debug-mode","title":"Locust Debug Mode","text":"<pre><code># Run with verbose logging\nlocust -f tests/load/locustfile.py --loglevel DEBUG\n\n# Single user testing\nlocust -f tests/load/locustfile.py --users 1 --spawn-rate 1\n</code></pre>"},{"location":"operations/load-testing/#network-troubleshooting","title":"Network Troubleshooting","text":"<pre><code># Test network connectivity\ncurl -I https://your-backend.azurecontainerapps.io/health\n\n# Check DNS resolution\nnslookup your-backend.azurecontainerapps.io\n\n# Test WebSocket upgrade\ncurl -i -N \\\n  -H \"Connection: Upgrade\" \\\n  -H \"Upgrade: websocket\" \\\n  -H \"Sec-WebSocket-Key: test\" \\\n  -H \"Sec-WebSocket-Version: 13\" \\\n  https://your-backend.azurecontainerapps.io/api/v1/media/stream\n</code></pre>"},{"location":"operations/load-testing/#advanced-usage","title":"Advanced Usage","text":""},{"location":"operations/load-testing/#custom-scenarios","title":"Custom Scenarios","text":"<p>To add new conversation scenarios:</p> <ol> <li>Update audio generator with new conversation templates</li> <li>Regenerate audio files using <code>make generate_audio</code></li> <li>Update locustfile to reference new audio files</li> <li>Test locally before Azure deployment</li> </ol>"},{"location":"operations/load-testing/#integration-with-cicd","title":"Integration with CI/CD","text":"<pre><code># GitHub Actions example\n- name: Generate Load Test Audio\n  run: make generate_audio\n\n- name: Run Load Test\n  run: make run_load_test URL=${{ secrets.STAGING_WS_URL }}\n\n- name: Upload Results\n  uses: actions/upload-artifact@v3\n  with:\n    name: load-test-results\n    path: locust_report_*.csv\n</code></pre>"},{"location":"operations/load-testing/#continuous-performance-testing","title":"Continuous Performance Testing","text":""},{"location":"operations/load-testing/#scheduled-testing","title":"Scheduled Testing","text":"<pre><code># Daily performance regression test\n0 2 * * * cd /path/to/project &amp;&amp; make run_load_test CONVERSATIONS=20 CONCURRENT=5\n\n# Weekly capacity test\n0 3 * * 0 cd /path/to/project &amp;&amp; make run_load_test CONVERSATIONS=100 CONCURRENT=20\n</code></pre>"},{"location":"operations/load-testing/#performance-monitoring","title":"Performance Monitoring","text":"<ul> <li>Set up alerts for performance degradation</li> <li>Track performance trends over time</li> <li>Compare results across different environments</li> </ul> <p>This comprehensive load testing framework ensures reliable WebSocket performance testing with realistic audio streaming scenarios, supporting both local development and production-scale Azure Load Testing deployments.</p> <p>\ud83d\udcd6 References: Azure Load Testing \u2022 Locust Documentation \u2022 Azure Speech Services</p>"},{"location":"operations/monitoring/","title":"Monitoring","text":""},{"location":"operations/monitoring/#monitoring-observability-guide","title":"Monitoring &amp; Observability Guide","text":"<p>Application Insights Integration</p> <p>This guide explains how to configure, use, and troubleshoot Azure Application Insights for comprehensive telemetry in the real-time audio agent application.</p> <p>The application uses the Azure Monitor OpenTelemetry Distro to automatically collect and send telemetry data to Application Insights, including: - Structured logging - Distributed request tracing - Performance metrics - Live Metrics</p>"},{"location":"operations/monitoring/#configuration-authentication","title":"Configuration &amp; Authentication","text":""},{"location":"operations/monitoring/#environment-variables","title":"Environment Variables","text":"Variable Description Default Required <code>APPLICATIONINSIGHTS_CONNECTION_STRING</code> The connection string for your App Insights resource. None Yes <code>AZURE_MONITOR_DISABLE_LIVE_METRICS</code> Disables Live Metrics to reduce permissions. <code>false</code> No <code>ENVIRONMENT</code> Sets the environment (<code>dev</code>, <code>prod</code>). <code>dev</code> No"},{"location":"operations/monitoring/#authentication","title":"Authentication","text":"<p>The telemetry configuration uses the <code>DefaultAzureCredential</code> chain, which automatically handles authentication in both local and deployed environments: 1.  Managed Identity (in Azure): Automatically uses the system-assigned or user-assigned managed identity of the hosting service (e.g., Container Apps). 2.  Local Development: Falls back to credentials from Azure CLI, Visual Studio Code, or environment variables.</p>"},{"location":"operations/monitoring/#permissions-troubleshooting","title":"Permissions &amp; Troubleshooting","text":"<p>Problem: 'Forbidden' errors or 'The Agent/SDK does not have permissions to send telemetry'</p> <p>Symptoms: <pre><code>azure.core.exceptions.HttpResponseError: Operation returned an invalid status 'Forbidden'\nContent: {\"Code\":\"InvalidOperation\",\"Message\":\"The Agent/SDK does not have permissions to send telemetry...\"}\n</code></pre> This error typically occurs because the identity running the application (your user account locally, or a managed identity in Azure) lacks the necessary permissions to write telemetry, especially for the Live Metrics feature.</p> <p>Solutions: 1.  Immediate Fix (Disable Live Metrics): The simplest solution is to disable the Live Metrics feature, which requires elevated permissions.     <pre><code># Add this to your .env file or export it\nAZURE_MONITOR_DISABLE_LIVE_METRICS=true\n</code></pre> 2.  Grant Permissions (Local Development): Grant your user account the <code>Application Insights Component Contributor</code> role on the App Insights resource.     <pre><code># Grant permissions to your Azure CLI user\naz role assignment create \\\n  --assignee $(az account show --query user.name -o tsv) \\\n  --role \"Application Insights Component Contributor\" \\\n  --scope &lt;your-app-insights-resource-id&gt;\n</code></pre> 3.  Configure Managed Identity (Production): In Azure, ensure the managed identity of your Container App has the <code>Application Insights Component Contributor</code> role. This is handled automatically by the provided Bicep and Terraform templates.</p>"},{"location":"operations/monitoring/#viewing-telemetry-logs","title":"Viewing Telemetry &amp; Logs","text":"<p>Once configured, you can explore your application's telemetry in the Azure portal.</p>"},{"location":"operations/monitoring/#log-analytics-queries","title":"Log Analytics Queries","text":"<p>Navigate to your Application Insights resource, select Logs, and run Kusto (KQL) queries.</p> <p>Kusto Query Examples</p> View Recent ErrorsTrace a Specific CallCustom Metrics <pre><code>traces\n| where timestamp &gt; ago(1h)\n| where severityLevel &gt;= 3 // 3 for Error, 4 for Critical\n| order by timestamp desc\n</code></pre> <pre><code>requests\n| where url contains \"start_call\"\n| project timestamp, url, resultCode, duration, operation_Id\n| join kind=inner (\n    traces | extend operation_Id = tostring(customDimensions.operation_Id)\n) on operation_Id\n</code></pre> <pre><code>customMetrics\n| where name == \"custom_requests_total\"\n| extend endpoint = tostring(customDimensions.endpoint)\n| summarize sum(value) by endpoint\n</code></pre>"},{"location":"operations/monitoring/#key-monitoring-features","title":"Key Monitoring Features","text":"<ul> <li>Application Map: Visualizes the dependencies and communication between your services.</li> <li>Live Metrics: Real-time performance data (if permissions are granted).</li> <li>Performance: Analyze request latency, dependency calls, and identify bottlenecks.</li> <li>Failures: Investigate exceptions and failed requests with detailed stack traces.</li> </ul>"},{"location":"operations/monitoring/#production-best-practices","title":"Production Best Practices","text":"<ul> <li>Use Managed Identity: Always prefer managed identities for authentication in Azure.</li> <li>Use Key Vault: Store the Application Insights connection string in Azure Key Vault and reference it in your application configuration.</li> <li>Grant Minimal Permissions: Assign the most restrictive role necessary. If you don't need Live Metrics, the <code>Monitoring Metrics Publisher</code> role may be sufficient.</li> <li>Enable Alerts: Configure alert rules in Azure Monitor to be notified of high error rates, performance degradation, or other critical events.</li> <li>Sample Telemetry: For high-traffic applications, configure sampling to reduce costs while still collecting representative data.</li> </ul> <p>Additional Resources</p> <ul> <li>Azure Monitor OpenTelemetry Documentation</li> <li>Application Insights Troubleshooting</li> <li>Azure RBAC Documentation</li> </ul>"},{"location":"operations/testing/","title":"Testing","text":""},{"location":"operations/testing/#testing-framework","title":"Testing Framework","text":"<p>Comprehensive unit and integration testing suite for ARTVoice Accelerator covering core components along the call automation path.</p> <p>Note: For load testing and performance validation, see Load Testing Guide.</p>"},{"location":"operations/testing/#overview","title":"Overview","text":"<p>The testing framework provides validation for:</p> <ul> <li>Unit Tests: Core component testing for call automation path</li> <li>Integration Tests: End-to-end event handling and lifecycle testing</li> <li>DTMF Testing: Dual-tone multi-frequency validation and failure scenarios</li> <li>Code Quality: Automated formatting, linting, and type checking</li> </ul>"},{"location":"operations/testing/#unit-tests","title":"Unit Tests","text":""},{"location":"operations/testing/#test-coverage-overview","title":"Test Coverage Overview","text":"<p>The unit test suite validates critical components along the call automation path:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_acs_media_lifecycle.py         # Audio processing pipeline\n\u251c\u2500\u2500 test_acs_events_handlers.py         # Event processing &amp; WebSocket integration  \n\u251c\u2500\u2500 test_redis_manager.py               # Session state management\n\u251c\u2500\u2500 test_dtmf_validation.py             # DTMF tone processing\n\u251c\u2500\u2500 test_dtmf_validation_failure_cancellation.py  # DTMF error scenarios\n\u251c\u2500\u2500 test_events_architecture_simple.py  # Event-driven architecture\n\u251c\u2500\u2500 test_speech_queue.py                # Audio queue management\n\u2514\u2500\u2500 test_v1_events_integration.py       # API v1 event integration\n</code></pre>"},{"location":"operations/testing/#core-components-coverage","title":"Core Components Coverage","text":""},{"location":"operations/testing/#acs-media-lifecycle-test_acs_media_lifecyclepy","title":"ACS Media Lifecycle (<code>test_acs_media_lifecycle.py</code>)","text":"<p>Tests the real-time audio processing pipeline components:</p> <p>ThreadBridge Testing: - Queue management and speech result handling - Backpressure handling when queues are full - Cross-thread communication patterns</p> <p>SpeechSDKThread Testing: - Speech recognition lifecycle and audio streaming - Push stream initialization and management - Recognizer state management and error handling</p> <p>MainEventLoop Testing: - WebSocket message handling and audio metadata processing - Barge-in functionality and playback cancellation - Audio chunk processing and base64 decoding</p> <p>RouteTurnThread Testing: - Turn processing and conversation flow management - Cancellation logic and queue cleanup - Response task management</p> <pre><code># Example test coverage\ndef test_thread_bridge_queue_speech_result_put_nowait():\n    # Tests immediate queue operations\n\ndef test_main_event_loop_handle_barge_in_cancels_playback():\n    # Tests response interruption handling\n\ndef test_route_turn_thread_cancel_current_processing_clears_queue():\n    # Tests conversation state cleanup\n</code></pre>"},{"location":"operations/testing/#event-handlers-test_acs_events_handlerspy","title":"Event Handlers (<code>test_acs_events_handlers.py</code>)","text":"<p>Validates event processing and WebSocket integration:</p> <p>Call Event Processing: - Inbound and outbound call lifecycle management - Call connection state transitions - Participant management and call metadata</p> <p>DTMF Event Handling: - Tone sequence processing and validation - DTMF recognition and routing - Sequence building and context updates</p> <p>WebSocket Broadcasting: - Client notification system - Message serialization and delivery - Multi-client event distribution</p> <p>Event Routing: - Cloud event dispatcher functionality - Unknown event type handling - Event context management</p> <pre><code># Key test scenarios\ndef test_handle_call_initiated():\n    # Tests outbound call setup\n\ndef test_handle_call_connected_with_broadcast():\n    # Tests WebSocket client notifications\n\ndef test_handle_dtmf_tone_received():\n    # Tests tone processing and sequence building\n</code></pre>"},{"location":"operations/testing/#redis-session-management-test_redis_managerpy","title":"Redis Session Management (<code>test_redis_manager.py</code>)","text":"<p>Tests Azure Redis cluster management and session persistence:</p> <p>Cluster Detection: - Automatic cluster mode switching on MovedError - Fallback behavior when cluster support unavailable - Connection pool management</p> <p>Address Remapping: - IP to domain name mapping for Azure Redis - Cluster node address resolution - Connection string handling</p> <p>Session Operations: - Session data storage and retrieval - Conversation history persistence - Memory context management</p> <pre><code>def test_get_session_data_switches_to_cluster():\n    # Tests automatic cluster detection\n\ndef test_remap_cluster_address_to_domain():\n    # Tests Azure Redis address mapping\n</code></pre>"},{"location":"operations/testing/#dtmf-validation-test_dtmf_validationpy","title":"DTMF Validation (<code>test_dtmf_validation.py</code>)","text":"<p>Validates dual-tone multi-frequency processing:</p> <p>Validation Flow: - AWS Connect DTMF validation setup - Validation gate state management - Tone collection and processing</p> <p>Context Management: - Session state persistence during validation - Validation context setup and teardown - Error state handling</p> <p>Timeout Handling: - Validation completion monitoring - Timeout detection and handling - Async validation workflows</p> <pre><code>def test_setup_aws_connect_validation_flow_sets_context():\n    # Tests validation workflow initialization\n\ndef test_wait_for_dtmf_validation_completion_success():\n    # Tests successful validation completion\n</code></pre>"},{"location":"operations/testing/#running-unit-tests","title":"Running Unit Tests","text":""},{"location":"operations/testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all unit tests\npython -m pytest tests/ -v\n\n# Run specific test file\npython -m pytest tests/test_acs_media_lifecycle.py -v\n\n# Run with coverage reporting\npython -m pytest --cov=apps.rtagent.backend --cov-report=term-missing tests/\n\n# Run specific test method\npython -m pytest tests/test_acs_events_handlers.py::TestCallEventHandlers::test_handle_call_connected_with_broadcast -v\n</code></pre>"},{"location":"operations/testing/#advanced-test-options","title":"Advanced Test Options","text":"<pre><code># Run tests with detailed output\npython -m pytest tests/ -v -s\n\n# Run tests matching pattern\npython -m pytest tests/ -k \"dtmf\" -v\n\n# Run tests with performance profiling\npython -m pytest tests/ --durations=10\n\n# Run tests in parallel (if pytest-xdist installed)\npython -m pytest tests/ -n auto\n</code></pre>"},{"location":"operations/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"operations/testing/#event-architecture-testing","title":"Event Architecture Testing","text":"<p>Event Dispatching (<code>test_events_architecture_simple.py</code>): - Cloud event routing and handling - Event serialization and deserialization - Cross-component event flow validation</p> <p>Memory Management: - Session context persistence across events - Memory cleanup and lifecycle management - Context sharing between components</p> <p>Error Handling: - Exception management and recovery - Graceful degradation scenarios - Error propagation patterns</p>"},{"location":"operations/testing/#v1-events-integration-test_v1_events_integrationpy","title":"V1 Events Integration (<code>test_v1_events_integration.py</code>)","text":"<p>WebSocket Events: - Real-time event streaming validation - Event ordering and sequencing - Connection lifecycle management</p> <p>Event Serialization: - JSON event format validation - Event schema compliance - Backward compatibility testing</p> <p>Client Broadcasting: - Multi-client event distribution - Client subscription management - Event filtering and routing</p>"},{"location":"operations/testing/#code-quality","title":"Code Quality","text":""},{"location":"operations/testing/#automated-code-quality-checks","title":"Automated Code Quality Checks","text":"<p>The project uses comprehensive code quality tools:</p> <pre><code># Run all code quality checks\nmake check_code_quality\n\n# Auto-fix formatting issues  \nmake fix_code_quality\n\n# Individual tool execution\nmake run_unit_tests                 # Execute unit tests with coverage\n</code></pre>"},{"location":"operations/testing/#code-quality-tools","title":"Code Quality Tools","text":"<p>Formatting and Style: - ruff: Python linter and code formatter - black: Code formatting - isort: Import sorting and organization - flake8: Style guide enforcement</p> <p>Type Checking: - mypy: Static type checking - Type annotations: Function and class type hints</p> <p>Security: - bandit: Security vulnerability scanning - Dependency scanning: Package vulnerability checks</p> <p>Documentation: - interrogate: Docstring coverage checking - YAML validation: Configuration file validation</p>"},{"location":"operations/testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install pre-commit hooks\nmake set_up_precommit_and_prepush\n\n# Manual pre-commit execution\npre-commit run --all-files\n</code></pre>"},{"location":"operations/testing/#test-structure-and-patterns","title":"Test Structure and Patterns","text":""},{"location":"operations/testing/#test-organization","title":"Test Organization","text":"<p>File Naming Convention: - <code>test_&lt;component&gt;.py</code>: Unit tests for specific components - <code>test_&lt;feature&gt;_integration.py</code>: Integration tests for features - <code>test_&lt;scenario&gt;_failure_&lt;condition&gt;.py</code>: Failure scenario tests</p> <p>Test Class Structure: <pre><code>class TestComponentName:\n    \"\"\"Test class for ComponentName functionality.\"\"\"\n\n    @pytest.fixture\n    def component_instance(self):\n        \"\"\"Fixture providing test instance.\"\"\"\n        return ComponentName()\n\n    def test_component_basic_functionality(self, component_instance):\n        \"\"\"Test basic component operation.\"\"\"\n        pass\n\n    def test_component_error_handling(self, component_instance):\n        \"\"\"Test component error scenarios.\"\"\"\n        pass\n</code></pre></p>"},{"location":"operations/testing/#mocking-and-test-doubles","title":"Mocking and Test Doubles","text":"<p>Common Patterns: <pre><code># WebSocket mocking\nmock_websocket = MagicMock()\nmock_websocket.send_text = AsyncMock()\n\n# Azure service mocking  \nwith patch('azure.communication.callautomation.CallAutomationClient'):\n    # Test Azure integration\n    pass\n\n# Async operation testing\n@pytest.mark.asyncio\nasync def test_async_operation():\n    result = await async_function()\n    assert result is not None\n</code></pre></p>"},{"location":"operations/testing/#test-data-management","title":"Test Data Management","text":"<p>Fixtures for Test Data: <pre><code>@pytest.fixture\ndef sample_call_event():\n    \"\"\"Provide sample call event data.\"\"\"\n    return CloudEvent(\n        source=\"test\",\n        type=ACSEventTypes.CALL_CONNECTED,\n        data={\"callConnectionId\": \"test_123\"}\n    )\n\n@pytest.fixture  \ndef mock_memory_manager():\n    \"\"\"Provide mock memory manager.\"\"\"\n    manager = MagicMock()\n    manager.get_context.return_value = None\n    return manager\n</code></pre></p>"},{"location":"operations/testing/#development-workflow","title":"Development Workflow","text":""},{"location":"operations/testing/#testing-during-development","title":"Testing During Development","text":"<ol> <li>Write tests first: Follow TDD principles where applicable</li> <li>Run tests frequently: Use <code>pytest --watch</code> for continuous testing</li> <li>Check coverage: Maintain &gt;80% test coverage on critical paths</li> <li>Review test output: Analyze test failures and performance</li> </ol>"},{"location":"operations/testing/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># Example GitHub Actions workflow\n- name: Run Unit Tests\n  run: make run_unit_tests\n\n- name: Check Code Quality  \n  run: make check_code_quality\n\n- name: Upload Coverage\n  uses: codecov/codecov-action@v3\n  with:\n    file: ./coverage.xml\n</code></pre>"},{"location":"operations/testing/#test-environment-setup","title":"Test Environment Setup","text":"<pre><code># Create test environment\nmake create_conda_env\n\n# Activate environment\nmake activate_conda_env\n\n# Install test dependencies\npip install -r requirements-test.txt\n</code></pre>"},{"location":"operations/testing/#best-practices","title":"Best Practices","text":""},{"location":"operations/testing/#test-development-guidelines","title":"Test Development Guidelines","text":"<ol> <li>Isolation: Each test should be independent and repeatable</li> <li>Clarity: Test names should clearly describe what is being tested</li> <li>Coverage: Focus on critical paths and edge cases</li> <li>Performance: Keep unit tests fast (&lt;1s per test)</li> <li>Documentation: Include docstrings explaining complex test scenarios</li> </ol>"},{"location":"operations/testing/#debugging-test-failures","title":"Debugging Test Failures","text":"<pre><code># Run with verbose output\npython -m pytest tests/test_failing.py -v -s\n\n# Run with debugger\npython -m pytest tests/test_failing.py --pdb\n\n# Run with logging\npython -m pytest tests/test_failing.py --log-cli-level=DEBUG\n</code></pre>"},{"location":"operations/testing/#mock-strategy","title":"Mock Strategy","text":"<ul> <li>Unit tests: Mock external dependencies (Azure services, databases)</li> <li>Integration tests: Use test doubles for expensive operations</li> <li>End-to-end tests: Minimize mocking, use test environments</li> </ul>"},{"location":"operations/testing/#test-results-and-coverage","title":"Test Results and Coverage","text":""},{"location":"operations/testing/#current-test-coverage","title":"Current Test Coverage","text":"<p>The test suite provides comprehensive coverage of: - ACS Media Pipeline: 85% coverage of audio processing components - Event Handling: 90% coverage of webhook and cloud event processing - Redis Management: 95% coverage of session state management - DTMF Processing: 80% coverage of tone validation logic</p>"},{"location":"operations/testing/#coverage-reporting","title":"Coverage Reporting","text":"<pre><code># Generate HTML coverage report\npython -m pytest --cov=apps.rtagent.backend --cov-report=html tests/\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"operations/testing/#performance-testing","title":"Performance Testing","text":"<p>For performance and load testing capabilities, including WebSocket stress testing and Azure Load Testing integration, see the dedicated Load Testing Guide.</p> <p>This testing framework ensures the reliability and maintainability of the ARTVoice Accelerator platform through comprehensive unit and integration testing coverage.</p> <p>\ud83d\udcd6 References: pytest Documentation \u2022 Python Testing Best Practices \u2022 Azure SDK Testing</p>"},{"location":"operations/troubleshooting/","title":"Troubleshooting","text":""},{"location":"operations/troubleshooting/#troubleshooting-guide","title":"Troubleshooting Guide","text":"<p>Quick Solutions for Common Issues</p> <p>This guide provides solutions for common issues encountered with the Real-Time Voice Agent application, covering deployment, connectivity, and performance.</p>"},{"location":"operations/troubleshooting/#acs-websocket-issues","title":"ACS &amp; WebSocket Issues","text":"<p>Problem: ACS is not making outbound calls or audio quality is poor</p> <p>Symptoms: - Call fails to initiate or no audio connection is established. - ACS callback events are not received. - Audio quality is choppy or has high latency.</p> <p>Solutions: 1.  Check Container App Logs: <pre><code># Monitor backend logs for errors\nmake monitor_backend_deployment\n# Or directly query Azure Container Apps\naz containerapp logs show --name &lt;your-app-name&gt; --resource-group &lt;rg-name&gt;\n</code></pre> 2.  Verify Webhook Accessibility: Ensure your webhook URL is public and uses <code>https</code>. For local development, use a tunnel:     <pre><code># Use devtunnel for local development\ndevtunnel host -p 8010 --allow-anonymous\n</code></pre> 3.  Test WebSocket Connectivity: <pre><code># Install wscat (npm install -g wscat) and test the connection\nwscat -c wss://your-domain.com/ws/call/{callConnectionId}\n</code></pre> 4.  Check ACS &amp; Speech Resources: Verify that your ACS connection string and Speech service keys are correctly configured in your environment variables.</p> <p>Problem: WebSocket connection fails or drops frequently</p> <p>Symptoms: - <code>WebSocket connection failed</code> errors in the browser console. - Frequent reconnections or missing real-time updates.</p> <p>Solutions: 1.  Test WebSocket Endpoint Directly: <pre><code>wscat -c wss://&lt;backend-domain&gt;/api/v1/media/stream\n</code></pre> 2.  Check CORS Configuration: Ensure your frontend's origin is allowed in the backend's CORS settings, especially for WebSocket upgrade headers. 3.  Monitor Connection Lifecycle: Review backend logs for WebSocket connection and disconnection events to identify patterns.</p>"},{"location":"operations/troubleshooting/#backend-api-issues","title":"Backend &amp; API Issues","text":"<p>Problem: FastAPI server won't start or endpoints return 500 errors</p> <p>Symptoms: - Import errors, \"port already in use,\" or environment variable errors on startup. - API endpoints respond with <code>500 Internal Server Error</code>.</p> <p>Solutions: 1.  Check Python Environment &amp; Dependencies: <pre><code># Ensure you are in the correct conda environment\nconda activate audioagent\n# Reinstall dependencies\npip install -r requirements.txt\n</code></pre> 2.  Free Up Port: If port <code>8010</code> is in use, find and terminate the process:     <pre><code># Find and kill the process on macOS or Linux\nlsof -ti:8010 | xargs kill -9\n</code></pre> 3.  Run with Debug Logging: <pre><code>uvicorn apps.rtagent.backend.main:app --reload --port 8010 --log-level debug\n</code></pre> 4.  Verify Environment File (<code>.env</code>): Ensure the file exists and all required variables for Azure, Redis, and OpenAI are correctly set.</p>"},{"location":"operations/troubleshooting/#azure-ai-redis-issues","title":"Azure AI &amp; Redis Issues","text":"<p>Problem: Speech-to-Text or OpenAI API errors</p> <p>Symptoms: - Transcription is not appearing or is inaccurate. - AI-generated responses are missing or failing. - <code>401 Unauthorized</code> or <code>429 Too Many Requests</code> errors.</p> <p>Solutions: 1.  Check Keys and Endpoints: Verify that <code>AZURE_COGNITIVE_SERVICES_KEY</code>, <code>AZURE_OPENAI_ENDPOINT</code>, and other related variables are correct. 2.  Test Service Connectivity Directly: <pre><code># Test Azure Speech API (replace with a valid audio file)\ncurl -X POST \"https://{region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1\" \\\n  -H \"Ocp-Apim-Subscription-Key: {key}\" -H \"Content-Type: audio/wav\" --data-binary @test.wav\n\n# Test OpenAI API\ncurl -X GET \"{endpoint}/openai/deployments?api-version=2023-12-01-preview\" -H \"api-key: {key}\"\n</code></pre> 3.  Check Quotas and Model Names: Ensure your service quotas have not been exceeded and that the model deployment names in your code match those in the Azure portal.</p> <p>Problem: Redis connection timeouts or failures</p> <p>Symptoms: - High latency in agent responses. - Errors related to reading or writing session state. - <code>ConnectionTimeoutError</code> in backend logs.</p> <p>Solutions: 1.  Test Redis Connectivity: <pre><code># Use redis-cli to ping the server\nredis-cli -u $REDIS_URL ping\n</code></pre> 2.  Verify Configuration: For Azure Cache for Redis, check the connection string, firewall rules, and whether SSL/TLS is required.</p>"},{"location":"operations/troubleshooting/#deployment-performance","title":"Deployment &amp; Performance","text":"<p>Problem: <code>azd</code> deployment fails or containers won't start</p> <p>Symptoms: - <code>azd up</code> or <code>azd provision</code> command fails with an error. - Container Apps show a status of \"unhealthy\" or are stuck in a restart loop.</p> <p>Solutions: 1.  Check Azure Authentication &amp; Permissions: <pre><code># Ensure you are logged into the correct account\naz account show\n# Verify you have Contributor/Owner rights on the subscription\n</code></pre> 2.  Review Deployment Logs: <pre><code># Use the 'logs' command for detailed output\nazd logs\n# For container-specific issues\naz containerapp logs show --name &lt;app-name&gt; --resource-group &lt;rg-name&gt; --follow\n</code></pre> 3.  Purge and Redeploy: As a last resort, a clean deployment can resolve state issues:     <pre><code>azd down --force --purge\nazd up\n</code></pre></p> <p>Problem: High latency or memory usage</p> <p>Symptoms: - Slow audio processing or delayed AI responses. - Backend container memory usage grows over time and leads to restarts.</p> <p>Solutions: 1.  Monitor Resources: Use <code>htop</code> or <code>docker stats</code> locally, and Application Insights in Azure to monitor CPU and memory usage. 2.  Profile Memory Usage: Add lightweight profiling to your Python code to track object allocation and identify potential leaks.     <pre><code>import psutil\nprocess = psutil.Process()\nprint(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.1f} MB\")\n</code></pre> 3.  Check for Connection Leaks: Ensure that database and WebSocket connections are properly closed and managed.</p>"},{"location":"operations/troubleshooting/#debugging-tools-commands","title":"Debugging Tools &amp; Commands","text":"<p>Essential Commands for Quick Diagnostics</p> <ul> <li>Health Check: <pre><code>make health_check\n</code></pre></li> <li>Monitor Backend Deployment: <pre><code>make monitor_backend_deployment\n</code></pre></li> <li>View Logs: <pre><code>tail -f logs/app.log\n</code></pre></li> <li>Test WebSocket Connection: <pre><code>wscat -c ws://localhost:8010/ws/call/test-id\n</code></pre></li> <li>Check Network Connectivity: <pre><code>curl -v http://localhost:8010/health\n</code></pre></li> </ul> <p>Log Locations</p> <ul> <li>Backend: Container logs in Azure or <code>logs/app.log</code> locally.</li> <li>Frontend: Browser developer console (F12).</li> <li>Azure Services: Azure Monitor and Application Insights.</li> </ul>"},{"location":"samples/","title":"Overview","text":""},{"location":"samples/#samples-labs","title":"Samples &amp; Labs","text":"<p>Explore hands-on notebooks that demonstrate how to build and extend the Real-Time Voice Agent. The repository groups content into quickstart \u201cHello World\u201d tutorials and deeper lab exercises.</p>"},{"location":"samples/#hello-world-series","title":"Hello World Series","text":"<p>Beginner-friendly notebooks under <code>samples/hello_world/</code> walk through the core features step by step.</p> Notebook Summary <code>01-create-your-first-rt-agent.ipynb</code> Assemble a basic customer-support voice agent end to end. <code>02-run-test-rt-agent.ipynb</code> Execute call flows and validate the agent locally. <code>03-create-your-first-foundry-agents.ipynb</code> Provision Azure AI Foundry agents and wire them into the pipeline. <code>04-exploring-live-api.ipynb</code> Explore Azure Live Voice API capabilities. <code>05-create-your-first-livevoice.ipynb</code> Build out Live Voice scenarios using the accelerator scaffold. <p>Tips: - Run notebooks in sequence for a guided learning path. - Launch Jupyter from the repo root so relative imports work (<code>jupyter lab</code>). - Ensure <code>.env</code> contains valid Azure credentials before executing calls.</p>"},{"location":"samples/#advanced-labs","title":"Advanced Labs","text":"<p>Deep-dive content lives in <code>samples/labs/</code> and focuses on performance tuning, state management, and experimentation.</p> Notebook Focus <code>01-build-your-audio-agent.ipynb</code> Full voice-to-voice pipeline with Azure AI components. <code>02-how-to-use-aoai-for-realtime-transcriptions.ipynb</code> Optimize Azure OpenAI for real-time STT. <code>03-latency-arena.ipynb</code> Measure and optimize end-to-end latency. <code>04-memory-agents.ipynb</code> Implement conversational memory and session persistence. <code>05-speech-to-text-multilingual.ipynb</code> Multi-language transcription workflows. <code>06-text-to-speech.ipynb</code> Tune neural voice synthesis and SSML. <code>07-vad.ipynb</code> Voice activity detection experiments. <code>08-speech-to-text-diarization.ipynb</code> Multi-speaker diarization strategies. <code>voice-live.ipynb</code> Real-time voice tests across environments."},{"location":"samples/#audio-experiment-bundles","title":"Audio Experiment Bundles","text":"<ul> <li><code>labs/podcast_voice_tests/</code> \u2013 Compare TTS model outputs against ground-truth   recordings to evaluate voice quality.</li> <li><code>labs/recordings/</code> \u2013 Store captured audio samples for regression testing and   debugging.</li> </ul>"},{"location":"samples/#environment-checklist","title":"Environment Checklist","text":"<ol> <li>Python 3.11+ with project dependencies installed (<code>pip install -r requirements.txt</code>).</li> <li>Jupyter or VS Code notebooks. Activate the project virtual environment first.</li> <li>Azure resources (Speech, OpenAI, ACS, Redis) provisioned and referenced in <code>.env</code>.</li> </ol>"},{"location":"samples/#suggested-paths","title":"Suggested Paths","text":"<ul> <li>New to the stack? Start with the Hello World series (notebooks 01 \u2192 05).</li> <li>Voice quality &amp; tuning: Labs 06, 07, and the podcast voice tests.</li> <li>Performance &amp; reliability: Labs 03 and <code>voice-live.ipynb</code> for latency and live   validation.</li> </ul> <p>For additional context, see <code>samples/README.md</code> in the repository root\u2014this page is a condensed version suitable for the documentation site.</p>"},{"location":"security/authentication/","title":"Authentication","text":""},{"location":"security/authentication/#authentication-guide","title":"Authentication Guide","text":"<p>This document outlines the authentication and session management strategy for the real-time voice agent application that integrates Azure Communication Services (ACS) with external telephony systems.</p>"},{"location":"security/authentication/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Architecture Overview</li> <li>Authentication Flow Diagram</li> <li>Call Flow Types</li> <li>PSTN Flow (with DTMF Authentication)</li> <li>SIP Flow (with DTMF Authentication) </li> <li>API Flow (with Direct Lookup)</li> <li>WebSocket Authentication</li> <li>Session Key Management</li> <li>Security Architecture</li> <li>Technical References</li> </ol>"},{"location":"security/authentication/#architecture-overview","title":"Architecture Overview","text":"<p>The system uses Azure Communication Services Call Automation as the unified media processing layer with three distinct authentication mechanisms:</p> <ul> <li>\ud83d\udd10 DTMF Authentication: For PSTN and SIP calls using media tone analysis</li> <li>\ud83d\udd11 Direct Lookup: For API calls using call connection IDs</li> <li>\ud83d\udce6 Redis Session Store: Centralized session management across all flows</li> </ul>"},{"location":"security/authentication/#key-components","title":"Key Components","text":"<ul> <li>Event Grid Integration: Delivers <code>IncomingCall</code> events with webhook callbacks</li> <li>Call Automation REST API: Asynchronous interface for call control  </li> <li>Session Border Controllers (SBCs): Certified SBCs for Direct Routing</li> <li>WebSocket Security: Custom token validation for real-time media</li> <li>AWS Connect Integration: Cross-cloud session handoff using Resume Contact API</li> </ul>"},{"location":"security/authentication/#authentication-flow-diagram","title":"Authentication Flow Diagram","text":"flowchart LR   %% Style Definitions   classDef acs fill:#e0e7ff,stroke:#4f46e5,stroke-width:2px,color:#312e81   classDef backend fill:#fef3c7,stroke:#d97706,stroke-width:2px,color:#92400e   classDef storage fill:#dbeafe,stroke:#2563eb,stroke-width:2px,color:#1e40af   classDef external fill:#fed7aa,stroke:#ea580c,stroke-width:2px,color:#9a3412   classDef event fill:#fce7f3,stroke:#db2777,stroke-width:2px,color:#831843   classDef dtmf fill:#ecfeff,stroke:#0891b2,stroke-width:2px,color:#164e63    %% Call Flows   subgraph SIP[\"\ud83d\udcf1 SIP Flow\"]     SIP1[\ud83d\udcde SIP User] --&gt; SIP2[\u2601\ufe0f AWS Connect]     SIP2 --&gt; SIP3[\ud83d\udd27 Enterprise SBC] --&gt; SIP4[\ud83d\udce1 ACS SIP]   end    subgraph PSTN[\"\ud83d\udcde PSTN Flow\"]     PSTN1[\ud83d\udcde Caller] --&gt; PSTN2[\u2601\ufe0f AWS Connect]     PSTN2 --&gt; PSTN3[\ud83d\udd27 Telco SBC] --&gt; PSTN4[\ud83d\udce1 ACS PSTN]   end    subgraph API[\"\ud83e\uddd1\u200d\ud83d\udcbb API Flow\"]     API1[\ud83e\uddd1\u200d\ud83d\udcbb Client] --&gt; API2[\ud83d\udd10 EasyAuth] --&gt; API3[\u26a1 /api/call]     API3 --&gt; API4[\ud83d\udce1 ACS Automation]   end    %% Authentication Engine   subgraph AUTH[\"\ud83c\udfb5 Authentication Engine\"]     D1[\ud83d\udd0e Analyze DTMF Media]     D2[\ud83d\udd0d Lookup Session Key]     D3{\u2705 Key exists?}     D4[\u2705 Authorize WebSocket]     D5[\u274c Reject Connection]     D3 -- Yes --&gt; D4     D3 -- No --&gt; D5   end    %% Backend &amp; Storage   subgraph Backend[\"\ud83e\udde0 Backend Orchestrator\"]     WS[\ud83d\udd0c WebSocket Handler]     TV[\ud83d\udee1\ufe0f Token Validation]   end    Redis[(\ud83d\uddc4\ufe0f Redis Store)]    %% Flow Connections   SIP4 --&gt; D1   PSTN4 --&gt; D1   API4 --&gt; D2   D1 --&gt; D2   D2 --&gt; D3   D4 --&gt; WS   WS --&gt; TV --&gt; Redis    %% Session Storage   SIP2 --&gt;|store sip:call_id| Redis   PSTN2 --&gt;|store pstn:ani:code| Redis   API3 --&gt;|store call_connection_id| Redis    %% Styling   class SIP1,SIP2,SIP3,PSTN1,PSTN2,PSTN3,API1,API2,API3 external   class SIP4,PSTN4,API4 acs   class D1,D2,D3,D4,D5 dtmf   class WS,TV backend   class Redis storage"},{"location":"security/authentication/#call-flow-types","title":"Call Flow Types","text":""},{"location":"security/authentication/#pstn-flow","title":"PSTN Flow","text":"<p>Authentication Method: DTMF Media Analysis</p> <ol> <li>Call Setup: Caller \u2192 AWS Connect IVR \u2192 SBC \u2192 ACS PSTN</li> <li>Session Storage: AWS Connect stores <code>pstn:ani:code</code> in Redis</li> <li>Authentication: DTMF analysis extracts caller ANI and codes</li> <li>Validation: System checks Redis for matching composite key</li> <li>Authorization: Valid sessions proceed to WebSocket handler</li> </ol>"},{"location":"security/authentication/#sip-flow","title":"SIP Flow","text":"<p>Authentication Method: DTMF Media Analysis</p> <ol> <li>Call Setup: SIP Client \u2192 Enterprise SBC \u2192 ACS SIP Interface</li> <li>Session Storage: SBC stores <code>sip:call_id</code> in Redis</li> <li>Authentication: DTMF analysis extracts SIP call identifier</li> <li>Validation: System validates against stored session key</li> <li>Authorization: Authenticated calls establish media streaming</li> </ol>"},{"location":"security/authentication/#api-flow","title":"API Flow","text":"<p>Authentication Method: Direct Call Connection ID Lookup</p> <ol> <li>Call Setup: Client \u2192 <code>/api/call</code> endpoint \u2192 ACS Call Automation</li> <li>Session Storage: API stores <code>acs:call_connection_id</code> in Redis</li> <li>Authentication: Direct lookup using known call connection ID</li> <li>Validation: No DTMF analysis required</li> <li>Authorization: WebSocket established with validated session</li> </ol>"},{"location":"security/authentication/#websocket-authentication","title":"WebSocket Authentication","text":"<p>WebSocket connections require secure authentication for real-time media processing. The system implements custom token validation based on the established session.</p>"},{"location":"security/authentication/#websocket-security-implementation","title":"WebSocket Security Implementation","text":"<p>For detailed WebSocket authentication patterns, see the official Azure Communication Services documentation: Secure Webhook Endpoint</p>"},{"location":"security/authentication/#key-security-features","title":"Key Security Features","text":"<ul> <li>Token-based Authentication: Custom JWT tokens for WebSocket connections</li> <li>Session Correlation: WebSocket sessions correlated with call sessions</li> <li>Real-time Validation: Continuous validation during media streaming</li> <li>Secure Handshake: Encrypted WebSocket handshake process</li> </ul>"},{"location":"security/authentication/#session-key-management","title":"Session Key Management","text":""},{"location":"security/authentication/#session-key-formats","title":"Session Key Formats","text":"Flow Type Key Format Example Purpose PSTN <code>pstn:ani:code</code> <code>pstn:+15551234567:823</code> ANI + DTMF code from AWS Connect SIP <code>sip:call_id</code> <code>sip:abc-xyz-123</code> Call identifier from enterprise SBC API <code>acs:call_connection_id</code> <code>acs:call_connection_id:abc123</code> Direct call connection ID"},{"location":"security/authentication/#authentication-process","title":"Authentication Process","text":"<p>For PSTN/SIP Calls (DTMF-based): 1. External system stores session key in Redis 2. ACS receives <code>IncomingCall</code> event 3. System analyzes DTMF media stream 4. Extracts caller data and constructs composite key 5. Validates key existence in Redis 6. Authorizes or rejects WebSocket connection</p> <p>For API Calls (Direct lookup): 1. Client calls <code>/api/call</code> endpoint 2. System stores call connection ID in Redis 3. ACS establishes call and triggers event 4. Direct lookup using call connection ID 5. Authorizes WebSocket connection</p>"},{"location":"security/authentication/#security-architecture","title":"Security Architecture","text":""},{"location":"security/authentication/#dtmf-based-authentication-logic","title":"\ud83d\udd01 DTMF-Based Authentication Logic","text":"<p>The authentication flow leverages DTMF media analysis for telephony calls (PSTN/SIP) and direct call connection ID lookup for API-initiated calls to bridge session context between cloud platforms:</p> <ol> <li>Session Pre-Storage: External systems (AWS Connect, SBC) store composite keys in Redis; API calls store call connection IDs</li> <li>EventGrid Delivery: <code>IncomingCall</code> events trigger authentication processing</li> <li>Authentication Method:</li> <li>DTMF Analysis: For PSTN/SIP calls - extracts caller information and DTMF codes from media stream</li> <li>Direct Lookup: For API calls - uses call connection ID from the initial <code>/api/call</code> request</li> <li>Composite Key Construction: Builds Redis lookup key using extracted data or call connection ID</li> <li>Redis Validation: Checks if composite key exists in session store</li> <li>Authentication Decision: Key presence determines authorization success/failure</li> <li>WebSocket Authorization: Only validated sessions proceed to real-time media processing</li> </ol>"},{"location":"security/authentication/#authentication-states","title":"Authentication States","text":"<ul> <li>\u2705 Valid Session: </li> <li>PSTN/SIP: Composite key exists in Redis \u2192 DTMF authentication successful \u2192 WebSocket authorized</li> <li>API: Call connection ID exists in Redis \u2192 Direct lookup successful \u2192 WebSocket authorized</li> <li>\u23f3 Processing Authentication: </li> <li>PSTN/SIP: DTMF media analysis in progress \u2192 Authentication pending</li> <li>API: Call connection ID lookup in progress \u2192 Authentication pending</li> <li>\u274c Invalid Session: </li> <li>PSTN/SIP: Composite key missing or DTMF analysis failed \u2192 Authentication failed \u2192 Connection rejected</li> <li>API: Call connection ID missing or invalid \u2192 Authentication failed \u2192 Connection rejected</li> </ul>"},{"location":"security/authentication/#fallback-mechanisms","title":"Fallback Mechanisms","text":"<ul> <li>DTMF Re-analysis: If initial DTMF extraction fails for PSTN/SIP calls, system can re-analyze media stream</li> <li>Session Recovery: Temporary authentication failures can be retried with configurable timeout</li> <li>API Call Validation: For API calls, validates against the original <code>/api/call</code> request session</li> <li>Key Expiration: Redis keys have configurable TTL to prevent stale session accumulation</li> </ul>"},{"location":"security/authentication/#security-layers","title":"\ud83d\udd10 Security Layers","text":"Layer Method Purpose Event Grid Azure Event Grid Security Secure <code>IncomingCall</code> event delivery DTMF Analysis Media Stream Processing Extract caller data for authentication Redis Validation Composite Key Lookup Primary authorization decision WebSocket Custom JWT + Session Auth Real-time media stream security API Endpoints EasyAuth (Microsoft Entra ID) HTTP endpoint protection"},{"location":"security/authentication/#security-implementation","title":"Security Implementation","text":"<ul> <li>Media Stream Security: DTMF analysis on encrypted ACS streams</li> <li>Session Timeout: Configurable TTL (default: 1 hour)  </li> <li>Rate Limiting: DTMF processing abuse prevention</li> <li>Key Cryptography: Secure Redis key formatting</li> <li>Cross-Cloud Validation: Secure AWS Connect \u2194 ACS handoff</li> </ul>"},{"location":"security/authentication/#technical-references","title":"Technical References","text":""},{"location":"security/authentication/#azure-communication-services","title":"Azure Communication Services","text":"<ul> <li>Call Automation Overview</li> <li>Incoming Call Events</li> <li>Direct Routing SIP Specification</li> <li>Secure Webhook Endpoints</li> </ul>"},{"location":"security/authentication/#azure-event-grid-security","title":"Azure Event Grid &amp; Security","text":"<ul> <li>Event Grid Webhook Security</li> <li>Communication Services Events</li> </ul>"},{"location":"security/authentication/#aws-connect-integration","title":"AWS Connect Integration","text":"<ul> <li>Resume Contact Flow</li> <li>DTMF Handling</li> </ul>"},{"location":"security/authentication/#implementation-patterns","title":"Implementation Patterns","text":"<ul> <li>WebSocket Authentication</li> <li>Redis Session Management</li> </ul>"}]}