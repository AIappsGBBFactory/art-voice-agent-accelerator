{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35513e46",
   "metadata": {},
   "source": [
    "# Create your first AzureLiveVoiceAgent\n",
    "\n",
    "This notebook provides a guide for building real-time voice agents using Azure AI Agent Service and Azure Voice Live API.Usign our class `\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Client App    â”‚â—„â”€â”€â–ºâ”‚  Azure Voice     â”‚â—„â”€â”€â–ºâ”‚ Azure AI Agent      â”‚\n",
    "â”‚   (This Code)   â”‚    â”‚  Live API        â”‚    â”‚ Service             â”‚\n",
    "â”‚                 â”‚    â”‚                  â”‚    â”‚                     â”‚\n",
    "â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚ â”‚ Microphone  â”‚ â”‚    â”‚ â”‚ Speech-to-   â”‚ â”‚    â”‚ â”‚ Agent Logic     â”‚ â”‚\n",
    "â”‚ â”‚ Input       â”‚ â”œâ”€â”€â”€â”€â”¤ â”‚ Text (STT)   â”‚ â”œâ”€â”€â”€â”€â”¤ â”‚ & Instructions  â”‚ â”‚\n",
    "â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                 â”‚    â”‚                  â”‚    â”‚                     â”‚\n",
    "â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚ â”‚ Speaker     â”‚ â”‚    â”‚ â”‚ Text-to-     â”‚ â”‚    â”‚ â”‚ Knowledge Base  â”‚ â”‚\n",
    "â”‚ â”‚ Output      â”‚ â”‚â—„â”€â”€â”€â”¤ â”‚ Speech (TTS) â”‚ â”‚â—„â”€â”€â”€â”¤ â”‚ & Functions     â”‚ â”‚\n",
    "â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **YAML Configuration**: Defines agent binding and voice settings\n",
    "2. **WebSocket Connection**: Real-time bidirectional communication\n",
    "3. **Audio Streaming**: Low-latency audio input/output processing\n",
    "4. **Session Management**: Handles conversation state and events\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure AI Agent Service resource\n",
    "- Azure Voice Live API access\n",
    "- Python environment with required dependencies\n",
    "- Audio input/output devices (microphone and speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8bd92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully changed directory to: c:\\Users\\pablosal\\Desktop\\art-voice-agent-accelerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Changed directory to: c:\\Users\\pablosal\\Desktop\\art-voice-agent-accelerator\n",
      "ğŸ“ Current working directory: c:\\Users\\pablosal\\Desktop\\art-voice-agent-accelerator\n",
      "ğŸ“‹ Contents: .devcontainer, .env, .env.sample, .git, .github, .gitignore, .pre-commit-config.yaml, .pytest_cache, .vscode, apps...\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ Setup Working Directory for ARTAgent Framework Access\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging to track directory changes\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Navigate to the project root directory\n",
    "# This ensures we can import ARTAgent framework modules properly\n",
    "try:\n",
    "    # Move up two directories from samples/hello_world/ to project root\n",
    "    os.chdir(\"../../\")\n",
    "    \n",
    "    # Allow override via environment variable for different setups\n",
    "    target_directory = os.getenv(\n",
    "        \"TARGET_DIRECTORY\", os.getcwd()\n",
    "    )  # Use environment variable if available\n",
    "    \n",
    "    # Verify the target directory exists before changing\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        print(f\"âœ… Changed directory to: {os.getcwd()}\")\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"âŒ Directory does not exist: {target_directory}\")\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error changing directory: {e}\")\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")\n",
    "\n",
    "# Verify we're in the correct location\n",
    "print(f\"ğŸ“ Current working directory: {os.getcwd()}\")\n",
    "print(f\"ğŸ“‹ Contents: {', '.join(os.listdir('.')[:10])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff18773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YAML Configuration Guide ===\n",
      "\n",
      "The agent configuration uses YAML to define:\n",
      "\n",
      "agent:\n",
      "  name: \"Your Agent Name\"\n",
      "  description: \"Agent purpose and capabilities\"\n",
      "\n",
      "model:\n",
      "  deployment_id: \"gpt-4o\"    # Voice Live compatible model\n",
      "\n",
      "azure_ai_foundry_agent_connected:\n",
      "  agent_id: \"${AI_FOUNDRY_AGENT_ID}\"          # From Azure portal\n",
      "  project_name: \"${AI_FOUNDRY_PROJECT_NAME}\"  # AI Foundry project\n",
      "\n",
      "session:\n",
      "  voice:\n",
      "    name: \"en-US-Ava:DragonHDLatestNeural\"   # Voice selection\n",
      "    temperature: 0.8                          # Voice variation\n",
      "  vad_threshold: 0.5                         # Voice activity detection\n",
      "  vad_prefix_ms: 300                         # Voice detection timing\n",
      "  vad_silence_ms: 1000                       # Silence detection\n",
      "\n",
      "Environment Variable Check:\n",
      "  âœ“ AZURE_VOICE_LIVE_ENDPOINT\n",
      "  âœ“ AI_FOUNDRY_AGENT_ID\n",
      "  âœ“ AI_FOUNDRY_PROJECT_NAME\n",
      "\n",
      "âœ… All required environment variables are set\n"
     ]
    }
   ],
   "source": [
    "# Step 2: YAML Configuration Structure\n",
    "\n",
    "print(\"=== YAML Configuration Guide ===\")\n",
    "print(\"\"\"\n",
    "The agent configuration uses YAML to define:\n",
    "\n",
    "agent:\n",
    "  name: \"Your Agent Name\"\n",
    "  description: \"Agent purpose and capabilities\"\n",
    "\n",
    "model:\n",
    "  deployment_id: \"gpt-4o\"    # Voice Live compatible model\n",
    "\n",
    "azure_ai_foundry_agent_connected:\n",
    "  agent_id: \"${AI_FOUNDRY_AGENT_ID}\"          # From Azure portal\n",
    "  project_name: \"${AI_FOUNDRY_PROJECT_NAME}\"  # AI Foundry project\n",
    "\n",
    "session:\n",
    "  voice:\n",
    "    name: \"en-US-Ava:DragonHDLatestNeural\"   # Voice selection\n",
    "    temperature: 0.8                          # Voice variation\n",
    "  vad_threshold: 0.5                         # Voice activity detection\n",
    "  vad_prefix_ms: 300                         # Voice detection timing\n",
    "  vad_silence_ms: 1000                       # Silence detection\n",
    "\"\"\")\n",
    "\n",
    "# Validate required environment variables\n",
    "required_vars = [\n",
    "    \"AZURE_VOICE_LIVE_ENDPOINT\",\n",
    "    \"AI_FOUNDRY_AGENT_ID\", \n",
    "    \"AI_FOUNDRY_PROJECT_NAME\"\n",
    "]\n",
    "\n",
    "print(\"Environment Variable Check:\")\n",
    "missing_vars = []\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        print(f\"  âœ“ {var}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {var}: MISSING\")\n",
    "        missing_vars.append(var)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\\nâš ï¸  Missing variables: {', '.join(missing_vars)}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All required environment variables are set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8164671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Creation Process ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.20.0 Python/3.11.5 (Windows-10-10.0.26200-SP0)'\n",
      "No body was attached to the request\n",
      "[2025-10-09 23:15:40,515] INFO - apps.rtagent.backend.src.agents.Lvagent.base: Using token-based authentication (cognitiveservices scope)\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:Using token-based authentication (cognitiveservices scope)\n",
      "[2025-10-09 23:15:40,904] INFO - apps.rtagent.backend.src.agents.Lvagent.base: Azure Live Voice Agent initialized\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:Azure Live Voice Agent initialized\n",
      "[2025-10-09 23:15:40,915] INFO - apps.rtagent.backend.src.agents.Lvagent.base:   - Endpoint: https://poc-ai-agents-voice-resource.cognitiveservices.azure.com/\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:  - Endpoint: https://poc-ai-agents-voice-resource.cognitiveservices.azure.com/\n",
      "[2025-10-09 23:15:40,925] INFO - apps.rtagent.backend.src.agents.Lvagent.base:   - Model: gpt-4o\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:  - Model: gpt-4o\n",
      "[2025-10-09 23:15:40,936] INFO - apps.rtagent.backend.src.agents.Lvagent.base:   - Authentication: token\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:  - Authentication: token\n",
      "[2025-10-09 23:15:40,948] INFO - apps.rtagent.backend.src.agents.Lvagent.base:   - Agent ID: asst_Kp4exd80NINFuraHyWOftsuR\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:  - Agent ID: asst_Kp4exd80NINFuraHyWOftsuR\n",
      "[2025-10-09 23:15:40,959] INFO - apps.rtagent.backend.src.agents.Lvagent.base:   - Project: poc-ai-agents-voice\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:  - Project: poc-ai-agents-voice\n",
      "[2025-10-09 23:15:41,112] INFO - apps.rtagent.backend.src.agents.Lvagent.factory: Built AzureLiveVoiceAgent | deployment=gpt-4o | agent_id=asst_Kp4exd80NINFuraHyWOftsuR | project=poc-ai-agents-voice | voice=en-US-Ava:DragonHDLatestNeural\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.factory:Built AzureLiveVoiceAgent | deployment=gpt-4o | agent_id=asst_Kp4exd80NINFuraHyWOftsuR | project=poc-ai-agents-voice | voice=en-US-Ava:DragonHDLatestNeural\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created successfully:\n",
      "   Authentication: token\n",
      "   Agent ID: asst_Kp4exd80NINFuraHyWOftsuR\n",
      "   Project: poc-ai-agents-voice\n",
      "   Voice: en-US-Ava:DragonHDLatestNeural\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Agent Creation and Initialization\n",
    "\n",
    "from apps.rtagent.backend.src.agents.Lvagent.factory import build_lva_from_yaml\n",
    "\n",
    "print(\"=== Agent Creation Process ===\")\n",
    "\n",
    "# Load agent from YAML configuration\n",
    "yaml_path = \"apps\\\\rtagent\\\\backend\\\\src\\\\agents\\\\Lvagent\\\\agent_store\\\\auth_agent.yaml\"\n",
    "\n",
    "try:\n",
    "    agent = build_lva_from_yaml(yaml_path)\n",
    "    \n",
    "    print(\"âœ… Agent created successfully:\")\n",
    "    print(f\"   Authentication: {agent.auth_method}\")\n",
    "    print(f\"   Agent ID: {agent._binding.agent_id}\")\n",
    "    print(f\"   Project: {agent._binding.project_name}\")\n",
    "    print(f\"   Voice: {agent._session.voice_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Agent creation failed: {e}\")\n",
    "    print(\"Check your environment variables and YAML configuration\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5dc6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Connection Diagnostics ===\n",
      "ğŸ” Diagnosing Connection Configuration...\n",
      "WebSocket URL: wss://poc-ai-agents-voice-resource.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-05-01-preview&agent-project-name=poc-ai-agents-voice&agent-id=asst_Kp4exd80NINFuraHyWOftsuR&agent-access-token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkhTMjNiN0RvN1RjYVUxUm9MSHdwSXEyNFZZZyIsImtpZCI6IkhTMjNiN0RvN1RjYVUxUm9MSHdwSXEyNFZZZyJ9.eyJhdWQiOiJodHRwczovL2FpLmF6dXJlLmNvbSIsImlzcyI6Imh0dHBzOi8vc3RzLndpbmRvd3MubmV0LzcyZjk4OGJmLTg2ZjEtNDFhZi05MWFiLTJkN2NkMDExZGI0Ny8iLCJpYXQiOjE3NjAwNjg2MzcsIm5iZiI6MTc2MDA2ODYzNywiZXhwIjoxNzYwMDczMDgwLCJfY2xhaW1fbmFtZXMiOnsiZ3JvdXBzIjoic3JjMSJ9LCJfY2xhaW1fc291cmNlcyI6eyJzcmMxIjp7ImVuZHBvaW50IjoiaHR0cHM6Ly9ncmFwaC53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvdXNlcnMvOTdiZjJlMWYtMmZmNy00ZDgxLTgzMjgtMmRlOTg4Y2IxMjE2L2dldE1lbWJlck9iamVjdHMifX0sImFjciI6IjEiLCJhaW8iOiJBYVFBVy84YUFBQUFpTW5Ja1NmV2tjMzN5VVdaS09KSURYTk5UY3FaTTg1RU90NjdaU25ZQWludEp5c3o5alhiQUhDTWpDYWExWVBHdGRUSDhJZXdJcE83WHFkYkNrUkpJYTN6VVlENmlkZjR4NGlVUXlKSER5NVpCTmp4bnJCQktZVFhMVHhDWXp2WFk0WWgvUFNPaHF2SGpLeENjVFRFaDlvZjZqVis4cmptSkpqQ3VsVTVMMXlSTEk0bHhLRmR6UUZFRUVHVjB1VHlTMzBJMklkL1pBdW96Uk4yZ25ZWktBPT0iLCJhbXIiOlsicnNhIiwibWZhIl0sImFwcGlkIjoiMDRiMDc3OTUtOGRkYi00NjFhLWJiZWUtMDJmOWUxYmY3YjQ2IiwiYXBwaWRhY3IiOiIwIiwiZGV2aWNlaWQiOiI1ZDFmZDdjNS04NmEwLTQ3YzYtOWE3ZC04ZDQ0N2MwZjZkYWIiLCJmYW1pbHlfbmFtZSI6IlNhbHZhZG9yIExvcGV6IiwiZ2l2ZW5fbmFtZSI6IlBhYmxvIiwiaWR0eXAiOiJ1c2VyIiwiaXBhZGRyIjoiNjQuNjQuMTUwLjExNiIsIm5hbWUiOiJQYWJsbyBTYWx2YWRvciBMb3BleiIsIm9pZCI6Ijk3YmYyZTFmLTJmZjctNGQ4MS04MzI4LTJkZTk4OGNiMTIxNiIsIm9ucHJlbV9zaWQiOiJTLTEtNS0yMS0yMTI3NTIxMTg0LTE2MDQwMTI5MjAtMTg4NzkyNzUyNy03MjA2MDI3MiIsInB1aWQiOiIxMDAzMjAwMzAyNTk4MDIzIiwicmgiOiIxLkFSb0F2NGo1Y3ZHR3IwR1JxeTE4MEJIYlIxOXZwaGpmMnhkTW5kY1dOSEVxbkw0YUFDOGFBQS4iLCJzY3AiOiJ1c2VyX2ltcGVyc29uYXRpb24iLCJzaWQiOiIwMDdiYzc5OS03YTZmLTk1ZGQtZDQxMy04YzhjNDU3NGJjY2EiLCJzdWIiOiJtVlBsQmFlV2N3MWpHZ01BQnR3OE9JazBPYXl1TjM0SllvLUJhUUc1aEprIiwidGlkIjoiNzJmOTg4YmYtODZmMS00MWFmLTkxYWItMmQ3Y2QwMTFkYjQ3IiwidW5pcXVlX25hbWUiOiJwYWJsb3NhbEBtaWNyb3NvZnQuY29tIiwidXBuIjoicGFibG9zYWxAbWljcm9zb2Z0LmNvbSIsInV0aSI6IkQxUWxfTDVqTVVXaWJaZVRTTjFZQUEiLCJ2ZXIiOiIxLjAiLCJ4bXNfZnRkIjoiaDZUcVozbk5iUWgwVTc3eUozVWhLYm1EXzFUZjlCdHdGOVV4VGlfcXJGd0JkWE56YjNWMGFDMWtjMjF6IiwieG1zX2lkcmVsIjoiMTQgMSJ9.CKchkuiN6X8A06_Iwzj1zDiObXsrolMEeq12tG0DqzKBySQ9jhpjHBAtx9bCX4LJ00810Wf5vyB7wPuPh2FeKUM38sdLgQNx_Ldqrsn6NsW5ehyZpWyaJlaIj3a8kkxP7KPLcQQ7dFMwFZxQogDTOnWkOZy1VcUKpJ9Ysy_qL15a56UuKlgL71S8V5LV0sBtZyZ9dHHf781KLLdxcRqfW7vWb3zyB2Pq7VpcXiE-mwIWK7hoRCDUSSf-lr1I7JkdLa2tAkAusbJ-JTwgfx24yaV6yD5ZjtPANNs4lXp35vBtvMjns1prK_-bCxDJ2xb1vd4QacoLFDkCLuR648fnfQ\n",
      "Authentication method: token\n",
      "Endpoint: https://poc-ai-agents-voice-resource.cognitiveservices.azure.com/\n",
      "âœ… agent-access-token found in URL\n",
      "Headers: Not available\n",
      "ğŸ”Œ Attempting WebSocket connection...\n",
      "   URL: wss://poc-ai-agents-voice-resource.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-09 23:15:46,916] ERROR - apps.rtagent.backend.src.agents.Lvagent.transport: WebSocket error: Handshake status 400 BadRequest -+-+- {'content-length': '169', 'content-type': 'application/json', 'apim-request-id': '017a2d0d-abe6-4f6a-8685-ba0d18242042', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:15:47 GMT'} -+-+- b'{\"error\":{\"code\":\"Tenant provided in token does not match resource token\",\"message\":\"Token tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 does not match resource tenant.\"}}'\n",
      "ERROR:apps.rtagent.backend.src.agents.Lvagent.transport:WebSocket error: Handshake status 400 BadRequest -+-+- {'content-length': '169', 'content-type': 'application/json', 'apim-request-id': '017a2d0d-abe6-4f6a-8685-ba0d18242042', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:15:47 GMT'} -+-+- b'{\"error\":{\"code\":\"Tenant provided in token does not match resource token\",\"message\":\"Token tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 does not match resource tenant.\"}}'\n",
      "ERROR:websocket:Handshake status 400 BadRequest -+-+- {'content-length': '169', 'content-type': 'application/json', 'apim-request-id': '017a2d0d-abe6-4f6a-8685-ba0d18242042', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:15:47 GMT'} -+-+- b'{\"error\":{\"code\":\"Tenant provided in token does not match resource token\",\"message\":\"Token tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 does not match resource tenant.\"}}' - goodbye\n",
      "[2025-10-09 23:15:46,926] INFO - apps.rtagent.backend.src.agents.Lvagent.transport: WebSocket closed: code=None, msg=None\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.transport:WebSocket closed: code=None, msg=None\n",
      "[2025-10-09 23:15:56,218] ERROR - apps.rtagent.backend.src.agents.Lvagent.base: Failed to connect: WebSocket did not open within 10.0s (last_error=Handshake status 400 BadRequest -+-+- {'content-length': '169', 'content-type': 'application/json', 'apim-request-id': '017a2d0d-abe6-4f6a-8685-ba0d18242042', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:15:47 GMT'} -+-+- b'{\"error\":{\"code\":\"Tenant provided in token does not match resource token\",\"message\":\"Token tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 does not match resource tenant.\"}}')\n",
      "ERROR:apps.rtagent.backend.src.agents.Lvagent.base:Failed to connect: WebSocket did not open within 10.0s (last_error=Handshake status 400 BadRequest -+-+- {'content-length': '169', 'content-type': 'application/json', 'apim-request-id': '017a2d0d-abe6-4f6a-8685-ba0d18242042', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:15:47 GMT'} -+-+- b'{\"error\":{\"code\":\"Tenant provided in token does not match resource token\",\"message\":\"Token tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 does not match resource tenant.\"}}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Connection failed: WebSocket did not open within 10.0s (last_error=Handshake status 400 BadRequest -+-+- {'content-length': '169', 'content-type': 'application/json', 'apim-request-id': '017a2d0d-abe6-4f6a-8685-ba0d18242042', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:15:47 GMT'} -+-+- b'{\"error\":{\"code\":\"Tenant provided in token does not match resource token\",\"message\":\"Token tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 does not match resource tenant.\"}}')\n",
      "\n",
      "ğŸ› ï¸  400 BadRequest Troubleshooting:\n",
      "   1. Check if agent-access-token is in the WebSocket URL\n",
      "   2. Verify AI_FOUNDRY_AGENT_ID is correct\n",
      "   3. Ensure AI_FOUNDRY_PROJECT_NAME matches your Azure AI Foundry project\n",
      "   4. Check if your Azure authentication is valid\n",
      "   5. Verify the endpoint format: https://your-resource.services.ai.azure.com/\n",
      "\n",
      "ğŸ”¬ Additional Diagnostics:\n",
      "   Agent ID: asst_Kp4exd80NINFuraHyWOftsuR\n",
      "   Project: poc-ai-agents-voice\n",
      "   URL contains token: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-09 23:15:56,431] INFO - apps.rtagent.backend.src.agents.Lvagent.audio_io: SpeakerSink stopped.\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.audio_io:SpeakerSink stopped.\n",
      "[2025-10-09 23:15:56,437] INFO - apps.rtagent.backend.src.agents.Lvagent.base: Azure Live Voice Agent connection closed\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:Azure Live Voice Agent connection closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âŒ Connection failed - please check the troubleshooting steps above\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Connection Testing and Validation\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(\"=== Connection Diagnostics ===\")\n",
    "\n",
    "# First, let's diagnose the connection configuration\n",
    "print(\"ğŸ” Diagnosing Connection Configuration...\")\n",
    "print(f\"WebSocket URL: {agent.url}\")\n",
    "print(f\"Authentication method: {agent.auth_method}\")\n",
    "print(f\"Endpoint: {agent._endpoint}\")\n",
    "\n",
    "# Check URL format\n",
    "if \"agent-access-token\" not in agent.url:\n",
    "    print(\"âš ï¸  WARNING: agent-access-token missing from URL\")\n",
    "else:\n",
    "    print(\"âœ… agent-access-token found in URL\")\n",
    "\n",
    "# Check headers\n",
    "print(f\"Headers: {list(agent._ws_headers.keys()) if hasattr(agent, '_ws_headers') else 'Not available'}\")\n",
    "\n",
    "def test_agent_connection():\n",
    "    \"\"\"Test the agent connection and session establishment with detailed error reporting.\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”Œ Attempting WebSocket connection...\")\n",
    "        print(f\"   URL: {agent.url[:100]}...\")\n",
    "        \n",
    "        # Try to connect with detailed error handling\n",
    "        agent.connect()\n",
    "        \n",
    "        # Wait for session events\n",
    "        print(\"âœ… Connection successful! Waiting for session events...\")\n",
    "        for i in range(10):\n",
    "            msg = agent._ws.recv(timeout_s=0.5)\n",
    "            if msg:\n",
    "                try:\n",
    "                    event = json.loads(msg)\n",
    "                    event_type = event.get(\"type\", \"unknown\")\n",
    "                    print(f\"   ğŸ“¨ Received: {event_type}\")\n",
    "                    \n",
    "                    if event_type == \"session.created\":\n",
    "                        session_id = event.get(\"session\", {}).get(\"id\", \"unknown\")\n",
    "                        print(f\"âœ… Session created: {session_id}\")\n",
    "                        break\n",
    "                    elif event_type == \"error\":\n",
    "                        error = event.get(\"error\", {})\n",
    "                        print(f\"âŒ API Error: {error}\")\n",
    "                        return False\n",
    "                except Exception as parse_error:\n",
    "                    print(f\"   ğŸ“„ Raw message: {msg[:100]}...\")\n",
    "        \n",
    "        # Test message sending\n",
    "        test_message = {\n",
    "            \"type\": \"conversation.item.create\",\n",
    "            \"item\": {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"Hello, this is a connection test.\"}]\n",
    "            }\n",
    "        }\n",
    "        agent._ws.send_dict(test_message)\n",
    "        print(\"âœ… Test message sent successfully\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        agent.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Connection failed: {e}\")\n",
    "        \n",
    "        # Provide specific guidance for 400 BadRequest\n",
    "        if \"400 BadRequest\" in str(e):\n",
    "            print(\"\\nğŸ› ï¸  400 BadRequest Troubleshooting:\")\n",
    "            print(\"   1. Check if agent-access-token is in the WebSocket URL\")\n",
    "            print(\"   2. Verify AI_FOUNDRY_AGENT_ID is correct\")\n",
    "            print(\"   3. Ensure AI_FOUNDRY_PROJECT_NAME matches your Azure AI Foundry project\")\n",
    "            print(\"   4. Check if your Azure authentication is valid\")\n",
    "            print(\"   5. Verify the endpoint format: https://your-resource.services.ai.azure.com/\")\n",
    "            \n",
    "            # Additional diagnostics\n",
    "            print(\"\\nğŸ”¬ Additional Diagnostics:\")\n",
    "            print(f\"   Agent ID: {agent._binding.agent_id}\")\n",
    "            print(f\"   Project: {agent._binding.project_name}\")\n",
    "            print(f\"   URL contains token: {'agent-access-token' in agent.url}\")\n",
    "            \n",
    "        try:\n",
    "            agent.close()\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "# Run connection test\n",
    "success = test_agent_connection()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nâœ… Agent is ready for voice streaming\")\n",
    "else:\n",
    "    print(\"\\nâŒ Connection failed - please check the troubleshooting steps above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1207d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 400 BadRequest Error Troubleshooting ===\n",
      "1ï¸âƒ£ Checking Environment Variables...\n",
      "   âœ… AZURE_VOICE_LIVE_ENDPOINT: https://poc-ai-agents-voice-re...\n",
      "   âœ… AI_FOUNDRY_AGENT_ID: asst_Kp4exd80NINFuraHyWOftsuR...\n",
      "   âœ… AI_FOUNDRY_PROJECT_NAME: poc-ai-agents-voice...\n",
      "\n",
      "2ï¸âƒ£ Checking Endpoint Format...\n",
      "   âš ï¸  Endpoint should end with '.services.ai.azure.com/': https://poc-ai-agents-voice-resource.cognitiveservices.azure.com/\n",
      "\n",
      "3ï¸âƒ£ Checking Agent Configuration...\n",
      "   Agent ID: asst_Kp4exd80NINFuraHyWOftsuR\n",
      "   Project: poc-ai-agents-voice\n",
      "   URL: wss://poc-ai-agents-voice-resource.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-...\n",
      "   âœ… agent-access-token found in URL\n",
      "\n",
      "4ï¸âƒ£ Recommended Solutions:\n",
      "   Issues found:\n",
      "   â€¢ Incorrect endpoint format\n",
      "\n",
      "   ğŸ”§ Try these fixes:\n",
      "   1. Verify your environment variables are set correctly\n",
      "   2. Ensure your Azure AI Foundry agent ID is correct\n",
      "   3. Check that your project name matches exactly\n",
      "   4. Verify your Azure authentication is working\n",
      "   5. Try recreating the agent object:\n",
      "      agent = build_lva_from_yaml(yaml_path)\n",
      "\n",
      "âš ï¸  Issues detected - please fix the above problems and recreate the agent\n"
     ]
    }
   ],
   "source": [
    "# ğŸ› ï¸ Troubleshooting: Fix 400 BadRequest Error\n",
    "# Run this cell if you're getting WebSocket handshake errors\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=== 400 BadRequest Error Troubleshooting ===\")\n",
    "\n",
    "def diagnose_and_fix():\n",
    "    \"\"\"Diagnose common causes of 400 BadRequest errors.\"\"\"\n",
    "    \n",
    "    issues_found = []\n",
    "    \n",
    "    # Check 1: Environment variables\n",
    "    print(\"1ï¸âƒ£ Checking Environment Variables...\")\n",
    "    required_vars = {\n",
    "        \"AZURE_VOICE_LIVE_ENDPOINT\": os.getenv(\"AZURE_VOICE_LIVE_ENDPOINT\"),\n",
    "        \"AI_FOUNDRY_AGENT_ID\": os.getenv(\"AI_FOUNDRY_AGENT_ID\"),\n",
    "        \"AI_FOUNDRY_PROJECT_NAME\": os.getenv(\"AI_FOUNDRY_PROJECT_NAME\")\n",
    "    }\n",
    "    \n",
    "    for var, value in required_vars.items():\n",
    "        if not value:\n",
    "            print(f\"   âŒ {var}: MISSING\")\n",
    "            issues_found.append(f\"Missing {var}\")\n",
    "        else:\n",
    "            print(f\"   âœ… {var}: {value[:30]}...\")\n",
    "    \n",
    "    # Check 2: Endpoint format\n",
    "    print(\"\\n2ï¸âƒ£ Checking Endpoint Format...\")\n",
    "    endpoint = required_vars[\"AZURE_VOICE_LIVE_ENDPOINT\"]\n",
    "    if endpoint:\n",
    "        if not endpoint.endswith(\".services.ai.azure.com/\"):\n",
    "            print(f\"   âš ï¸  Endpoint should end with '.services.ai.azure.com/': {endpoint}\")\n",
    "            issues_found.append(\"Incorrect endpoint format\")\n",
    "        else:\n",
    "            print(f\"   âœ… Endpoint format looks correct\")\n",
    "    \n",
    "    # Check 3: Agent configuration\n",
    "    print(\"\\n3ï¸âƒ£ Checking Agent Configuration...\")\n",
    "    if 'agent' in globals():\n",
    "        print(f\"   Agent ID: {agent._binding.agent_id}\")\n",
    "        print(f\"   Project: {agent._binding.project_name}\")\n",
    "        print(f\"   URL: {agent.url[:100]}...\")\n",
    "        \n",
    "        # Check if URL has required parameters\n",
    "        if \"agent-access-token\" not in agent.url:\n",
    "            print(\"   âŒ agent-access-token missing from WebSocket URL\")\n",
    "            issues_found.append(\"Missing agent-access-token in URL\")\n",
    "        else:\n",
    "            print(\"   âœ… agent-access-token found in URL\")\n",
    "    \n",
    "    # Check 4: Common solutions\n",
    "    print(\"\\n4ï¸âƒ£ Recommended Solutions:\")\n",
    "    if issues_found:\n",
    "        print(\"   Issues found:\")\n",
    "        for issue in issues_found:\n",
    "            print(f\"   â€¢ {issue}\")\n",
    "        \n",
    "        print(\"\\n   ğŸ”§ Try these fixes:\")\n",
    "        print(\"   1. Verify your environment variables are set correctly\")\n",
    "        print(\"   2. Ensure your Azure AI Foundry agent ID is correct\")\n",
    "        print(\"   3. Check that your project name matches exactly\")\n",
    "        print(\"   4. Verify your Azure authentication is working\")\n",
    "        print(\"   5. Try recreating the agent object:\")\n",
    "        print(\"      agent = build_lva_from_yaml(yaml_path)\")\n",
    "    else:\n",
    "        print(\"   âœ… Configuration looks correct\")\n",
    "        print(\"   ğŸ’¡ This might be a temporary Azure service issue\")\n",
    "        print(\"   ğŸ’¡ Try running the agent creation cell again\")\n",
    "    \n",
    "    return len(issues_found) == 0\n",
    "\n",
    "# Run diagnostics\n",
    "is_healthy = diagnose_and_fix()\n",
    "\n",
    "if not is_healthy:\n",
    "    print(\"\\nâš ï¸  Issues detected - please fix the above problems and recreate the agent\")\n",
    "else:\n",
    "    print(\"\\nâœ… Configuration appears healthy - try running the connection test again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489228b6",
   "metadata": {},
   "source": [
    "# Audio Processing Architecture\n",
    "\n",
    "The live voice streaming system uses a multi-threaded architecture for real-time audio processing:\n",
    "\n",
    "## Thread Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Main Application Thread                      â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚ Audio Input     â”‚  â”‚ Audio Output    â”‚  â”‚ User Input      â”‚ â”‚\n",
    "â”‚  â”‚ Thread          â”‚  â”‚ Thread          â”‚  â”‚ Thread          â”‚ â”‚\n",
    "â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚\n",
    "â”‚  â”‚ Microphone      â”‚  â”‚ Speaker         â”‚  â”‚ Keyboard        â”‚ â”‚\n",
    "â”‚  â”‚ â†“               â”‚  â”‚ â†‘               â”‚  â”‚ Monitor         â”‚ â”‚\n",
    "â”‚  â”‚ PCM Audio       â”‚  â”‚ PCM Audio       â”‚  â”‚ ('q' to quit)  â”‚ â”‚\n",
    "â”‚  â”‚ â†“               â”‚  â”‚ â†‘               â”‚  â”‚                 â”‚ â”‚\n",
    "â”‚  â”‚ Base64 Encode   â”‚  â”‚ Base64 Decode   â”‚  â”‚                 â”‚ â”‚\n",
    "â”‚  â”‚ â†“               â”‚  â”‚ â†‘               â”‚  â”‚                 â”‚ â”‚\n",
    "â”‚  â”‚ WebSocket Send  â”‚  â”‚ WebSocket Recv  â”‚  â”‚                 â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                â”‚\n",
    "                                â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Azure Voice Live API                        â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Audio Input â†’ STT â†’ Agent Processing â†’ TTS â†’ Audio Output     â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚              â””â”€â”€ Azure AI Agent Service â”€â”€â”˜                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Audio Flow\n",
    "\n",
    "1. **Input**: Microphone captures audio at 24kHz sample rate\n",
    "2. **Chunking**: Audio read in 20ms chunks (480 samples)\n",
    "3. **Encoding**: Audio converted to Base64 for WebSocket transmission\n",
    "4. **Processing**: Azure Voice Live API performs STT, agent processing, and TTS\n",
    "5. **Output**: Processed audio returned and played through speakers\n",
    "\n",
    "## Proven Audio Configuration (from working notebook 04)\n",
    "\n",
    "**Input Stream:**\n",
    "- **Sample Rate**: 24,000 Hz (Azure Voice Live API standard)\n",
    "- **Channels**: 1 (Mono)\n",
    "- **Data Type**: int16 (16-bit PCM)\n",
    "- **Chunk Size**: 480 samples (20ms at 24kHz)\n",
    "- **Read Strategy**: Check available samples before reading\n",
    "\n",
    "**Output Stream:**\n",
    "- **Sample Rate**: 24,000 Hz (matching input)\n",
    "- **Channels**: 1 (Mono)  \n",
    "- **Data Type**: int16 (16-bit PCM)\n",
    "- **Block Size**: 2400 samples (~100ms buffer)\n",
    "- **Queue Management**: deque with thread-safe operations\n",
    "\n",
    "## Key Technical Details\n",
    "\n",
    "- **Audio Latency**: ~20ms input chunks + ~100ms output buffer = ~120ms total\n",
    "- **Format**: PCM 16-bit audio data (no float conversion needed)\n",
    "- **Threading**: Non-blocking audio I/O with efficient deque-based buffering\n",
    "- **Buffer Strategy**: Auto-start playback when data available\n",
    "- **Error Handling**: Graceful degradation with status monitoring\n",
    "\n",
    "## Performance Characteristics\n",
    "\n",
    "- **Low CPU Usage**: Direct int16 processing without unnecessary conversions\n",
    "- **Stable Playback**: Large output buffer (100ms) prevents dropouts\n",
    "- **Real-time**: 20ms input chunks ensure responsive voice detection\n",
    "- **Memory Efficient**: deque-based queue with automatic cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aedb3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Audio Processing Functions ===\n",
      "âœ… Audio processing functions loaded\n",
      "   Configuration: 24000Hz, 480 samples/chunk (20ms)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Audio Processing Implementation\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "print(\"=== Audio Processing Functions ===\")\n",
    "\n",
    "# Global configuration - Matching working notebook 04\n",
    "stop_event = threading.Event()\n",
    "AUDIO_SAMPLE_RATE = 24000  # Hz - Azure Voice Live API standard\n",
    "READ_SIZE = int(AUDIO_SAMPLE_RATE * 0.02)  # 20ms chunks = 480 samples\n",
    "\n",
    "class AudioPlayerAsync:\n",
    "    \"\"\"\n",
    "    Asynchronous audio player for real-time Voice Live API responses.\n",
    "    \n",
    "    Based on the working implementation from notebook 04-exploring-live-api.ipynb\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = deque()\n",
    "        self.lock = threading.Lock()\n",
    "        self.stream = sd.OutputStream(\n",
    "            callback=self.callback,\n",
    "            samplerate=AUDIO_SAMPLE_RATE,\n",
    "            channels=1,\n",
    "            dtype=np.int16,\n",
    "            blocksize=2400,  # ~100ms at 24kHz\n",
    "        )\n",
    "        self.playing = False\n",
    "\n",
    "    def callback(self, outdata, frames, time, status):\n",
    "        \"\"\"Audio callback function called by sounddevice.\"\"\"\n",
    "        if status:\n",
    "            print(f\"âš ï¸  Audio status: {status}\")\n",
    "            \n",
    "        with self.lock:\n",
    "            data = np.empty(0, dtype=np.int16)\n",
    "            \n",
    "            # Fill the output buffer from our queue\n",
    "            while len(data) < frames and len(self.queue) > 0:\n",
    "                item = self.queue.popleft()\n",
    "                frames_needed = frames - len(data)\n",
    "                data = np.concatenate((data, item[:frames_needed]))\n",
    "                \n",
    "                # If we have leftover data, put it back\n",
    "                if len(item) > frames_needed:\n",
    "                    self.queue.appendleft(item[frames_needed:])\n",
    "            \n",
    "            # Pad with silence if we don't have enough data\n",
    "            if len(data) < frames:\n",
    "                data = np.concatenate((data, np.zeros(frames - len(data), dtype=np.int16)))\n",
    "                \n",
    "        outdata[:] = data.reshape(-1, 1)\n",
    "\n",
    "    def add_data(self, data: bytes):\n",
    "        \"\"\"Add audio data to the playback queue.\"\"\"\n",
    "        with self.lock:\n",
    "            np_data = np.frombuffer(data, dtype=np.int16)\n",
    "            self.queue.append(np_data)\n",
    "            \n",
    "            # Auto-start playback if we have data\n",
    "            if not self.playing and len(self.queue) > 0:\n",
    "                self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start audio playback.\"\"\"\n",
    "        if not self.playing:\n",
    "            self.playing = True\n",
    "            self.stream.start()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop audio playback and clear buffer.\"\"\"\n",
    "        with self.lock:\n",
    "            self.queue.clear()\n",
    "        self.playing = False\n",
    "        self.stream.stop()\n",
    "\n",
    "    def terminate(self):\n",
    "        \"\"\"Terminate the audio player and release resources.\"\"\"\n",
    "        with self.lock:\n",
    "            self.queue.clear()\n",
    "        self.stream.stop()\n",
    "        self.stream.close()\n",
    "\n",
    "def listen_and_send_audio(connection):\n",
    "    \"\"\"Capture audio from microphone and send to Voice Live API.\"\"\"\n",
    "    print(\"ğŸ¤ Audio input started\")\n",
    "\n",
    "    # Create audio input stream - EXACT settings from working notebook\n",
    "    stream = sd.InputStream(\n",
    "        channels=1, \n",
    "        samplerate=AUDIO_SAMPLE_RATE, \n",
    "        dtype=\"int16\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        stream.start()\n",
    "        \n",
    "        while not stop_event.is_set():\n",
    "            if stream.read_available >= READ_SIZE:\n",
    "                # Read audio data\n",
    "                data, _ = stream.read(READ_SIZE)\n",
    "                \n",
    "                # Encode as base64\n",
    "                audio = base64.b64encode(data).decode(\"utf-8\")\n",
    "                \n",
    "                # Create API message\n",
    "                param = {\n",
    "                    \"type\": \"input_audio_buffer.append\", \n",
    "                    \"audio\": audio, \n",
    "                    \"event_id\": \"\"\n",
    "                }\n",
    "                \n",
    "                # Send to API\n",
    "                connection.send_dict(param)\n",
    "            else:\n",
    "                time.sleep(0.001)  # Small sleep to prevent busy waiting\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Audio input error: {e}\")\n",
    "        stop_event.set()\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "\n",
    "def receive_audio_and_playback(connection):\n",
    "    \"\"\"Receive messages from Voice Live API and handle audio playback.\"\"\"\n",
    "    print(\"ğŸ”Š Audio output started\")\n",
    "    \n",
    "    # Create audio player\n",
    "    audio_player = AudioPlayerAsync()\n",
    "    last_audio_item_id = None\n",
    "    \n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            try:\n",
    "                raw_message = connection.recv(timeout_s=0.1)\n",
    "                if raw_message:\n",
    "                    event = json.loads(raw_message)\n",
    "                    event_type = event.get(\"type\", \"\")\n",
    "                    \n",
    "                    # Handle different event types\n",
    "                    if event_type == \"session.created\":\n",
    "                        session = event.get(\"session\", {})\n",
    "                        session_id = session.get(\"id\", \"unknown\")\n",
    "                        print(f\"âœ… Session: {session_id}\")\n",
    "                        \n",
    "                    elif event_type == \"conversation.item.input_audio_transcription.completed\":\n",
    "                        transcript = event.get(\"transcript\", \"\")\n",
    "                        if transcript:\n",
    "                            print(f\"User: {transcript}\")\n",
    "                            \n",
    "                    elif event_type == \"response.audio_transcript.done\":\n",
    "                        transcript = event.get(\"transcript\", \"\")\n",
    "                        if transcript:\n",
    "                            print(f\"Agent: {transcript}\")\n",
    "                            \n",
    "                    elif event_type == \"response.audio.delta\":\n",
    "                        # New audio data from AI response\n",
    "                        item_id = event.get(\"item_id\", \"unknown\")\n",
    "                        \n",
    "                        if item_id != last_audio_item_id:\n",
    "                            last_audio_item_id = item_id\n",
    "\n",
    "                        # Decode and play audio - EXACT method from working notebook\n",
    "                        bytes_data = base64.b64decode(event.get(\"delta\", \"\"))\n",
    "                        if bytes_data:\n",
    "                            audio_player.add_data(bytes_data)\n",
    "                            \n",
    "                    elif event_type == \"error\":\n",
    "                        error = event.get(\"error\", {})\n",
    "                        print(f\"âŒ API Error: {error.get('message', 'Unknown error')}\")\n",
    "                        stop_event.set()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if not stop_event.is_set():\n",
    "                    print(f\"âŒ Audio processing error: {e}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Audio output error: {e}\")\n",
    "        stop_event.set()\n",
    "    finally:\n",
    "        audio_player.terminate()\n",
    "\n",
    "def monitor_user_input():\n",
    "    \"\"\"Monitor keyboard input for quit command.\"\"\"\n",
    "    print(\"âŒ¨ï¸  Type 'q' + Enter to quit\")\n",
    "    \n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            user_input = input().strip().lower()\n",
    "            if user_input == 'q':\n",
    "                stop_event.set()\n",
    "                break\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            stop_event.set()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            break\n",
    "    \n",
    "print(\"âœ… Audio processing functions loaded\")\n",
    "print(f\"   Configuration: {AUDIO_SAMPLE_RATE}Hz, {READ_SIZE} samples/chunk (20ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0128bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Live Voice Agent application ready\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Live Voice Agent Application\n",
    "\n",
    "def run_live_voice_agent():\n",
    "    \"\"\"\n",
    "    Main application orchestrating the live voice agent.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Establish WebSocket connection to Azure Voice Live API\n",
    "    2. Send session configuration\n",
    "    3. Start three concurrent threads:\n",
    "       - Audio input (microphone â†’ API)\n",
    "       - Audio output (API â†’ speakers)  \n",
    "       - User input (keyboard monitoring)\n",
    "    4. Coordinate graceful shutdown\n",
    "    \"\"\"\n",
    "    global stop_event\n",
    "    stop_event.clear()\n",
    "    \n",
    "    threads = []\n",
    "    connection = None\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸš€ Starting Live Voice Agent...\")\n",
    "        \n",
    "        # Establish connection\n",
    "        agent.connect()\n",
    "        connection = agent._ws\n",
    "        \n",
    "        # Configure session\n",
    "        session_config = agent._session_update()\n",
    "        connection.send_dict(session_config)\n",
    "        \n",
    "        # Wait for session establishment\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Start processing threads\n",
    "        thread_configs = [\n",
    "            {\"target\": lambda: listen_and_send_audio(connection), \"name\": \"AudioInput\"},\n",
    "            {\"target\": lambda: receive_audio_and_playback(connection), \"name\": \"AudioOutput\"},\n",
    "            {\"target\": monitor_user_input, \"name\": \"UserInput\"}\n",
    "        ]\n",
    "        \n",
    "        for config in thread_configs:\n",
    "            thread = threading.Thread(target=config[\"target\"], name=config[\"name\"])\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"ğŸ™ï¸  LIVE VOICE AGENT ACTIVE\")\n",
    "        print(\"   Speak into microphone\")\n",
    "        print(\"   Type 'q' + Enter to quit\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # Wait for user termination\n",
    "        threads[2].join()  # Wait for user input thread\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Application error: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        print(\"\\nğŸ›‘ Shutting down...\")\n",
    "        stop_event.set()\n",
    "        \n",
    "        # Stop threads with timeout\n",
    "        for thread in threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join(timeout=3)\n",
    "        \n",
    "        # Close connection\n",
    "        if connection:\n",
    "            try:\n",
    "                agent.close()\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "        print(\"âœ… Shutdown complete\")\n",
    "\n",
    "print(\"âœ… Live Voice Agent application ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74d24208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›‘ Stopping any running voice agents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-09 23:04:12,974] INFO - apps.rtagent.backend.src.agents.Lvagent.audio_io: SpeakerSink stopped.\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.audio_io:SpeakerSink stopped.\n",
      "[2025-10-09 23:04:12,981] INFO - apps.rtagent.backend.src.agents.Lvagent.base: Azure Live Voice Agent connection closed\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.base:Azure Live Voice Agent connection closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ Closed existing agent connection\n",
      "âœ… No active audio threads found\n",
      "=== Live Voice Agent Ready ===\n",
      "Agent: asst_Kp4exd80NINFuraHyWOftsuR\n",
      "Voice: en-US-Ava:DragonHDLatestNeural\n",
      "Audio: 24000Hz, 20ms chunks\n",
      "\n",
      "ğŸ¯ Starting voice conversation...\n",
      "   â€¢ Speak into your microphone\n",
      "   â€¢ Agent will respond with voice\n",
      "   â€¢ Type 'q' + Enter to quit\n",
      "ğŸš€ Starting Live Voice Agent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-09 23:04:13,536] ERROR - apps.rtagent.backend.src.agents.Lvagent.transport: WebSocket error: Handshake status 400 BadRequest -+-+- {'content-length': '0', 'apim-request-id': '7bb89442-da28-4726-8e74-aac0730d4c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:04:13 GMT'} -+-+- b''\n",
      "ERROR:apps.rtagent.backend.src.agents.Lvagent.transport:WebSocket error: Handshake status 400 BadRequest -+-+- {'content-length': '0', 'apim-request-id': '7bb89442-da28-4726-8e74-aac0730d4c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:04:13 GMT'} -+-+- b''\n",
      "ERROR:websocket:Handshake status 400 BadRequest -+-+- {'content-length': '0', 'apim-request-id': '7bb89442-da28-4726-8e74-aac0730d4c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:04:13 GMT'} -+-+- b'' - goodbye\n",
      "[2025-10-09 23:04:13,556] INFO - apps.rtagent.backend.src.agents.Lvagent.transport: WebSocket closed: code=None, msg=None\n",
      "INFO:apps.rtagent.backend.src.agents.Lvagent.transport:WebSocket closed: code=None, msg=None\n",
      "[2025-10-09 23:04:23,024] ERROR - apps.rtagent.backend.src.agents.Lvagent.base: Failed to connect: WebSocket did not open within 10.0s (last_error=Handshake status 400 BadRequest -+-+- {'content-length': '0', 'apim-request-id': '7bb89442-da28-4726-8e74-aac0730d4c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:04:13 GMT'} -+-+- b'')\n",
      "ERROR:apps.rtagent.backend.src.agents.Lvagent.base:Failed to connect: WebSocket did not open within 10.0s (last_error=Handshake status 400 BadRequest -+-+- {'content-length': '0', 'apim-request-id': '7bb89442-da28-4726-8e74-aac0730d4c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:04:13 GMT'} -+-+- b'')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Application error: WebSocket did not open within 10.0s (last_error=Handshake status 400 BadRequest -+-+- {'content-length': '0', 'apim-request-id': '7bb89442-da28-4726-8e74-aac0730d4c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'date': 'Fri, 10 Oct 2025 04:04:13 GMT'} -+-+- b'')\n",
      "\n",
      "ğŸ›‘ Shutting down...\n",
      "âœ… Shutdown complete\n",
      "âœ… Session ended\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Execute Live Voice Agent\n",
    "\n",
    "# Clean up any existing connections first\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Stop all running threads\n",
    "if 'stop_event' in globals():\n",
    "    stop_event.set()\n",
    "    print(\"ğŸ›‘ Stopping any running voice agents...\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Close any existing agent connections\n",
    "if 'agent' in globals():\n",
    "    try:\n",
    "        agent.close()\n",
    "        print(\"ğŸ”Œ Closed existing agent connection\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Clear thread references\n",
    "active_threads = [t for t in threading.enumerate() if t.name in ['AudioInput', 'AudioOutput', 'UserInput']]\n",
    "if active_threads:\n",
    "    print(f\"âš ï¸  Found {len(active_threads)} active audio threads - they should stop shortly\")\n",
    "else:\n",
    "    print(\"âœ… No active audio threads found\")\n",
    "\n",
    "\n",
    "print(\"=== Live Voice Agent Ready ===\")\n",
    "print(f\"Agent: {agent._binding.agent_id}\")\n",
    "print(f\"Voice: {agent._session.voice_name}\")\n",
    "print(f\"Audio: {AUDIO_SAMPLE_RATE}Hz, 20ms chunks\")\n",
    "\n",
    "print(\"\\nğŸ¯ Starting voice conversation...\")\n",
    "print(\"   â€¢ Speak into your microphone\")\n",
    "print(\"   â€¢ Agent will respond with voice\")\n",
    "print(\"   â€¢ Type 'q' + Enter to quit\")\n",
    "\n",
    "# Execute the live voice agent (single instance only)\n",
    "try:\n",
    "    run_live_voice_agent()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâ¹ï¸  Interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")\n",
    "finally:\n",
    "    print(\"âœ… Session ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3656631",
   "metadata": {},
   "source": [
    "# Notes and Troubleshooting\n",
    "\n",
    "## System Requirements\n",
    "\n",
    "**Software Dependencies:**\n",
    "- Python 3.11+\n",
    "- sounddevice library for audio I/O\n",
    "- websocket-client for WebSocket communication\n",
    "- azure-identity for authentication\n",
    "- numpy for audio processing\n",
    "\n",
    "**Hardware Requirements:**\n",
    "- Microphone for audio input\n",
    "- Speakers/headphones for audio output\n",
    "- Stable internet connection (minimum 1 Mbps)\n",
    "\n",
    "**Azure Resources:**\n",
    "- Azure AI Agent Service resource\n",
    "- Azure Voice Live API access\n",
    "- Proper RBAC permissions for agent access\n",
    "\n",
    "## Configuration Files\n",
    "\n",
    "**YAML Structure:**\n",
    "```yaml\n",
    "model:\n",
    "  deployment_id: \"gpt-4o\"\n",
    "  \n",
    "azure_ai_foundry_agent_connected:\n",
    "  agent_id: \"${AI_FOUNDRY_AGENT_ID}\"\n",
    "  project_name: \"${AI_FOUNDRY_PROJECT_NAME}\"\n",
    "  \n",
    "session:\n",
    "  voice:\n",
    "    name: \"en-US-Ava:DragonHDLatestNeural\"\n",
    "    temperature: 0.8\n",
    "  vad_threshold: 0.5\n",
    "  vad_prefix_ms: 300\n",
    "  vad_silence_ms: 1000\n",
    "```\n",
    "\n",
    "**Environment Variables:**\n",
    "```bash\n",
    "AZURE_VOICE_LIVE_ENDPOINT=https://your-resource.services.ai.azure.com/\n",
    "AI_FOUNDRY_AGENT_ID=asst_your_agent_id\n",
    "AI_FOUNDRY_PROJECT_NAME=your-project-name\n",
    "AZURE_VOICE_LIVE_API_KEY=optional_api_key\n",
    "```\n",
    "\n",
    "## Common Issues\n",
    "\n",
    "**Connection Errors:**\n",
    "- Verify endpoint format (.services.ai.azure.com)\n",
    "- Check agent ID and project name\n",
    "- Ensure proper Azure authentication\n",
    "\n",
    "**Audio Issues:**\n",
    "- Check microphone/speaker permissions\n",
    "- Verify audio device availability\n",
    "- Adjust sample rate if needed\n",
    "\n",
    "**Performance Issues:**\n",
    "- Monitor thread synchronization\n",
    "- Check network latency\n",
    "- Optimize buffer sizes for your environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
