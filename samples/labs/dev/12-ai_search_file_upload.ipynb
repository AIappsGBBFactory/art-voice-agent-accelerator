{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f4bcf1",
   "metadata": {},
   "source": [
    "# Azure AI Search PDF Uploader\n",
    "This notebook loads files from a folder, extracts text, chunks it, generates embeddings with Azure OpenAI, and uploads into an Azure AI Search index with vector search enabled.\n",
    "\n",
    "To use:\n",
    "1. Create an .env file from sample.env and input your variables\n",
    "2. Include path to local folder of PDF's\n",
    "3. Create a search index (optional after initial creation)\n",
    "4. Upload documents with embeddings\n",
    "5. Test with a query\n",
    "\n",
    "Notes:\n",
    "- To avoid issues with different SDK versions, this notebook creates the search index using the `schema.json` file and inputs variables directly from your .env file. If you want to make changes to your index (ie: change field names), update the `schema.json` file.\n",
    "- This is utilizing the simple chunking strategy of 1 page per chunk. Depending on your documents, you may want to utilize a different strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2281e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. Load environment variables\n",
    "# ---------------------------------------------------------\n",
    "load_dotenv(override=True)\n",
    "\n",
    "SEARCH_ENDPOINT = os.environ[\"AZURE_AI_SEARCH_SERVICE_ENDPOINT\"]\n",
    "SEARCH_API_KEY = os.environ[\"AZURE_AI_SEARCH_ADMIN_KEY\"]\n",
    "SEARCH_INDEX = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "INDEX_SCHEMA_PATH = os.environ[\"INDEX_SCHEMA_PATH\"]\n",
    "MODEL_DIMENSIONS = int(os.environ[\"MODEL_DIMENSIONS\"])\n",
    "\n",
    "AOAI_ENDPOINT= os.environ[\"AZURE_OPEN_AI_ENDPOINT\"]\n",
    "EMBED_MODEL = os.environ[\"AZURE_OPEN_AI_DEPLOYMENT_NAME\"] # 3072 dims\n",
    "AOAI_API_VERSION = os.environ[\"AZURE_OPEN_AI_API_VERSION\"]\n",
    "AOAI_KEY=os.environ[\"AZURE_OPEN_AI_API_KEY\"]\n",
    "\n",
    "# Path to folder containing PDFs to upload\n",
    "PDF_FOLDER = Path(r\"C:\\Users\\annaquincy\\Desktop\\Code\\bofa-demo\\art-voice-agent-accelerator\\utils\\data\\creditcardsProducts\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Initialize Azure AI Foundry client (embeddings)\n",
    "# ---------------------------------------------------------\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "aoai_client = AzureOpenAI(\n",
    "    api_key=AOAI_KEY,\n",
    "    api_version=AOAI_API_VERSION,\n",
    "    azure_endpoint=AOAI_ENDPOINT\n",
    ")\n",
    "# ---------------------------------------------------------\n",
    "# 3. Initialize Azure AI Search client\n",
    "# ---------------------------------------------------------\n",
    "search_client = SearchClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    index_name=SEARCH_INDEX,\n",
    "    credential=AzureKeyCredential(SEARCH_API_KEY)\n",
    ")\n",
    "\n",
    "search_index_client = SearchIndexClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    credential=AzureKeyCredential(SEARCH_API_KEY)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae54a61",
   "metadata": {},
   "source": [
    "### Optional: Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee75b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_schema_file = Path(INDEX_SCHEMA_PATH)\n",
    "with open(index_schema_file, \"r\") as f:\n",
    "    index_schema = json.loads(f.read())\n",
    "    index_schema[\"name\"] = SEARCH_INDEX\n",
    "    index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['resourceUri'] = AOAI_ENDPOINT\n",
    "    index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['deploymentId'] = EMBED_MODEL\n",
    "    index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['apiKey'] = AOAI_KEY\n",
    "    index_schema['vectorSearch']['vectorizers'][0]['azureOpenAIParameters']['modelName'] = EMBED_MODEL\n",
    "    #for vector field, set dimensions\n",
    "    for field in index_schema['fields']:\n",
    "        if field.get('name') == 'vector':\n",
    "            field['dimensions'] = MODEL_DIMENSIONS \n",
    "\n",
    "search_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": SEARCH_API_KEY\n",
    "}\n",
    "\n",
    "# #print index schema for debugging\n",
    "# print(json.dumps(index_schema, indent=2))\n",
    "\n",
    "create_index_url = f\"{SEARCH_ENDPOINT}/indexes?api-version=2025-09-01\"\n",
    "print(create_index_url)\n",
    "response = requests.post(create_index_url, headers=search_headers, json=index_schema)\n",
    "if response.status_code == 201:\n",
    "    print(f\"Index '{SEARCH_INDEX}' created successfully.\")\n",
    "elif response.status_code == 204:\n",
    "    print(f\"Index '{SEARCH_INDEX}' already exists.\")\n",
    "else:\n",
    "    print(f\"Failed to create index '{SEARCH_INDEX}'. Status code: {response.status_code}, Response: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da1225f",
   "metadata": {},
   "source": [
    "### Upload Embedded Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. PDF per-page extraction\n",
    "# ---------------------------------------------------------\n",
    "def extract_pdf_pages(pdf_path: Path):\n",
    "    \"\"\"Return list of (page_number, text) for each non-empty page.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\").replace(\"\\x00\", \"\").strip()\n",
    "\n",
    "        if text:\n",
    "            pages.append((page_num + 1, text))\n",
    "\n",
    "    return pages\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Embed a single chunk using Azure AI Foundry\n",
    "# ---------------------------------------------------------\n",
    "def generate_embedding(text):\n",
    "    \"\"\"Generate 3072-dim embedding using text-embedding-3-large\"\"\"\n",
    "    try:\n",
    "        response = aoai_client.embeddings.create(\n",
    "            model=EMBED_MODEL,\n",
    "            input=text,\n",
    "            dimensions=3072\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating embedding: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. Build a document entry for AI Search\n",
    "# ---------------------------------------------------------\n",
    "def build_search_doc(pdf_path: Path, page_num: int, content: str, vector):\n",
    "    return {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"title\": pdf_path.stem,\n",
    "        \"content\": content,\n",
    "        \"file_name\": f\"{pdf_path.name}#page={page_num}\",\n",
    "        \"vector\": vector,\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 7. Main ingestion loop (read PDFs ‚Üí embed ‚Üí upload)\n",
    "# ---------------------------------------------------------\n",
    "all_documents = []\n",
    "\n",
    "for pdf_file in PDF_FOLDER.glob(\"*.pdf\"):\n",
    "    print(f\"üìÑ Processing {pdf_file.name}...\")\n",
    "\n",
    "    pages = extract_pdf_pages(pdf_file)\n",
    "\n",
    "    for page_num, text in pages:\n",
    "        # Per-page embedding\n",
    "        vector = generate_embedding(text)\n",
    "\n",
    "        # Build search document\n",
    "        doc = build_search_doc(pdf_file, page_num, text, vector)\n",
    "        all_documents.append(doc)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. Upload to Azure AI Search in batches\n",
    "# ---------------------------------------------------------\n",
    "print(f\"üöÄ Uploading {len(all_documents)} chunks to Azure AI Search...\")\n",
    "\n",
    "result = search_client.upload_documents(all_documents)\n",
    "\n",
    "print(\"‚úÖ Upload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c29b4d",
   "metadata": {},
   "source": [
    "### Test Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf12eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query AI Search for relevant documents\n",
    "def query_ai_search(query: str, top_k: int =3):\n",
    "    embedding = generate_embedding(query)\n",
    "    search_results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[{\n",
    "            \"kind\": \"vector\",\n",
    "            \"vector\": embedding,\n",
    "            \"fields\": \"vector\",\n",
    "            \"k\": top_k\n",
    "        }]\n",
    "    )\n",
    "    return search_results\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the best options for a travel credit card?\"\n",
    "results = query_ai_search(query, top_k=3)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"File Name: {result['file_name']}\")\n",
    "    print(f\"Content Snippet: {result['content'][:200]}...\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92af2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
